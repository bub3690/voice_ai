{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37664ece",
   "metadata": {},
   "source": [
    "- http://keunwoochoi.blogspot.com/2016/03/2.html\n",
    "- http://www.rex-ai.info/docs/AI_Example_CNN_speech_recognize\n",
    "- https://www.youtube.com/watch?v=oltGIc4uo5c\n",
    "- https://youdaeng-com.tistory.com/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "275b8092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pytorch version :  1.10.0  Device :  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn # 인공 신경망 모델들 모아놓은 모듈\n",
    "import torch.nn.functional as F #그중 자주 쓰이는것들을 F로\n",
    "from torchvision import transforms, datasets\n",
    "import cv2\n",
    "from torchvision import transforms, datasets\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "p = os.path.abspath('..') # 상위 폴더를 사용하기 위해서.\n",
    "sys.path.insert(1, p)\n",
    "from pytorchtools.pytorchtools import EarlyStopping # 현재 폴더에 추가된 모듈.\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "#DEVICE = torch.device('cpu')\n",
    "print('Using Pytorch version : ',torch.__version__,' Device : ',DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ebea6",
   "metadata": {},
   "source": [
    "# SVD 문장 데이터에서 Feature 추출\n",
    "- mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "114a1b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa, librosa.display \n",
    "import matplotlib.pyplot as plt\n",
    "#window sizde : FFT를 할때 참조할 그래프 길이 ( 프레임 하나당 sample 수 )\n",
    "#자연어 처리에서는 25ms 사용. https://ahnjg.tistory.com/93\n",
    "#초당 50000hz 중 1250개씩 윈도우 사이즈로 사용.\n",
    "sr=50000\n",
    "win_length =  np.int64(50000/40) # 1250\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c72d82e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pathology data 수 :  1195\n",
      "healthy data 수 :  687\n",
      "가장 긴 path sample : 130793\n",
      "가장 긴 healthy sample : 194501\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa, librosa.display \n",
    "import matplotlib.pyplot as plt\n",
    "#window sizde : FFT를 할때 참조할 그래프 길이 ( 프레임 하나당 sample 수 )\n",
    "#자연어 처리에서는 25ms 사용. https://ahnjg.tistory.com/93\n",
    "#초당 50000hz 중 1250개씩 윈도우 사이즈로 사용.\n",
    "sr=50000\n",
    "win_length =  np.int64(50000/40) # 1250\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다.\n",
    "\n",
    "pathology_sig=[]\n",
    "healthy_sig=[]\n",
    "\n",
    "pathology=[]\n",
    "healthy=[]\n",
    "\n",
    "\n",
    "#PATHOLOGY DATA\n",
    "for audio_path in os.listdir('../../voice_data/pathology_new/u/export'):\n",
    "    sig, sr = librosa.load('../../voice_data/pathology_new/u/export/'+audio_path, sr=50000)# 논문에서 f_s = 50 000HZ\n",
    "    pathology_sig.append(sig)\n",
    "    MFCCs = librosa.feature.mfcc(sig, sr, win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "    pathology.append(MFCCs)\n",
    "    \n",
    "\n",
    "#Healthy data\n",
    "for audio_path in os.listdir('../../voice_data/healthy_new/u/export'):\n",
    "    sig, sr = librosa.load('../../voice_data/healthy_new/u/export/'+audio_path, sr=50000)# 논문에서 f_s = 50 000HZ\n",
    "    healthy_sig.append(sig)\n",
    "    MFCCs = librosa.feature.mfcc(sig, sr, win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "    healthy.append(MFCCs)\n",
    "    \n",
    "print(\"pathology data 수 : \",len(pathology))\n",
    "print(\"healthy data 수 : \",len(healthy))\n",
    "\n",
    "\n",
    "path_max=max([ len(samples) for samples in pathology_sig])\n",
    "healthy_max=max([ len(samples) for samples in healthy_sig])\n",
    "print(\"가장 긴 path sample :\" ,path_max)\n",
    "print(\"가장 긴 healthy sample :\" ,healthy_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "636bede8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.61586 초\n",
      "3.89002 초\n"
     ]
    }
   ],
   "source": [
    "print(path_max/sr,\"초\")\n",
    "print(healthy_max/sr,\"초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5915f64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 :  1.2356882510460252\n",
      "평균 :  1.3178440174672488\n"
     ]
    }
   ],
   "source": [
    "print('평균 : ',np.mean([ len(samples) for samples in pathology_sig])/sr)\n",
    "print('평균 : ',np.mean([ len(samples) for samples in healthy_sig])/sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91bd1989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.504"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "400*313/sr\n",
    "#400 frame은 약 2.5초 이상."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148ec668",
   "metadata": {},
   "source": [
    "# 결과 확인\n",
    "- 1 row당 1 frame으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a48f3297",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>mfcc5</th>\n",
       "      <th>mfcc6</th>\n",
       "      <th>mfcc7</th>\n",
       "      <th>mfcc8</th>\n",
       "      <th>mfcc9</th>\n",
       "      <th>mfcc10</th>\n",
       "      <th>mfcc11</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-272.275146</td>\n",
       "      <td>208.902557</td>\n",
       "      <td>44.434441</td>\n",
       "      <td>40.349213</td>\n",
       "      <td>-25.458517</td>\n",
       "      <td>12.826863</td>\n",
       "      <td>-3.920654</td>\n",
       "      <td>-8.411410</td>\n",
       "      <td>3.417778</td>\n",
       "      <td>7.566922</td>\n",
       "      <td>-2.498518</td>\n",
       "      <td>-6.284049</td>\n",
       "      <td>-2.326992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-292.371613</td>\n",
       "      <td>203.497162</td>\n",
       "      <td>55.854485</td>\n",
       "      <td>54.128845</td>\n",
       "      <td>-19.807659</td>\n",
       "      <td>14.410148</td>\n",
       "      <td>-1.129526</td>\n",
       "      <td>-7.547229</td>\n",
       "      <td>2.966858</td>\n",
       "      <td>11.841558</td>\n",
       "      <td>1.122357</td>\n",
       "      <td>-0.466148</td>\n",
       "      <td>-0.014877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-326.458984</td>\n",
       "      <td>179.993637</td>\n",
       "      <td>64.711746</td>\n",
       "      <td>65.344246</td>\n",
       "      <td>-17.435101</td>\n",
       "      <td>19.880333</td>\n",
       "      <td>2.197647</td>\n",
       "      <td>-1.880868</td>\n",
       "      <td>-4.580058</td>\n",
       "      <td>4.086713</td>\n",
       "      <td>3.976766</td>\n",
       "      <td>1.293952</td>\n",
       "      <td>6.717286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-324.657288</td>\n",
       "      <td>174.853928</td>\n",
       "      <td>61.641129</td>\n",
       "      <td>64.695351</td>\n",
       "      <td>-10.726300</td>\n",
       "      <td>23.473757</td>\n",
       "      <td>-8.347025</td>\n",
       "      <td>-9.129495</td>\n",
       "      <td>-7.556191</td>\n",
       "      <td>10.262231</td>\n",
       "      <td>8.042992</td>\n",
       "      <td>2.768127</td>\n",
       "      <td>9.962308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-317.942169</td>\n",
       "      <td>182.751175</td>\n",
       "      <td>64.051483</td>\n",
       "      <td>59.415588</td>\n",
       "      <td>-17.222746</td>\n",
       "      <td>18.475574</td>\n",
       "      <td>-8.616613</td>\n",
       "      <td>-10.723660</td>\n",
       "      <td>-0.691800</td>\n",
       "      <td>12.757200</td>\n",
       "      <td>7.716760</td>\n",
       "      <td>2.235234</td>\n",
       "      <td>4.562744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>-354.029236</td>\n",
       "      <td>172.662659</td>\n",
       "      <td>72.229408</td>\n",
       "      <td>51.822090</td>\n",
       "      <td>-19.475491</td>\n",
       "      <td>24.674398</td>\n",
       "      <td>-14.183729</td>\n",
       "      <td>-14.277061</td>\n",
       "      <td>-8.532803</td>\n",
       "      <td>3.395573</td>\n",
       "      <td>14.948679</td>\n",
       "      <td>-4.153752</td>\n",
       "      <td>7.948050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>-363.935699</td>\n",
       "      <td>166.532837</td>\n",
       "      <td>73.193100</td>\n",
       "      <td>50.661980</td>\n",
       "      <td>-21.652119</td>\n",
       "      <td>21.548904</td>\n",
       "      <td>-14.202366</td>\n",
       "      <td>-13.243938</td>\n",
       "      <td>-2.112081</td>\n",
       "      <td>3.580634</td>\n",
       "      <td>10.965590</td>\n",
       "      <td>-10.593177</td>\n",
       "      <td>3.021251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>-364.039581</td>\n",
       "      <td>163.347534</td>\n",
       "      <td>80.410004</td>\n",
       "      <td>55.608833</td>\n",
       "      <td>-18.868038</td>\n",
       "      <td>21.568939</td>\n",
       "      <td>-14.416084</td>\n",
       "      <td>-12.026213</td>\n",
       "      <td>-2.639414</td>\n",
       "      <td>5.210083</td>\n",
       "      <td>14.799844</td>\n",
       "      <td>-4.204784</td>\n",
       "      <td>2.161280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>-360.334564</td>\n",
       "      <td>167.725281</td>\n",
       "      <td>81.819809</td>\n",
       "      <td>53.282486</td>\n",
       "      <td>-13.211727</td>\n",
       "      <td>18.665279</td>\n",
       "      <td>-17.974466</td>\n",
       "      <td>-14.677999</td>\n",
       "      <td>-6.362213</td>\n",
       "      <td>-0.718999</td>\n",
       "      <td>20.342644</td>\n",
       "      <td>-3.675610</td>\n",
       "      <td>-3.875287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>-350.499359</td>\n",
       "      <td>175.658173</td>\n",
       "      <td>78.769157</td>\n",
       "      <td>45.172649</td>\n",
       "      <td>-10.140876</td>\n",
       "      <td>15.867226</td>\n",
       "      <td>-21.012016</td>\n",
       "      <td>-10.770565</td>\n",
       "      <td>-3.238189</td>\n",
       "      <td>0.111002</td>\n",
       "      <td>20.215496</td>\n",
       "      <td>-3.303527</td>\n",
       "      <td>-4.188798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>341 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mfcc1       mfcc2      mfcc3      mfcc4      mfcc5      mfcc6  \\\n",
       "0   -272.275146  208.902557  44.434441  40.349213 -25.458517  12.826863   \n",
       "1   -292.371613  203.497162  55.854485  54.128845 -19.807659  14.410148   \n",
       "2   -326.458984  179.993637  64.711746  65.344246 -17.435101  19.880333   \n",
       "3   -324.657288  174.853928  61.641129  64.695351 -10.726300  23.473757   \n",
       "4   -317.942169  182.751175  64.051483  59.415588 -17.222746  18.475574   \n",
       "..          ...         ...        ...        ...        ...        ...   \n",
       "336 -354.029236  172.662659  72.229408  51.822090 -19.475491  24.674398   \n",
       "337 -363.935699  166.532837  73.193100  50.661980 -21.652119  21.548904   \n",
       "338 -364.039581  163.347534  80.410004  55.608833 -18.868038  21.568939   \n",
       "339 -360.334564  167.725281  81.819809  53.282486 -13.211727  18.665279   \n",
       "340 -350.499359  175.658173  78.769157  45.172649 -10.140876  15.867226   \n",
       "\n",
       "         mfcc7      mfcc8     mfcc9     mfcc10     mfcc11     mfcc12    mfcc13  \n",
       "0    -3.920654  -8.411410  3.417778   7.566922  -2.498518  -6.284049 -2.326992  \n",
       "1    -1.129526  -7.547229  2.966858  11.841558   1.122357  -0.466148 -0.014877  \n",
       "2     2.197647  -1.880868 -4.580058   4.086713   3.976766   1.293952  6.717286  \n",
       "3    -8.347025  -9.129495 -7.556191  10.262231   8.042992   2.768127  9.962308  \n",
       "4    -8.616613 -10.723660 -0.691800  12.757200   7.716760   2.235234  4.562744  \n",
       "..         ...        ...       ...        ...        ...        ...       ...  \n",
       "336 -14.183729 -14.277061 -8.532803   3.395573  14.948679  -4.153752  7.948050  \n",
       "337 -14.202366 -13.243938 -2.112081   3.580634  10.965590 -10.593177  3.021251  \n",
       "338 -14.416084 -12.026213 -2.639414   5.210083  14.799844  -4.204784  2.161280  \n",
       "339 -17.974466 -14.677999 -6.362213  -0.718999  20.342644  -3.675610 -3.875287  \n",
       "340 -21.012016 -10.770565 -3.238189   0.111002  20.215496  -3.303527 -4.188798  \n",
       "\n",
       "[341 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(healthy[0][2]) #1번 : 파일. 2번:mfcc\n",
    "headers = \"mfcc1 mfcc2 mfcc3 mfcc4 mfcc5 mfcc6 mfcc7 mfcc8 mfcc9 mfcc10 mfcc11 mfcc12 mfcc13\".split()\n",
    "pd.DataFrame(healthy[1].T,columns=headers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "186be135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthy[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73d328bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "del pathology\n",
    "del healthy\n",
    "del pathology_sig\n",
    "del healthy_sig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23a4c15",
   "metadata": {},
   "source": [
    "# 데이터 나누기 - Stratified KFold\n",
    "\n",
    "- pathology : 1195 / healthy : 687 / 총 1882\n",
    "- k = 5\n",
    "- random over sampling 추가 ( healthy 데이터가 부족하기 때문)\n",
    "- 변경 후 -> pathology : 1195 / healthy : 1195 / 총: 2390"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919f9829",
   "metadata": {},
   "source": [
    "kfold와 random over sampling을 같이 실시하려면, 미리 test set을 나눠야 한다.\n",
    "\n",
    "먼저 테스트셋을 나누고, 그 후에 random over sampling을 실시한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483be78e",
   "metadata": {},
   "source": [
    "## 1. test/ train 나누기\n",
    "\n",
    "- train+valid :1504  / test : 377\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c299eacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pathology :  1195\n",
      "Healthy:  687\n",
      "총 데이터수 :  1882\n",
      "---\n",
      "훈련 셋 :  1505 Counter({'pathology': 956, 'healthy': 549})\n",
      "테스트 셋 :  377 Counter({'pathology': 239, 'healthy': 138})\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "#1. train, test 나누기\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split # train , test 분리에 사용.\n",
    "\n",
    "pathology = glob('../../voice_data/pathology_new/u/export/*.wav')\n",
    "healthy = glob('../../voice_data/healthy_new/u/export/*.wav')\n",
    "print(\"Pathology : \",len(pathology))\n",
    "print(\"Healthy: \",len(healthy))\n",
    "\n",
    "X = pathology+healthy # path 데이터 합\n",
    "print(\"총 데이터수 : \",len(X))\n",
    "Y = [] # 라벨\n",
    "for idx,x in enumerate(X):\n",
    "    if idx<1195:\n",
    "        Y.append(\"pathology\")\n",
    "    else:\n",
    "        Y.append(\"healthy\")\n",
    "\n",
    "#train 1504   test: 377\n",
    "X, X_test, Y, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True, stratify=Y, random_state=456)\n",
    "#stratify를 넣어서, test에도 라벨별 잘 분류되게 한다.\n",
    "\n",
    "print(\"---\")\n",
    "print(\"훈련 셋 : \",len(Y),Counter(Y))\n",
    "print(\"테스트 셋 : \",len(Y_test),Counter(Y_test))\n",
    "print(\"---\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc18df8",
   "metadata": {},
   "source": [
    "## 2. random over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc4a0dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before dataset shape Counter({'pathology': 956, 'healthy': 549})\n",
      "Resampled dataset shape Counter({'healthy': 956, 'pathology': 956})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = np.array(X).reshape(-1,1)#각 데이터를 다 행으로 넣음. (1194,1)\n",
    "#Y = np.array(Y)\n",
    "ros = RandomOverSampler(random_state = 123)\n",
    "X_res,Y_res = ros.fit_resample(X,Y)\n",
    "\n",
    "print('before dataset shape {}'.format(Counter(Y)) )\n",
    "print('Resampled dataset shape {}'.format(Counter(Y_res)) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09f636fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['../../voice_data/healthy_new/a/export\\\\60-a_n.wav'],\n",
       "       ['../../voice_data/pathology_new/a/export\\\\2421-a_n.wav'],\n",
       "       ['../../voice_data/pathology_new/a/export\\\\1270-a_n.wav'],\n",
       "       ...,\n",
       "       ['../../voice_data/healthy_new/a/export\\\\1127-a_n.wav'],\n",
       "       ['../../voice_data/healthy_new/a/export\\\\1533-a_n.wav'],\n",
       "       ['../../voice_data/healthy_new/a/export\\\\1359-a_n.wav']],\n",
       "      dtype='<U52')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e3e54dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 데이터수 :  1912\n",
      "복사된 수 :  407\n"
     ]
    }
   ],
   "source": [
    "#원래대로 돌리기\n",
    "X=X_res.reshape(1, -1)\n",
    "print( '총 데이터수 : ',X[0].size )\n",
    "print(  '복사된 수 : ',X[0].size - np.unique(X[0]).size )\n",
    "\n",
    "X=X[0].tolist()\n",
    "Y=Y_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ac3467",
   "metadata": {},
   "source": [
    "## 3. stratified k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fada6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 : 1\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 764, 'pathology': 765}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 192, 'pathology': 191} \n",
      "\n",
      "교차 검증 : 2\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 765, 'pathology': 764}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 191, 'pathology': 192} \n",
      "\n",
      "교차 검증 : 3\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 765, 'pathology': 765}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 191, 'pathology': 191} \n",
      "\n",
      "교차 검증 : 4\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 765, 'pathology': 765}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 191, 'pathology': 191} \n",
      "\n",
      "교차 검증 : 5\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 765, 'pathology': 765}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 191, 'pathology': 191} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. train, test 나누기\n",
    "#stratified kfold\n",
    "import os\n",
    "import random #데이터 shuffle 사용\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "skf_iris = StratifiedKFold(n_splits=5,shuffle=True,random_state=456)\n",
    "cnt_iter = 0\n",
    "\n",
    "X_train_list = [] #데이터 셋 보관\n",
    "Y_train_list = []\n",
    "\n",
    "X_valid_list = []\n",
    "Y_valid_list = []\n",
    "\n",
    "for train_idx, test_idx in skf_iris.split(X,Y):\n",
    "    \n",
    "    #split으로 반환된 인덱스를 이용하여, 학습 검증용 테스트 데이터 추출\n",
    "    cnt_iter += 1\n",
    "    X_train, X_valid = [X[idx] for idx in train_idx.tolist() ], [X[idx] for idx in test_idx.tolist() ]\n",
    "    Y_train, Y_valid = [Y[idx] for idx in train_idx.tolist() ], [Y[idx] for idx in test_idx.tolist() ]\n",
    "    \n",
    "    X_train_list.append(X_train)\n",
    "    X_valid_list.append(X_valid)\n",
    "    \n",
    "    Y_train_list.append(Y_train)\n",
    "    Y_valid_list.append(Y_valid)\n",
    "    \n",
    "    \n",
    "    #학습 및 예측\n",
    "    \n",
    "    label_train = Y_train\n",
    "    label_test = Y_valid\n",
    "    unique_train, train_counts = np.unique(label_train, return_counts = True)\n",
    "    unique_test, test_counts = np.unique(label_test, return_counts = True)\n",
    "    \n",
    "    uniq_cnt_train = dict(zip(unique_train, train_counts))\n",
    "    uniq_cnt_test = dict(zip(unique_test, test_counts))\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('교차 검증 : {}'.format(cnt_iter))\n",
    "    print('학습 레이블 데이터 분포 : \\n', uniq_cnt_train)\n",
    "    print('검증 레이블 데이터 분포 : \\n', uniq_cnt_test,'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a663f0",
   "metadata": {},
   "source": [
    "# 데이터 정의\n",
    "- 추가적으로 데이터의 크기를 맞춰주기 위해 3초로 padding 및 truncate 실시 https://sequencedata.tistory.com/25 FixAudioLength\n",
    "- 논문에서는 400frame으로 설정.\n",
    "- 전처리 방법 결정.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2febf8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "classes = [\"pathology\",\"healthy\"]\n",
    "sr=50000\n",
    "win_length =  np.int64(50000/40) # 1250\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다.\n",
    "\n",
    "\n",
    "\n",
    "class svd_dataset(Dataset):\n",
    "    def __init__(self,data_path_list,classes,data_num,training,transform=None):\n",
    "        #클래스에서 사용할 인자를 받아 인스턴스 변수로 저장하는 일을 한다.\n",
    "        #예를들면, 이미지의 경로 리스트를 저장하는 일을 하게 된다.\n",
    "        \n",
    "        #data_num : k 개 데이터 셋 중 어떤것을 쓸지\n",
    "        #test인지 아닌지.\n",
    "        \n",
    "        self.path_list = data_path_list[data_num]\n",
    "        self.data_num = data_num\n",
    "        self.training = training\n",
    "        self.label = svd_dataset.get_label(self.path_list,training,data_num)\n",
    "        self.classes=classes\n",
    "        self.transform=transform\n",
    "        \n",
    "    \n",
    "    @classmethod\n",
    "    def get_label(cls,data_path_list,training,data_num):\n",
    "        label_list=[]\n",
    "        \n",
    "        if training:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_train_list[data_num][idx])\n",
    "        else:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_valid_list[data_num][idx])\n",
    "        #print(label_list)\n",
    "        return label_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "        #데이터 셋의 길이를 정수로 반환한다. \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        1. path를 받아서, 소리에서 mfcc를 추출\n",
    "        2. mfcc를 500프레임으로 패딩.\n",
    "        3. resnet에 사용되기 위해 3채널로 복사(rgb 처럼)\n",
    "        4. 0~1 정규화\n",
    "        \n",
    "        \"\"\"\n",
    "        sig, sr = librosa.load(self.path_list[idx], sr=50000)# 논문에서 f_s = 50 000HZ\n",
    "        \n",
    "        MFCCs = librosa.feature.mfcc(sig, sr, win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "        #mfcc 400 FRAME이 되도록 패딩.\n",
    "        length = 400\n",
    "        pad2d = lambda a, i: a[:, 0:i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0], i-a.shape[1]))))\n",
    "        MFCCs = pad2d(MFCCs, length)\n",
    "        MFCCs= MFCCs.T\n",
    "        \n",
    "        if self.transform:\n",
    "            #print('transform')\n",
    "            MFCCs=self.transform(MFCCs).type(torch.float32)# 데이터 0~1 정규화\n",
    "            MFCCs=torch.stack([MFCCs,MFCCs,MFCCs])# 3채널로 복사.\n",
    "            MFCCs = MFCCs.squeeze(dim=1)\n",
    "        else:\n",
    "            #print(\"else\")\n",
    "            MFCCs = torch.from_numpy(MFCCs).type(torch.float32)\n",
    "            MFCCs=MFCCs.unsqueeze(0)#cnn 사용위해서 추가\n",
    "            #MFCCs = MFCCs.permute(2, 0, 1)\n",
    "        return MFCCs, self.classes.index(self.label[idx])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ef4060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set 제작을 위한 class\n",
    "class svd_test_set(Dataset):\n",
    "    def __init__(self,data_path_list,classes,transform=None):\n",
    "        #클래스에서 사용할 인자를 받아 인스턴스 변수로 저장하는 일을 한다.\n",
    "        #예를들면, 이미지의 경로 리스트를 저장하는 일을 하게 된다.\n",
    "        \n",
    "        #data_num : k 개 데이터 셋 중 어떤것을 쓸지\n",
    "        #test인지 아닌지.\n",
    "        \n",
    "        self.path_list = data_path_list\n",
    "        self.label = svd_test_set.get_label(self.path_list)\n",
    "        self.classes=classes\n",
    "        self.transform=transform\n",
    "        \n",
    "    \n",
    "    @classmethod\n",
    "    def get_label(cls,data_path_list):\n",
    "        label_list=[]\n",
    "        \n",
    "        for idx,x in enumerate(data_path_list):\n",
    "            label_list.append(Y_test[idx])\n",
    "        #print(label_list)\n",
    "        return label_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "        #데이터 셋의 길이를 정수로 반환한다. \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        1. path를 받아서, 소리에서 mfcc를 추출\n",
    "        2. mfcc를 500프레임으로 패딩.\n",
    "        3. resnet에 사용되기 위해 3채널로 복사(rgb 처럼)\n",
    "        4. 0~1 정규화\n",
    "        \n",
    "        \"\"\"\n",
    "        sig, sr = librosa.load(self.path_list[idx], sr=50000)# 논문에서 f_s = 50 000HZ\n",
    "        \n",
    "        MFCCs = librosa.feature.mfcc(sig, sr, win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "        #mfcc 400 FRAME이 되도록 패딩.\n",
    "        length = 400\n",
    "        pad2d = lambda a, i: a[:, 0:i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0], i-a.shape[1]))))\n",
    "        MFCCs = pad2d(MFCCs, length)\n",
    "        MFCCs= MFCCs.T\n",
    "        \n",
    "        if self.transform:\n",
    "            #print('transform')\n",
    "            MFCCs=self.transform(MFCCs).type(torch.float32)# 데이터 0~1 정규화\n",
    "            MFCCs=torch.stack([MFCCs,MFCCs,MFCCs])# 3채널로 복사.\n",
    "            MFCCs = MFCCs.squeeze(dim=1)\n",
    "        else:\n",
    "            #print(\"else\")\n",
    "            MFCCs = torch.from_numpy(MFCCs).type(torch.float32)\n",
    "            MFCCs=MFCCs.unsqueeze(0)#cnn 사용위해서 추가\n",
    "            #MFCCs = MFCCs.permute(2, 0, 1)\n",
    "        return MFCCs, self.classes.index(self.label[idx])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d05129d",
   "metadata": {},
   "source": [
    "# 데이터 로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89052fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. 하이퍼 파라미터\n",
    "BATCH_SIZE =  30 #한 배치당 30개 음성데이터 # 32 배수시에, 1개만 남는 경우가 발생해서.\n",
    "EPOCHS = 40 # 전체 데이터 셋을 40번 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bba97b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA LOADER 함수가 BATCH_size 단위로 분리해 지정.\n",
    "\n",
    "#확인을 위해 데이터셋 하나만 확인\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                           svd_dataset(\n",
    "                                               X_train_list,\n",
    "                                               classes,\n",
    "                                               transform = transforms.ToTensor(),#이걸 composed로 고쳐서 전처리 하도록 수정.\n",
    "                                               data_num=0,\n",
    "                                               training=True\n",
    "                                           ),\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True,\n",
    "                                           ) # 순서가 암기되는것을 막기위해.\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                           svd_dataset(\n",
    "                                               X_valid_list,\n",
    "                                               classes,\n",
    "                                               transform = transforms.ToTensor(),\n",
    "                                               data_num=0,\n",
    "                                               training=False\n",
    "                                           ),\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True,) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5771dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 로더.\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_test_set(\n",
    "                                                   X_test,\n",
    "                                                   classes,\n",
    "                                                   transform = transforms.ToTensor(),\n",
    "                                               ),\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = True,) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b15a86",
   "metadata": {},
   "source": [
    "# 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f866237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :  torch.Size([30, 3, 400, 13]) type: torch.FloatTensor\n",
      "Y_train :  torch.Size([30]) type: torch.LongTensor\n",
      "tensor(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x1ecf7b4be80>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. 데이터 확인하기\n",
    "for (X_train,Y_train) in train_loader:\n",
    "    print(\"X_train : \",X_train.size(),'type:',X_train.type())\n",
    "    print(\"Y_train : \",Y_train.size(),'type:',Y_train.type())\n",
    "    break\n",
    "    \n",
    "print(Y_train[0])\n",
    "librosa.display.specshow(X_train[0][0].numpy().T, sr=50000, x_axis='time')\n",
    "#batch: 32 / frame수: 400  /  feature수: 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a45b51bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valid :  torch.Size([30, 3, 400, 13]) type: torch.FloatTensor\n",
      "Y_valid :  torch.Size([30]) type: torch.LongTensor\n",
      "tensor(1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x1ecdbd273d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#valiation set 확인\n",
    "for (X_valid,Y_valid) in validation_loader:\n",
    "    print(\"X_valid : \",X_valid.size(),'type:',X_valid.type())\n",
    "    print(\"Y_valid : \",Y_valid.size(),'type:',Y_valid.type())\n",
    "    break\n",
    "\n",
    "print(Y_valid[0])\n",
    "librosa.display.specshow(X_valid[0][0].numpy().T, sr=50000, x_axis='time')\n",
    "#batch: 32 / 3채널 / frame수: 400  /  feature수: 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe011218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valid :  torch.Size([30, 3, 400, 13]) type: torch.FloatTensor\n",
      "Y_valid :  torch.Size([30]) type: torch.LongTensor\n",
      "tensor(1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x1ec88068a60>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test set 확인\n",
    "for (test_data,test_label) in test_loader:\n",
    "    print(\"X_valid : \",test_data.size(),'type:',test_data.type())\n",
    "    print(\"Y_valid : \",test_label.size(),'type:',test_label.type())\n",
    "    break\n",
    "\n",
    "print(Y_valid[0])\n",
    "librosa.display.specshow(test_data[0][0].numpy().T, sr=50000, x_axis='time')\n",
    "#batch: 32 / 3채널 / frame수: 500  /  feature수: 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec40ea4",
   "metadata": {},
   "source": [
    "# RESNET18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e1d59a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 \n",
    "# pretrained\n",
    "\n",
    "\n",
    "def model_initialize():\n",
    "    model = models.resnet18(pretrained=True).cuda()\n",
    "    model.ftrs = model.fc.in_features # in_features : fully connected의 입력수.\n",
    "    num_ftrs = model.fc.in_features\n",
    "\n",
    "    model.fc = nn.Sequential(nn.Linear(num_ftrs, 256),\n",
    "                             nn.BatchNorm1d(256),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(256,128),\n",
    "                             nn.BatchNorm1d(128),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(128,64),\n",
    "                             nn.BatchNorm1d(64),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(64,50),\n",
    "                             nn.BatchNorm1d(50),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(50,2)\n",
    "                            )\n",
    "\n",
    "    model = model.cuda()\n",
    "    return model\n",
    "model=model_initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c26ff30a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.5, inplace=False)\n",
      "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.5, inplace=False)\n",
      "    (12): Linear(in_features=64, out_features=50, bias=True)\n",
      "    (13): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU()\n",
      "    (15): Dropout(p=0.5, inplace=False)\n",
      "    (16): Linear(in_features=50, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6097d312",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 200, 7]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 200, 7]             128\n",
      "              ReLU-3           [-1, 64, 200, 7]               0\n",
      "         MaxPool2d-4           [-1, 64, 100, 4]               0\n",
      "            Conv2d-5           [-1, 64, 100, 4]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 100, 4]             128\n",
      "              ReLU-7           [-1, 64, 100, 4]               0\n",
      "            Conv2d-8           [-1, 64, 100, 4]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 100, 4]             128\n",
      "             ReLU-10           [-1, 64, 100, 4]               0\n",
      "       BasicBlock-11           [-1, 64, 100, 4]               0\n",
      "           Conv2d-12           [-1, 64, 100, 4]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 100, 4]             128\n",
      "             ReLU-14           [-1, 64, 100, 4]               0\n",
      "           Conv2d-15           [-1, 64, 100, 4]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 100, 4]             128\n",
      "             ReLU-17           [-1, 64, 100, 4]               0\n",
      "       BasicBlock-18           [-1, 64, 100, 4]               0\n",
      "           Conv2d-19           [-1, 128, 50, 2]          73,728\n",
      "      BatchNorm2d-20           [-1, 128, 50, 2]             256\n",
      "             ReLU-21           [-1, 128, 50, 2]               0\n",
      "           Conv2d-22           [-1, 128, 50, 2]         147,456\n",
      "      BatchNorm2d-23           [-1, 128, 50, 2]             256\n",
      "           Conv2d-24           [-1, 128, 50, 2]           8,192\n",
      "      BatchNorm2d-25           [-1, 128, 50, 2]             256\n",
      "             ReLU-26           [-1, 128, 50, 2]               0\n",
      "       BasicBlock-27           [-1, 128, 50, 2]               0\n",
      "           Conv2d-28           [-1, 128, 50, 2]         147,456\n",
      "      BatchNorm2d-29           [-1, 128, 50, 2]             256\n",
      "             ReLU-30           [-1, 128, 50, 2]               0\n",
      "           Conv2d-31           [-1, 128, 50, 2]         147,456\n",
      "      BatchNorm2d-32           [-1, 128, 50, 2]             256\n",
      "             ReLU-33           [-1, 128, 50, 2]               0\n",
      "       BasicBlock-34           [-1, 128, 50, 2]               0\n",
      "           Conv2d-35           [-1, 256, 25, 1]         294,912\n",
      "      BatchNorm2d-36           [-1, 256, 25, 1]             512\n",
      "             ReLU-37           [-1, 256, 25, 1]               0\n",
      "           Conv2d-38           [-1, 256, 25, 1]         589,824\n",
      "      BatchNorm2d-39           [-1, 256, 25, 1]             512\n",
      "           Conv2d-40           [-1, 256, 25, 1]          32,768\n",
      "      BatchNorm2d-41           [-1, 256, 25, 1]             512\n",
      "             ReLU-42           [-1, 256, 25, 1]               0\n",
      "       BasicBlock-43           [-1, 256, 25, 1]               0\n",
      "           Conv2d-44           [-1, 256, 25, 1]         589,824\n",
      "      BatchNorm2d-45           [-1, 256, 25, 1]             512\n",
      "             ReLU-46           [-1, 256, 25, 1]               0\n",
      "           Conv2d-47           [-1, 256, 25, 1]         589,824\n",
      "      BatchNorm2d-48           [-1, 256, 25, 1]             512\n",
      "             ReLU-49           [-1, 256, 25, 1]               0\n",
      "       BasicBlock-50           [-1, 256, 25, 1]               0\n",
      "           Conv2d-51           [-1, 512, 13, 1]       1,179,648\n",
      "      BatchNorm2d-52           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-53           [-1, 512, 13, 1]               0\n",
      "           Conv2d-54           [-1, 512, 13, 1]       2,359,296\n",
      "      BatchNorm2d-55           [-1, 512, 13, 1]           1,024\n",
      "           Conv2d-56           [-1, 512, 13, 1]         131,072\n",
      "      BatchNorm2d-57           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-58           [-1, 512, 13, 1]               0\n",
      "       BasicBlock-59           [-1, 512, 13, 1]               0\n",
      "           Conv2d-60           [-1, 512, 13, 1]       2,359,296\n",
      "      BatchNorm2d-61           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-62           [-1, 512, 13, 1]               0\n",
      "           Conv2d-63           [-1, 512, 13, 1]       2,359,296\n",
      "      BatchNorm2d-64           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-65           [-1, 512, 13, 1]               0\n",
      "       BasicBlock-66           [-1, 512, 13, 1]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                  [-1, 256]         131,328\n",
      "      BatchNorm1d-69                  [-1, 256]             512\n",
      "             ReLU-70                  [-1, 256]               0\n",
      "          Dropout-71                  [-1, 256]               0\n",
      "           Linear-72                  [-1, 128]          32,896\n",
      "      BatchNorm1d-73                  [-1, 128]             256\n",
      "             ReLU-74                  [-1, 128]               0\n",
      "          Dropout-75                  [-1, 128]               0\n",
      "           Linear-76                   [-1, 64]           8,256\n",
      "      BatchNorm1d-77                   [-1, 64]             128\n",
      "             ReLU-78                   [-1, 64]               0\n",
      "          Dropout-79                   [-1, 64]               0\n",
      "           Linear-80                   [-1, 50]           3,250\n",
      "      BatchNorm1d-81                   [-1, 50]             100\n",
      "             ReLU-82                   [-1, 50]               0\n",
      "          Dropout-83                   [-1, 50]               0\n",
      "           Linear-84                    [-1, 2]             102\n",
      "================================================================\n",
      "Total params: 11,353,340\n",
      "Trainable params: 11,353,340\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 8.16\n",
      "Params size (MB): 43.31\n",
      "Estimated Total Size (MB): 51.52\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# get the model summary\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 400, 13), device=DEVICE.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f2ca15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. 학습\n",
    "def train(model,train_loader,optimizer, log_interval):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    train_loss = 0\n",
    "    for batch_idx,(image,label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        #데이터들 장비에 할당\n",
    "        optimizer.zero_grad() # device 에 저장된 gradient 제거\n",
    "        output = model(image) # model로 output을 계산\n",
    "        loss = criterion(output, label) #loss 계산\n",
    "        train_loss += loss.item()\n",
    "        prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "        correct += prediction.eq(label.view_as(prediction)).sum().item()# 아웃풋이 배치 사이즈 32개라서.\n",
    "        loss.backward() # loss 값을 이용해 gradient를 계산\n",
    "        optimizer.step() # Gradient 값을 이용해 파라미터 업데이트.\n",
    "    train_loss/=len(train_loader.dataset)\n",
    "    train_accuracy = 100. * correct / len(train_loader.dataset)\n",
    "    return train_loss,train_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b09341bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. 학습 진행하며, validation 데이터로 모델 성능확인\n",
    "def evaluate(model,valid_loader):\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    #no_grad : 그래디언트 값 계산 막기.\n",
    "    with torch.no_grad():\n",
    "        for image, label in valid_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            valid_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()# 아웃풋이 배치 사이즈 32개라서.\n",
    "            #true.false값을 sum해줌. item\n",
    "        valid_loss /= len(valid_loader.dataset)\n",
    "        valid_accuracy = 100. * correct / len(valid_loader.dataset)\n",
    "        return valid_loss,valid_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae179080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 로더 제작 함수\n",
    "\n",
    "def load_data(data_ind):\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_dataset(\n",
    "                                                   X_train_list,\n",
    "                                                   classes,\n",
    "                                                   transform = transforms.ToTensor(),#이걸 composed로 고쳐서 전처리 하도록 수정.\n",
    "                                                   data_num=data_ind,\n",
    "                                                   training=True\n",
    "                                               ),\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = True,\n",
    "                                               ) # 순서가 암기되는것을 막기위해.\n",
    "\n",
    "    validation_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_dataset(\n",
    "                                                   X_valid_list,\n",
    "                                                   classes,\n",
    "                                                   transform = transforms.ToTensor(),\n",
    "                                                   data_num=data_ind,\n",
    "                                                   training=False\n",
    "                                               ),\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = True,) \n",
    "    \n",
    "    return train_loader,validation_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7c8c86f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0260\t Train Acc:52.13 %  | \tValid Loss:0.0235 \tValid Acc: 51.17 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.023514).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0260\t Train Acc:50.43 %  | \tValid Loss:0.0232 \tValid Acc: 55.61 %\n",
      "\n",
      "Validation loss decreased (0.023514 --> 0.023165).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0246\t Train Acc:52.45 %  | \tValid Loss:0.0231 \tValid Acc: 56.14 %\n",
      "\n",
      "Validation loss decreased (0.023165 --> 0.023135).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0243\t Train Acc:51.80 %  | \tValid Loss:0.0231 \tValid Acc: 57.96 %\n",
      "\n",
      "Validation loss decreased (0.023135 --> 0.023060).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0240\t Train Acc:51.93 %  | \tValid Loss:0.0223 \tValid Acc: 61.10 %\n",
      "\n",
      "Validation loss decreased (0.023060 --> 0.022343).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0226\t Train Acc:56.90 %  | \tValid Loss:0.0217 \tValid Acc: 66.58 %\n",
      "\n",
      "Validation loss decreased (0.022343 --> 0.021721).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0222\t Train Acc:59.45 %  | \tValid Loss:0.0217 \tValid Acc: 62.14 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0222\t Train Acc:59.58 %  | \tValid Loss:0.0210 \tValid Acc: 69.19 %\n",
      "\n",
      "Validation loss decreased (0.021721 --> 0.021012).  Saving model ...\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0217\t Train Acc:60.56 %  | \tValid Loss:0.0215 \tValid Acc: 63.45 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0209\t Train Acc:63.51 %  | \tValid Loss:0.0211 \tValid Acc: 67.10 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0205\t Train Acc:65.66 %  | \tValid Loss:0.0213 \tValid Acc: 64.75 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0198\t Train Acc:67.95 %  | \tValid Loss:0.0211 \tValid Acc: 63.45 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0194\t Train Acc:68.28 %  | \tValid Loss:0.0205 \tValid Acc: 67.62 %\n",
      "\n",
      "Validation loss decreased (0.021012 --> 0.020491).  Saving model ...\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0192\t Train Acc:69.06 %  | \tValid Loss:0.0196 \tValid Acc: 67.89 %\n",
      "\n",
      "Validation loss decreased (0.020491 --> 0.019641).  Saving model ...\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0181\t Train Acc:73.25 %  | \tValid Loss:0.0203 \tValid Acc: 65.27 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0174\t Train Acc:76.06 %  | \tValid Loss:0.0200 \tValid Acc: 70.76 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0178\t Train Acc:75.15 %  | \tValid Loss:0.0206 \tValid Acc: 64.49 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0171\t Train Acc:76.06 %  | \tValid Loss:0.0190 \tValid Acc: 73.11 %\n",
      "\n",
      "Validation loss decreased (0.019641 --> 0.019047).  Saving model ...\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0161\t Train Acc:79.07 %  | \tValid Loss:0.0187 \tValid Acc: 70.76 %\n",
      "\n",
      "Validation loss decreased (0.019047 --> 0.018727).  Saving model ...\n",
      "\n",
      "[EPOCH:20]\t Train Loss:0.0155\t Train Acc:80.25 %  | \tValid Loss:0.0182 \tValid Acc: 73.89 %\n",
      "\n",
      "Validation loss decreased (0.018727 --> 0.018231).  Saving model ...\n",
      "\n",
      "[EPOCH:21]\t Train Loss:0.0145\t Train Acc:82.15 %  | \tValid Loss:0.0180 \tValid Acc: 77.28 %\n",
      "\n",
      "Validation loss decreased (0.018231 --> 0.017964).  Saving model ...\n",
      "\n",
      "[EPOCH:22]\t Train Loss:0.0138\t Train Acc:84.11 %  | \tValid Loss:0.0199 \tValid Acc: 69.45 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:23]\t Train Loss:0.0131\t Train Acc:85.55 %  | \tValid Loss:0.0172 \tValid Acc: 77.28 %\n",
      "\n",
      "Validation loss decreased (0.017964 --> 0.017150).  Saving model ...\n",
      "\n",
      "[EPOCH:24]\t Train Loss:0.0132\t Train Acc:85.09 %  | \tValid Loss:0.0189 \tValid Acc: 72.06 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:25]\t Train Loss:0.0137\t Train Acc:83.52 %  | \tValid Loss:0.0195 \tValid Acc: 72.06 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:26]\t Train Loss:0.0110\t Train Acc:89.14 %  | \tValid Loss:0.0177 \tValid Acc: 76.76 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:27]\t Train Loss:0.0101\t Train Acc:90.84 %  | \tValid Loss:0.0184 \tValid Acc: 73.63 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:28]\t Train Loss:0.0095\t Train Acc:91.43 %  | \tValid Loss:0.0173 \tValid Acc: 75.72 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[1 교차검증] Early stopping\n",
      "[2 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0255\t Train Acc:51.34 %  | \tValid Loss:0.0234 \tValid Acc: 51.17 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.023417).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0254\t Train Acc:50.10 %  | \tValid Loss:0.0233 \tValid Acc: 55.09 %\n",
      "\n",
      "Validation loss decreased (0.023417 --> 0.023339).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0257\t Train Acc:49.90 %  | \tValid Loss:0.0231 \tValid Acc: 57.96 %\n",
      "\n",
      "Validation loss decreased (0.023339 --> 0.023141).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0245\t Train Acc:54.41 %  | \tValid Loss:0.0234 \tValid Acc: 54.31 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0249\t Train Acc:50.82 %  | \tValid Loss:0.0232 \tValid Acc: 55.09 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0246\t Train Acc:51.93 %  | \tValid Loss:0.0233 \tValid Acc: 59.79 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0239\t Train Acc:54.09 %  | \tValid Loss:0.0228 \tValid Acc: 56.40 %\n",
      "\n",
      "Validation loss decreased (0.023141 --> 0.022815).  Saving model ...\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0241\t Train Acc:52.71 %  | \tValid Loss:0.0227 \tValid Acc: 58.49 %\n",
      "\n",
      "Validation loss decreased (0.022815 --> 0.022696).  Saving model ...\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0236\t Train Acc:55.40 %  | \tValid Loss:0.0227 \tValid Acc: 56.14 %\n",
      "\n",
      "Validation loss decreased (0.022696 --> 0.022692).  Saving model ...\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0234\t Train Acc:54.35 %  | \tValid Loss:0.0225 \tValid Acc: 57.96 %\n",
      "\n",
      "Validation loss decreased (0.022692 --> 0.022458).  Saving model ...\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0232\t Train Acc:56.90 %  | \tValid Loss:0.0223 \tValid Acc: 57.70 %\n",
      "\n",
      "Validation loss decreased (0.022458 --> 0.022264).  Saving model ...\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0226\t Train Acc:58.08 %  | \tValid Loss:0.0221 \tValid Acc: 64.49 %\n",
      "\n",
      "Validation loss decreased (0.022264 --> 0.022148).  Saving model ...\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0226\t Train Acc:57.75 %  | \tValid Loss:0.0216 \tValid Acc: 61.10 %\n",
      "\n",
      "Validation loss decreased (0.022148 --> 0.021629).  Saving model ...\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0217\t Train Acc:59.91 %  | \tValid Loss:0.0212 \tValid Acc: 65.01 %\n",
      "\n",
      "Validation loss decreased (0.021629 --> 0.021171).  Saving model ...\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0220\t Train Acc:58.67 %  | \tValid Loss:0.0215 \tValid Acc: 62.14 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0218\t Train Acc:60.24 %  | \tValid Loss:0.0212 \tValid Acc: 63.97 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0207\t Train Acc:64.42 %  | \tValid Loss:0.0206 \tValid Acc: 66.06 %\n",
      "\n",
      "Validation loss decreased (0.021171 --> 0.020608).  Saving model ...\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0202\t Train Acc:67.30 %  | \tValid Loss:0.0204 \tValid Acc: 68.93 %\n",
      "\n",
      "Validation loss decreased (0.020608 --> 0.020357).  Saving model ...\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0203\t Train Acc:66.97 %  | \tValid Loss:0.0199 \tValid Acc: 66.84 %\n",
      "\n",
      "Validation loss decreased (0.020357 --> 0.019922).  Saving model ...\n",
      "\n",
      "[EPOCH:20]\t Train Loss:0.0187\t Train Acc:69.78 %  | \tValid Loss:0.0197 \tValid Acc: 66.32 %\n",
      "\n",
      "Validation loss decreased (0.019922 --> 0.019707).  Saving model ...\n",
      "\n",
      "[EPOCH:21]\t Train Loss:0.0184\t Train Acc:72.53 %  | \tValid Loss:0.0192 \tValid Acc: 71.54 %\n",
      "\n",
      "Validation loss decreased (0.019707 --> 0.019243).  Saving model ...\n",
      "\n",
      "[EPOCH:22]\t Train Loss:0.0177\t Train Acc:72.92 %  | \tValid Loss:0.0190 \tValid Acc: 68.67 %\n",
      "\n",
      "Validation loss decreased (0.019243 --> 0.018979).  Saving model ...\n",
      "\n",
      "[EPOCH:23]\t Train Loss:0.0166\t Train Acc:75.93 %  | \tValid Loss:0.0185 \tValid Acc: 72.06 %\n",
      "\n",
      "Validation loss decreased (0.018979 --> 0.018498).  Saving model ...\n",
      "\n",
      "[EPOCH:24]\t Train Loss:0.0162\t Train Acc:77.57 %  | \tValid Loss:0.0194 \tValid Acc: 70.23 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:25]\t Train Loss:0.0158\t Train Acc:79.79 %  | \tValid Loss:0.0184 \tValid Acc: 72.32 %\n",
      "\n",
      "Validation loss decreased (0.018498 --> 0.018405).  Saving model ...\n",
      "\n",
      "[EPOCH:26]\t Train Loss:0.0147\t Train Acc:80.64 %  | \tValid Loss:0.0207 \tValid Acc: 68.41 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:27]\t Train Loss:0.0140\t Train Acc:83.39 %  | \tValid Loss:0.0191 \tValid Acc: 73.63 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:28]\t Train Loss:0.0132\t Train Acc:83.78 %  | \tValid Loss:0.0202 \tValid Acc: 67.10 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH:29]\t Train Loss:0.0136\t Train Acc:84.04 %  | \tValid Loss:0.0195 \tValid Acc: 71.54 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:30]\t Train Loss:0.0126\t Train Acc:84.37 %  | \tValid Loss:0.0182 \tValid Acc: 73.89 %\n",
      "\n",
      "Validation loss decreased (0.018405 --> 0.018151).  Saving model ...\n",
      "\n",
      "[EPOCH:31]\t Train Loss:0.0113\t Train Acc:87.25 %  | \tValid Loss:0.0168 \tValid Acc: 77.28 %\n",
      "\n",
      "Validation loss decreased (0.018151 --> 0.016766).  Saving model ...\n",
      "\n",
      "[EPOCH:32]\t Train Loss:0.0098\t Train Acc:90.97 %  | \tValid Loss:0.0180 \tValid Acc: 73.37 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:33]\t Train Loss:0.0090\t Train Acc:92.87 %  | \tValid Loss:0.0185 \tValid Acc: 74.67 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:34]\t Train Loss:0.0088\t Train Acc:91.96 %  | \tValid Loss:0.0163 \tValid Acc: 77.55 %\n",
      "\n",
      "Validation loss decreased (0.016766 --> 0.016289).  Saving model ...\n",
      "\n",
      "[EPOCH:35]\t Train Loss:0.0073\t Train Acc:94.57 %  | \tValid Loss:0.0178 \tValid Acc: 77.81 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:36]\t Train Loss:0.0077\t Train Acc:94.24 %  | \tValid Loss:0.0184 \tValid Acc: 75.20 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:37]\t Train Loss:0.0070\t Train Acc:94.64 %  | \tValid Loss:0.0184 \tValid Acc: 76.50 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:38]\t Train Loss:0.0057\t Train Acc:97.12 %  | \tValid Loss:0.0165 \tValid Acc: 79.37 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:39]\t Train Loss:0.0058\t Train Acc:96.21 %  | \tValid Loss:0.0169 \tValid Acc: 81.20 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[2 교차검증] Early stopping\n",
      "[3 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0249\t Train Acc:52.03 %  | \tValid Loss:0.0230 \tValid Acc: 57.33 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.022974).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0245\t Train Acc:51.70 %  | \tValid Loss:0.0226 \tValid Acc: 61.52 %\n",
      "\n",
      "Validation loss decreased (0.022974 --> 0.022557).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0243\t Train Acc:52.68 %  | \tValid Loss:0.0224 \tValid Acc: 62.30 %\n",
      "\n",
      "Validation loss decreased (0.022557 --> 0.022367).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0234\t Train Acc:56.47 %  | \tValid Loss:0.0220 \tValid Acc: 60.99 %\n",
      "\n",
      "Validation loss decreased (0.022367 --> 0.022020).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0232\t Train Acc:56.54 %  | \tValid Loss:0.0223 \tValid Acc: 61.78 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0231\t Train Acc:57.12 %  | \tValid Loss:0.0223 \tValid Acc: 61.78 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0224\t Train Acc:59.35 %  | \tValid Loss:0.0213 \tValid Acc: 62.83 %\n",
      "\n",
      "Validation loss decreased (0.022020 --> 0.021320).  Saving model ...\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0217\t Train Acc:62.29 %  | \tValid Loss:0.0212 \tValid Acc: 68.32 %\n",
      "\n",
      "Validation loss decreased (0.021320 --> 0.021192).  Saving model ...\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0210\t Train Acc:64.05 %  | \tValid Loss:0.0206 \tValid Acc: 68.32 %\n",
      "\n",
      "Validation loss decreased (0.021192 --> 0.020594).  Saving model ...\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0207\t Train Acc:65.03 %  | \tValid Loss:0.0209 \tValid Acc: 67.28 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0202\t Train Acc:66.99 %  | \tValid Loss:0.0201 \tValid Acc: 68.32 %\n",
      "\n",
      "Validation loss decreased (0.020594 --> 0.020056).  Saving model ...\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0194\t Train Acc:69.67 %  | \tValid Loss:0.0206 \tValid Acc: 65.97 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0188\t Train Acc:70.33 %  | \tValid Loss:0.0201 \tValid Acc: 68.85 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0181\t Train Acc:74.12 %  | \tValid Loss:0.0206 \tValid Acc: 65.97 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0174\t Train Acc:75.49 %  | \tValid Loss:0.0224 \tValid Acc: 64.14 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0166\t Train Acc:77.65 %  | \tValid Loss:0.0186 \tValid Acc: 74.35 %\n",
      "\n",
      "Validation loss decreased (0.020056 --> 0.018564).  Saving model ...\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0157\t Train Acc:80.98 %  | \tValid Loss:0.0196 \tValid Acc: 72.77 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0139\t Train Acc:83.66 %  | \tValid Loss:0.0192 \tValid Acc: 73.82 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0134\t Train Acc:85.36 %  | \tValid Loss:0.0188 \tValid Acc: 72.77 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:20]\t Train Loss:0.0132\t Train Acc:85.88 %  | \tValid Loss:0.0187 \tValid Acc: 73.04 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:21]\t Train Loss:0.0114\t Train Acc:88.37 %  | \tValid Loss:0.0176 \tValid Acc: 75.65 %\n",
      "\n",
      "Validation loss decreased (0.018564 --> 0.017575).  Saving model ...\n",
      "\n",
      "[EPOCH:22]\t Train Loss:0.0101\t Train Acc:91.83 %  | \tValid Loss:0.0174 \tValid Acc: 76.96 %\n",
      "\n",
      "Validation loss decreased (0.017575 --> 0.017432).  Saving model ...\n",
      "\n",
      "[EPOCH:23]\t Train Loss:0.0104\t Train Acc:90.46 %  | \tValid Loss:0.0184 \tValid Acc: 75.13 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:24]\t Train Loss:0.0110\t Train Acc:89.08 %  | \tValid Loss:0.0211 \tValid Acc: 70.94 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:25]\t Train Loss:0.0094\t Train Acc:91.44 %  | \tValid Loss:0.0203 \tValid Acc: 73.82 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:26]\t Train Loss:0.0086\t Train Acc:93.01 %  | \tValid Loss:0.0187 \tValid Acc: 72.51 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:27]\t Train Loss:0.0082\t Train Acc:93.73 %  | \tValid Loss:0.0193 \tValid Acc: 74.35 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[3 교차검증] Early stopping\n",
      "[4 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0254\t Train Acc:51.70 %  | \tValid Loss:0.0231 \tValid Acc: 56.02 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.023123).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0242\t Train Acc:53.59 %  | \tValid Loss:0.0225 \tValid Acc: 60.21 %\n",
      "\n",
      "Validation loss decreased (0.023123 --> 0.022520).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0235\t Train Acc:54.77 %  | \tValid Loss:0.0220 \tValid Acc: 64.66 %\n",
      "\n",
      "Validation loss decreased (0.022520 --> 0.021960).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0237\t Train Acc:53.33 %  | \tValid Loss:0.0221 \tValid Acc: 59.69 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0235\t Train Acc:53.53 %  | \tValid Loss:0.0222 \tValid Acc: 60.73 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0232\t Train Acc:56.73 %  | \tValid Loss:0.0212 \tValid Acc: 62.30 %\n",
      "\n",
      "Validation loss decreased (0.021960 --> 0.021214).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0234\t Train Acc:56.14 %  | \tValid Loss:0.0215 \tValid Acc: 61.52 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0227\t Train Acc:58.10 %  | \tValid Loss:0.0222 \tValid Acc: 58.12 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0227\t Train Acc:58.37 %  | \tValid Loss:0.0219 \tValid Acc: 62.57 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0220\t Train Acc:60.65 %  | \tValid Loss:0.0212 \tValid Acc: 65.97 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0217\t Train Acc:60.98 %  | \tValid Loss:0.0212 \tValid Acc: 65.97 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[4 교차검증] Early stopping\n",
      "[5 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0252\t Train Acc:50.72 %  | \tValid Loss:0.0234 \tValid Acc: 58.12 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.023361).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0247\t Train Acc:51.31 %  | \tValid Loss:0.0225 \tValid Acc: 60.99 %\n",
      "\n",
      "Validation loss decreased (0.023361 --> 0.022519).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0244\t Train Acc:51.31 %  | \tValid Loss:0.0222 \tValid Acc: 61.26 %\n",
      "\n",
      "Validation loss decreased (0.022519 --> 0.022174).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0239\t Train Acc:52.61 %  | \tValid Loss:0.0228 \tValid Acc: 57.59 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0238\t Train Acc:54.51 %  | \tValid Loss:0.0229 \tValid Acc: 59.69 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0230\t Train Acc:56.41 %  | \tValid Loss:0.0226 \tValid Acc: 62.83 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0234\t Train Acc:57.52 %  | \tValid Loss:0.0223 \tValid Acc: 60.99 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0228\t Train Acc:56.41 %  | \tValid Loss:0.0226 \tValid Acc: 56.81 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[5 교차검증] Early stopping\n"
     ]
    }
   ],
   "source": [
    "#10. 학습 및 평가.\n",
    "# resnet34 pretrained true\n",
    "# kfold 적용\n",
    "\n",
    "train_accs = []\n",
    "valid_accs = []\n",
    "\n",
    "for data_ind in range(1,6):\n",
    "\n",
    "    check_path = '../checkpoint/checkpoint_resnet18_true_'+str(data_ind)+'_u.pt'\n",
    "\n",
    "    early_stopping = EarlyStopping(patience = 5, verbose = True, path=check_path)\n",
    "    train_loader,validation_loader = load_data(data_ind-1)\n",
    "    \n",
    "    best_train_acc=0 # accuracy 기록용\n",
    "    best_valid_acc=0\n",
    "    \n",
    "    model=model_initialize()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "    \n",
    "    \n",
    "    print(\"[{} 교차검증] 학습 시작\\n ----- \".format(data_ind))\n",
    "    for Epoch in range(1,EPOCHS+1):\n",
    "        train_loss,train_accuracy=train(model,train_loader,optimizer,log_interval=31)\n",
    "        valid_loss,valid_accuracy = evaluate(model, validation_loader)\n",
    "\n",
    "\n",
    "        print(\"\\n[EPOCH:{}]\\t Train Loss:{:.4f}\\t Train Acc:{:.2f} %  | \\tValid Loss:{:.4f} \\tValid Acc: {:.2f} %\\n\".\n",
    "              format(Epoch,train_loss,train_accuracy,valid_loss,valid_accuracy))\n",
    "\n",
    "        early_stopping(valid_loss, model)\n",
    "        if -early_stopping.best_score == valid_loss:\n",
    "            best_train_acc, best_valid_acc = train_accuracy,valid_accuracy\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "                train_accs.append(best_train_acc)\n",
    "                valid_accs.append(best_valid_acc)\n",
    "                print(\"[{} 교차검증] Early stopping\".format(data_ind))\n",
    "                break\n",
    "\n",
    "        if Epoch==EPOCHS:\n",
    "            #만약 early stop 없이 40 epoch라서 중지 된 경우.\n",
    "            train_accs.append(best_train_acc)\n",
    "            valid_accs.append(best_valid_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6767ec8",
   "metadata": {},
   "source": [
    "# 모델 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6824ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 교차검증] train ACC : 85.5461 |\t valid ACC: 77.2846 \n",
      "[2 교차검증] train ACC : 91.9555 |\t valid ACC: 77.5457 \n",
      "[3 교차검증] train ACC : 91.8301 |\t valid ACC: 76.9634 \n",
      "[4 교차검증] train ACC : 56.7320 |\t valid ACC: 62.3037 \n",
      "[5 교차검증] train ACC : 51.3072 |\t valid ACC: 61.2565 \n",
      "평균 검증 정확도 71.0707694831381 %\n"
     ]
    }
   ],
   "source": [
    "sum_valid=0\n",
    "for data_ind in range(5):\n",
    "    print(\"[{} 교차검증] train ACC : {:.4f} |\\t valid ACC: {:.4f} \".format(data_ind+1,train_accs[data_ind],valid_accs[data_ind] ))\n",
    "    sum_valid+=valid_accs[data_ind]\n",
    "    \n",
    "print(\"평균 검증 정확도\",sum_valid/5,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0967cf",
   "metadata": {},
   "source": [
    "# Model Test\n",
    "\n",
    "- test set\n",
    "- confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a19235bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix 계산\n",
    "#test set 계산.\n",
    "def test_evaluate(model,test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    predictions = []\n",
    "    answers = []\n",
    "    #no_grad : 그래디언트 값 계산 막기.\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "            answers +=label\n",
    "            predictions +=prediction\n",
    "            \n",
    "        return predictions,answers,test_loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca2e1ed2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번 모델\n",
      "Accuracy : 67.1088% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.7778\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.6736\n",
      "f score : 0.7220 \n",
      "[[161  78]\n",
      " [ 46  92]]\n",
      "-----\n",
      "2번 모델\n",
      "Accuracy : 64.7215% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.7325\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.6987\n",
      "f score : 0.7152 \n",
      "[[167  72]\n",
      " [ 61  77]]\n",
      "-----\n",
      "3번 모델\n",
      "Accuracy : 62.3342% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.7215\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.6611\n",
      "f score : 0.6900 \n",
      "[[158  81]\n",
      " [ 61  77]]\n",
      "-----\n",
      "4번 모델\n",
      "Accuracy : 63.6605% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.6977\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.7531\n",
      "f score : 0.7243 \n",
      "[[180  59]\n",
      " [ 78  60]]\n",
      "-----\n",
      "5번 모델\n",
      "Accuracy : 65.7825% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.7022\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.7992\n",
      "f score : 0.7476 \n",
      "[[191  48]\n",
      " [ 81  57]]\n",
      "-----\n",
      "평균 acc : 0.6472\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Confusion matrix (resnet18)\n",
    "# kfold의 confusion matrix는 계산 방법이 다르다.\n",
    "# 모델을 각각 불러와서 test set을 평가한다.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf = np.zeros((2,2))\n",
    "cf_list = []\n",
    "average_accuracy = 0\n",
    "\n",
    "for data_ind in range(1,6):\n",
    "\n",
    "    check_path = '../checkpoint/checkpoint_resnet18_true_'+str(data_ind)+'_u.pt'\n",
    "    model.load_state_dict(torch.load(check_path))\n",
    "\n",
    "    predictions,answers,test_loss = test_evaluate(model, test_loader)\n",
    "    predictions=[ dat.cpu().numpy() for dat in predictions]\n",
    "    answers=[ dat.cpu().numpy() for dat in answers]\n",
    "\n",
    "    \n",
    "    cf = confusion_matrix(answers, predictions)\n",
    "    cf_list.append(cf)\n",
    "    \n",
    "    acc = (cf[0,0]+cf[1,1])/(cf[0,0]+cf[0,1]+cf[1,0]+cf[1,1])\n",
    "    average_accuracy+=acc\n",
    "    precision=cf[0,0]/(cf[0,0]+cf[1,0])\n",
    "    recall=cf[0,0]/(cf[0,0]+cf[0,1])\n",
    "    fscore=2*precision*recall/(precision+recall)\n",
    "    print('{}번 모델'.format(data_ind))\n",
    "    print(\"Accuracy : {:.4f}% \".format(acc*100))\n",
    "    print(\"Precision (pathology 예측한 것중 맞는 것) : {:.4f}\".format(precision))\n",
    "    print(\"recall (실제 pathology 중  예측이 맞는 것) : {:.4f}\".format(recall))\n",
    "    print(\"f score : {:.4f} \".format(fscore))\n",
    "    print(cf)\n",
    "    print(\"-----\")\n",
    "\n",
    "print(\"평균 acc : {:.4f}\".format(average_accuracy/5))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "455.111px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
