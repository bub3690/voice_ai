{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37664ece",
   "metadata": {},
   "source": [
    "- http://keunwoochoi.blogspot.com/2016/03/2.html\n",
    "- http://www.rex-ai.info/docs/AI_Example_CNN_speech_recognize\n",
    "- https://www.youtube.com/watch?v=oltGIc4uo5c\n",
    "- https://youdaeng-com.tistory.com/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "275b8092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pytorch version :  1.10.0  Device :  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn # 인공 신경망 모델들 모아놓은 모듈\n",
    "import torch.nn.functional as F #그중 자주 쓰이는것들을 F로\n",
    "from torchvision import transforms, datasets\n",
    "import cv2\n",
    "from torchvision import transforms, datasets\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "p = os.path.abspath('..') # 상위 폴더를 사용하기 위해서.\n",
    "sys.path.insert(1, p)\n",
    "from pytorchtools.pytorchtools import EarlyStopping # 현재 폴더에 추가된 모듈.\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "#DEVICE = torch.device('cpu')\n",
    "print('Using Pytorch version : ',torch.__version__,' Device : ',DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ebea6",
   "metadata": {},
   "source": [
    "# SVD 문장 데이터에서 Feature 추출\n",
    "- mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "114a1b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa, librosa.display \n",
    "import matplotlib.pyplot as plt\n",
    "#window sizde : FFT를 할때 참조할 그래프 길이 ( 프레임 하나당 sample 수 )\n",
    "#자연어 처리에서는 25ms 사용. https://ahnjg.tistory.com/93\n",
    "#초당 50000hz 중 1250개씩 윈도우 사이즈로 사용.\n",
    "sr=50000\n",
    "win_length =  np.int64(50000/40) # 1250\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c72d82e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pathology data 수 :  1194\n",
      "healthy data 수 :  687\n",
      "가장 긴 path sample : 131655\n",
      "가장 긴 healthy sample : 219501\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa, librosa.display \n",
    "import matplotlib.pyplot as plt\n",
    "#window sizde : FFT를 할때 참조할 그래프 길이 ( 프레임 하나당 sample 수 )\n",
    "#자연어 처리에서는 25ms 사용. https://ahnjg.tistory.com/93\n",
    "#초당 50000hz 중 1250개씩 윈도우 사이즈로 사용.\n",
    "sr=50000\n",
    "win_length =  np.int64(50000/40) # 1250\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다.\n",
    "\n",
    "pathology_sig=[]\n",
    "healthy_sig=[]\n",
    "\n",
    "pathology=[]\n",
    "healthy=[]\n",
    "\n",
    "\n",
    "#PATHOLOGY DATA\n",
    "for audio_path in os.listdir('../../voice_data/pathology_new/a/export'):\n",
    "    sig, sr = librosa.load('../../voice_data/pathology_new/a/export/'+audio_path, sr=50000)# 논문에서 f_s = 50 000HZ\n",
    "    pathology_sig.append(sig)\n",
    "    MFCCs = librosa.feature.mfcc(sig, sr, win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "    pathology.append(MFCCs)\n",
    "    \n",
    "\n",
    "#Healthy data\n",
    "for audio_path in os.listdir('../../voice_data/healthy_new/a/export'):\n",
    "    sig, sr = librosa.load('../../voice_data/healthy_new/a/export/'+audio_path, sr=50000)# 논문에서 f_s = 50 000HZ\n",
    "    healthy_sig.append(sig)\n",
    "    MFCCs = librosa.feature.mfcc(sig, sr, win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "    healthy.append(MFCCs)\n",
    "    \n",
    "print(\"pathology data 수 : \",len(pathology))\n",
    "print(\"healthy data 수 : \",len(healthy))\n",
    "\n",
    "\n",
    "path_max=max([ len(samples) for samples in pathology_sig])\n",
    "healthy_max=max([ len(samples) for samples in healthy_sig])\n",
    "print(\"가장 긴 path sample :\" ,path_max)\n",
    "print(\"가장 긴 healthy sample :\" ,healthy_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "636bede8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6331 초\n",
      "4.39002 초\n"
     ]
    }
   ],
   "source": [
    "print(path_max/sr,\"초\")\n",
    "print(healthy_max/sr,\"초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5915f64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 :  1.2573740201005026\n",
      "평균 :  1.314699767103348\n"
     ]
    }
   ],
   "source": [
    "print('평균 : ',np.mean([ len(samples) for samples in pathology_sig])/sr)\n",
    "print('평균 : ',np.mean([ len(samples) for samples in healthy_sig])/sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91bd1989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.504"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "400*313/sr\n",
    "#400 frame은 약 2.5초 이상."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148ec668",
   "metadata": {},
   "source": [
    "# 결과 확인\n",
    "- 1 row당 1 frame으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a48f3297",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>mfcc5</th>\n",
       "      <th>mfcc6</th>\n",
       "      <th>mfcc7</th>\n",
       "      <th>mfcc8</th>\n",
       "      <th>mfcc9</th>\n",
       "      <th>mfcc10</th>\n",
       "      <th>mfcc11</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-214.176651</td>\n",
       "      <td>207.977264</td>\n",
       "      <td>1.462625</td>\n",
       "      <td>13.944162</td>\n",
       "      <td>-63.319916</td>\n",
       "      <td>-2.144712</td>\n",
       "      <td>-16.828245</td>\n",
       "      <td>-21.429878</td>\n",
       "      <td>7.964348</td>\n",
       "      <td>-0.085761</td>\n",
       "      <td>-1.125562</td>\n",
       "      <td>-21.268238</td>\n",
       "      <td>-16.084270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-222.949982</td>\n",
       "      <td>209.148163</td>\n",
       "      <td>2.133819</td>\n",
       "      <td>17.240515</td>\n",
       "      <td>-52.081551</td>\n",
       "      <td>2.385664</td>\n",
       "      <td>-18.650604</td>\n",
       "      <td>-24.606426</td>\n",
       "      <td>3.663574</td>\n",
       "      <td>-1.903811</td>\n",
       "      <td>-8.280209</td>\n",
       "      <td>-16.000689</td>\n",
       "      <td>-12.138484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-248.733551</td>\n",
       "      <td>195.559235</td>\n",
       "      <td>-2.844307</td>\n",
       "      <td>7.977224</td>\n",
       "      <td>-52.356590</td>\n",
       "      <td>-1.202414</td>\n",
       "      <td>-16.476841</td>\n",
       "      <td>-20.510300</td>\n",
       "      <td>5.527544</td>\n",
       "      <td>-0.318386</td>\n",
       "      <td>-15.725111</td>\n",
       "      <td>-8.803049</td>\n",
       "      <td>-4.176742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-246.802917</td>\n",
       "      <td>198.915344</td>\n",
       "      <td>-3.477466</td>\n",
       "      <td>8.681169</td>\n",
       "      <td>-53.547142</td>\n",
       "      <td>-5.144975</td>\n",
       "      <td>-17.089766</td>\n",
       "      <td>-22.173811</td>\n",
       "      <td>4.114779</td>\n",
       "      <td>-1.155015</td>\n",
       "      <td>-14.204550</td>\n",
       "      <td>-9.640966</td>\n",
       "      <td>-2.181946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-245.827591</td>\n",
       "      <td>200.687988</td>\n",
       "      <td>0.568132</td>\n",
       "      <td>6.174569</td>\n",
       "      <td>-51.041344</td>\n",
       "      <td>-1.792537</td>\n",
       "      <td>-17.918312</td>\n",
       "      <td>-18.034185</td>\n",
       "      <td>5.677939</td>\n",
       "      <td>-2.018642</td>\n",
       "      <td>-12.768702</td>\n",
       "      <td>-11.336535</td>\n",
       "      <td>-1.299195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>-242.007767</td>\n",
       "      <td>200.297760</td>\n",
       "      <td>3.961174</td>\n",
       "      <td>14.153851</td>\n",
       "      <td>-52.725536</td>\n",
       "      <td>7.545429</td>\n",
       "      <td>-5.822221</td>\n",
       "      <td>-22.547153</td>\n",
       "      <td>6.216630</td>\n",
       "      <td>7.461223</td>\n",
       "      <td>-12.434643</td>\n",
       "      <td>-15.016934</td>\n",
       "      <td>12.251122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>-245.131500</td>\n",
       "      <td>196.616119</td>\n",
       "      <td>2.222031</td>\n",
       "      <td>15.436684</td>\n",
       "      <td>-56.961128</td>\n",
       "      <td>6.723224</td>\n",
       "      <td>-5.488671</td>\n",
       "      <td>-19.845875</td>\n",
       "      <td>7.457106</td>\n",
       "      <td>2.931230</td>\n",
       "      <td>-13.481985</td>\n",
       "      <td>-15.816978</td>\n",
       "      <td>13.508206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>-247.851624</td>\n",
       "      <td>198.925278</td>\n",
       "      <td>2.341530</td>\n",
       "      <td>14.167100</td>\n",
       "      <td>-54.980747</td>\n",
       "      <td>11.598038</td>\n",
       "      <td>-2.436407</td>\n",
       "      <td>-18.352262</td>\n",
       "      <td>8.678156</td>\n",
       "      <td>8.914279</td>\n",
       "      <td>-9.958929</td>\n",
       "      <td>-16.050816</td>\n",
       "      <td>15.700717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>-232.978348</td>\n",
       "      <td>215.946442</td>\n",
       "      <td>14.133223</td>\n",
       "      <td>16.482494</td>\n",
       "      <td>-50.424297</td>\n",
       "      <td>13.806274</td>\n",
       "      <td>-4.241011</td>\n",
       "      <td>-16.475407</td>\n",
       "      <td>5.775840</td>\n",
       "      <td>7.153922</td>\n",
       "      <td>-11.623649</td>\n",
       "      <td>-19.136692</td>\n",
       "      <td>15.453394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>-218.726624</td>\n",
       "      <td>225.969635</td>\n",
       "      <td>17.963581</td>\n",
       "      <td>17.724133</td>\n",
       "      <td>-46.865860</td>\n",
       "      <td>8.419164</td>\n",
       "      <td>-2.978050</td>\n",
       "      <td>-13.858909</td>\n",
       "      <td>9.973724</td>\n",
       "      <td>11.311474</td>\n",
       "      <td>-11.353134</td>\n",
       "      <td>-16.323940</td>\n",
       "      <td>12.591789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mfcc1       mfcc2      mfcc3      mfcc4      mfcc5      mfcc6  \\\n",
       "0   -214.176651  207.977264   1.462625  13.944162 -63.319916  -2.144712   \n",
       "1   -222.949982  209.148163   2.133819  17.240515 -52.081551   2.385664   \n",
       "2   -248.733551  195.559235  -2.844307   7.977224 -52.356590  -1.202414   \n",
       "3   -246.802917  198.915344  -3.477466   8.681169 -53.547142  -5.144975   \n",
       "4   -245.827591  200.687988   0.568132   6.174569 -51.041344  -1.792537   \n",
       "..          ...         ...        ...        ...        ...        ...   \n",
       "333 -242.007767  200.297760   3.961174  14.153851 -52.725536   7.545429   \n",
       "334 -245.131500  196.616119   2.222031  15.436684 -56.961128   6.723224   \n",
       "335 -247.851624  198.925278   2.341530  14.167100 -54.980747  11.598038   \n",
       "336 -232.978348  215.946442  14.133223  16.482494 -50.424297  13.806274   \n",
       "337 -218.726624  225.969635  17.963581  17.724133 -46.865860   8.419164   \n",
       "\n",
       "         mfcc7      mfcc8     mfcc9     mfcc10     mfcc11     mfcc12  \\\n",
       "0   -16.828245 -21.429878  7.964348  -0.085761  -1.125562 -21.268238   \n",
       "1   -18.650604 -24.606426  3.663574  -1.903811  -8.280209 -16.000689   \n",
       "2   -16.476841 -20.510300  5.527544  -0.318386 -15.725111  -8.803049   \n",
       "3   -17.089766 -22.173811  4.114779  -1.155015 -14.204550  -9.640966   \n",
       "4   -17.918312 -18.034185  5.677939  -2.018642 -12.768702 -11.336535   \n",
       "..         ...        ...       ...        ...        ...        ...   \n",
       "333  -5.822221 -22.547153  6.216630   7.461223 -12.434643 -15.016934   \n",
       "334  -5.488671 -19.845875  7.457106   2.931230 -13.481985 -15.816978   \n",
       "335  -2.436407 -18.352262  8.678156   8.914279  -9.958929 -16.050816   \n",
       "336  -4.241011 -16.475407  5.775840   7.153922 -11.623649 -19.136692   \n",
       "337  -2.978050 -13.858909  9.973724  11.311474 -11.353134 -16.323940   \n",
       "\n",
       "        mfcc13  \n",
       "0   -16.084270  \n",
       "1   -12.138484  \n",
       "2    -4.176742  \n",
       "3    -2.181946  \n",
       "4    -1.299195  \n",
       "..         ...  \n",
       "333  12.251122  \n",
       "334  13.508206  \n",
       "335  15.700717  \n",
       "336  15.453394  \n",
       "337  12.591789  \n",
       "\n",
       "[338 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(healthy[0][2]) #1번 : 파일. 2번:mfcc\n",
    "headers = \"mfcc1 mfcc2 mfcc3 mfcc4 mfcc5 mfcc6 mfcc7 mfcc8 mfcc9 mfcc10 mfcc11 mfcc12 mfcc13\".split()\n",
    "pd.DataFrame(healthy[1].T,columns=headers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "186be135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthy[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73d328bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "del pathology\n",
    "del healthy\n",
    "del pathology_sig\n",
    "del healthy_sig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23a4c15",
   "metadata": {},
   "source": [
    "# 데이터 나누기 - Stratified KFold\n",
    "\n",
    "- pathology : 1194 / healthy : 687 / 총 1881\n",
    "- k = 5\n",
    "- random over sampling 추가 ( healthy 데이터가 부족하기 때문)\n",
    "- 변경 후 -> pathology : 1194 / healthy : 1194 / 총: 2388"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919f9829",
   "metadata": {},
   "source": [
    "kfold와 random over sampling을 같이 실시하려면, 미리 test set을 나눠야 한다.\n",
    "\n",
    "먼저 테스트셋을 나누고, 그 후에 random over sampling을 실시한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483be78e",
   "metadata": {},
   "source": [
    "## 1. test/ train 나누기\n",
    "\n",
    "- train+valid :1504  / test : 377\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c299eacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pathology :  1194\n",
      "Healthy:  687\n",
      "총 데이터수 :  1881\n",
      "---\n",
      "훈련 셋 :  1504 Counter({'pathology': 955, 'healthy': 549})\n",
      "테스트 셋 :  377 Counter({'pathology': 239, 'healthy': 138})\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "#1. train, test 나누기\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split # train , test 분리에 사용.\n",
    "\n",
    "pathology = glob('../../voice_data/pathology_new/a/export/*.wav')\n",
    "healthy = glob('../../voice_data/healthy_new/a/export/*.wav')\n",
    "print(\"Pathology : \",len(pathology))\n",
    "print(\"Healthy: \",len(healthy))\n",
    "\n",
    "X = pathology+healthy # path 데이터 합\n",
    "print(\"총 데이터수 : \",len(X))\n",
    "Y = [] # 라벨\n",
    "for idx,x in enumerate(X):\n",
    "    if idx<1194:\n",
    "        Y.append(\"pathology\")\n",
    "    else:\n",
    "        Y.append(\"healthy\")\n",
    "\n",
    "#train 1504   test: 377\n",
    "X, X_test, Y, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True, stratify=Y, random_state=456)\n",
    "#stratify를 넣어서, test에도 라벨별 잘 분류되게 한다.\n",
    "\n",
    "print(\"---\")\n",
    "print(\"훈련 셋 : \",len(Y),Counter(Y))\n",
    "print(\"테스트 셋 : \",len(Y_test),Counter(Y_test))\n",
    "print(\"---\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc18df8",
   "metadata": {},
   "source": [
    "## 2. random over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc4a0dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before dataset shape Counter({'pathology': 955, 'healthy': 549})\n",
      "Resampled dataset shape Counter({'healthy': 955, 'pathology': 955})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = np.array(X).reshape(-1,1)#각 데이터를 다 행으로 넣음. (1194,1)\n",
    "#Y = np.array(Y)\n",
    "ros = RandomOverSampler(random_state = 123)\n",
    "X_res,Y_res = ros.fit_resample(X,Y)\n",
    "\n",
    "print('before dataset shape {}'.format(Counter(Y)) )\n",
    "print('Resampled dataset shape {}'.format(Counter(Y_res)) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09f636fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['../../voice_data/healthy_new/a/export\\\\60-a_n.wav'],\n",
       "       ['../../voice_data/pathology_new/a/export\\\\2421-a_n.wav'],\n",
       "       ['../../voice_data/pathology_new/a/export\\\\1270-a_n.wav'],\n",
       "       ...,\n",
       "       ['../../voice_data/healthy_new/a/export\\\\1127-a_n.wav'],\n",
       "       ['../../voice_data/healthy_new/a/export\\\\1533-a_n.wav'],\n",
       "       ['../../voice_data/healthy_new/a/export\\\\1359-a_n.wav']],\n",
       "      dtype='<U52')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e3e54dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 데이터수 :  1910\n",
      "복사된 수 :  406\n"
     ]
    }
   ],
   "source": [
    "#원래대로 돌리기\n",
    "X=X_res.reshape(1, -1)\n",
    "print( '총 데이터수 : ',X[0].size )\n",
    "print(  '복사된 수 : ',X[0].size - np.unique(X[0]).size )\n",
    "\n",
    "X=X[0].tolist()\n",
    "Y=Y_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ac3467",
   "metadata": {},
   "source": [
    "## 3. stratified k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fada6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 : 1\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 764, 'pathology': 764}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 191, 'pathology': 191} \n",
      "\n",
      "교차 검증 : 2\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 764, 'pathology': 764}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 191, 'pathology': 191} \n",
      "\n",
      "교차 검증 : 3\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 764, 'pathology': 764}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 191, 'pathology': 191} \n",
      "\n",
      "교차 검증 : 4\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 764, 'pathology': 764}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 191, 'pathology': 191} \n",
      "\n",
      "교차 검증 : 5\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 764, 'pathology': 764}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 191, 'pathology': 191} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. train, test 나누기\n",
    "#stratified kfold\n",
    "import os\n",
    "import random #데이터 shuffle 사용\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "skf_iris = StratifiedKFold(n_splits=5,shuffle=True,random_state=456)\n",
    "cnt_iter = 0\n",
    "\n",
    "X_train_list = [] #데이터 셋 보관\n",
    "Y_train_list = []\n",
    "\n",
    "X_valid_list = []\n",
    "Y_valid_list = []\n",
    "\n",
    "for train_idx, test_idx in skf_iris.split(X,Y):\n",
    "    \n",
    "    #split으로 반환된 인덱스를 이용하여, 학습 검증용 테스트 데이터 추출\n",
    "    cnt_iter += 1\n",
    "    X_train, X_valid = [X[idx] for idx in train_idx.tolist() ], [X[idx] for idx in test_idx.tolist() ]\n",
    "    Y_train, Y_valid = [Y[idx] for idx in train_idx.tolist() ], [Y[idx] for idx in test_idx.tolist() ]\n",
    "    \n",
    "    X_train_list.append(X_train)\n",
    "    X_valid_list.append(X_valid)\n",
    "    \n",
    "    Y_train_list.append(Y_train)\n",
    "    Y_valid_list.append(Y_valid)\n",
    "    \n",
    "    \n",
    "    #학습 및 예측\n",
    "    \n",
    "    label_train = Y_train\n",
    "    label_test = Y_valid\n",
    "    unique_train, train_counts = np.unique(label_train, return_counts = True)\n",
    "    unique_test, test_counts = np.unique(label_test, return_counts = True)\n",
    "    \n",
    "    uniq_cnt_train = dict(zip(unique_train, train_counts))\n",
    "    uniq_cnt_test = dict(zip(unique_test, test_counts))\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('교차 검증 : {}'.format(cnt_iter))\n",
    "    print('학습 레이블 데이터 분포 : \\n', uniq_cnt_train)\n",
    "    print('검증 레이블 데이터 분포 : \\n', uniq_cnt_test,'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a663f0",
   "metadata": {},
   "source": [
    "# 데이터 정의\n",
    "- 추가적으로 데이터의 크기를 맞춰주기 위해 3초로 padding 및 truncate 실시 https://sequencedata.tistory.com/25 FixAudioLength\n",
    "- 논문에서는 400frame으로 설정.\n",
    "- 전처리 방법 결정.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2febf8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "classes = [\"pathology\",\"healthy\"]\n",
    "sr=50000\n",
    "win_length =  np.int64(50000/40) # 1250\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다.\n",
    "\n",
    "\n",
    "\n",
    "class svd_dataset(Dataset):\n",
    "    def __init__(self,data_path_list,classes,data_num,training,transform=None):\n",
    "        #클래스에서 사용할 인자를 받아 인스턴스 변수로 저장하는 일을 한다.\n",
    "        #예를들면, 이미지의 경로 리스트를 저장하는 일을 하게 된다.\n",
    "        \n",
    "        #data_num : k 개 데이터 셋 중 어떤것을 쓸지\n",
    "        #test인지 아닌지.\n",
    "        \n",
    "        self.path_list = data_path_list[data_num]\n",
    "        self.data_num = data_num\n",
    "        self.training = training\n",
    "        self.label = svd_dataset.get_label(self.path_list,training,data_num)\n",
    "        self.classes=classes\n",
    "        self.transform=transform\n",
    "        \n",
    "    \n",
    "    @classmethod\n",
    "    def get_label(cls,data_path_list,training,data_num):\n",
    "        label_list=[]\n",
    "        \n",
    "        if training:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_train_list[data_num][idx])\n",
    "        else:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_valid_list[data_num][idx])\n",
    "        #print(label_list)\n",
    "        return label_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "        #데이터 셋의 길이를 정수로 반환한다. \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        1. path를 받아서, 소리에서 mfcc를 추출\n",
    "        2. mfcc를 500프레임으로 패딩.\n",
    "        3. resnet에 사용되기 위해 3채널로 복사(rgb 처럼)\n",
    "        4. 0~1 정규화\n",
    "        \n",
    "        \"\"\"\n",
    "        sig, sr = librosa.load(self.path_list[idx], sr=50000)# 논문에서 f_s = 50 000HZ\n",
    "        \n",
    "        MFCCs = librosa.feature.mfcc(sig, sr, win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "        #mfcc 400 FRAME이 되도록 패딩.\n",
    "        length = 400\n",
    "        pad2d = lambda a, i: a[:, 0:i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0], i-a.shape[1]))))\n",
    "        MFCCs = pad2d(MFCCs, length)\n",
    "        MFCCs= MFCCs.T\n",
    "        \n",
    "        if self.transform:\n",
    "            #print('transform')\n",
    "            MFCCs=self.transform(MFCCs).type(torch.float32)# 데이터 0~1 정규화\n",
    "            MFCCs=torch.stack([MFCCs,MFCCs,MFCCs])# 3채널로 복사.\n",
    "            MFCCs = MFCCs.squeeze(dim=1)\n",
    "        else:\n",
    "            #print(\"else\")\n",
    "            MFCCs = torch.from_numpy(MFCCs).type(torch.float32)\n",
    "            MFCCs=MFCCs.unsqueeze(0)#cnn 사용위해서 추가\n",
    "            #MFCCs = MFCCs.permute(2, 0, 1)\n",
    "        return MFCCs, self.classes.index(self.label[idx])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ef4060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set 제작을 위한 class\n",
    "class svd_test_set(Dataset):\n",
    "    def __init__(self,data_path_list,classes,transform=None):\n",
    "        #클래스에서 사용할 인자를 받아 인스턴스 변수로 저장하는 일을 한다.\n",
    "        #예를들면, 이미지의 경로 리스트를 저장하는 일을 하게 된다.\n",
    "        \n",
    "        #data_num : k 개 데이터 셋 중 어떤것을 쓸지\n",
    "        #test인지 아닌지.\n",
    "        \n",
    "        self.path_list = data_path_list\n",
    "        self.label = svd_test_set.get_label(self.path_list)\n",
    "        self.classes=classes\n",
    "        self.transform=transform\n",
    "        \n",
    "    \n",
    "    @classmethod\n",
    "    def get_label(cls,data_path_list):\n",
    "        label_list=[]\n",
    "        \n",
    "        for idx,x in enumerate(data_path_list):\n",
    "            label_list.append(Y_test[idx])\n",
    "        #print(label_list)\n",
    "        return label_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "        #데이터 셋의 길이를 정수로 반환한다. \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        1. path를 받아서, 소리에서 mfcc를 추출\n",
    "        2. mfcc를 500프레임으로 패딩.\n",
    "        3. resnet에 사용되기 위해 3채널로 복사(rgb 처럼)\n",
    "        4. 0~1 정규화\n",
    "        \n",
    "        \"\"\"\n",
    "        sig, sr = librosa.load(self.path_list[idx], sr=50000)# 논문에서 f_s = 50 000HZ\n",
    "        \n",
    "        MFCCs = librosa.feature.mfcc(sig, sr, win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "        #mfcc 400 FRAME이 되도록 패딩.\n",
    "        length = 400\n",
    "        pad2d = lambda a, i: a[:, 0:i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0], i-a.shape[1]))))\n",
    "        MFCCs = pad2d(MFCCs, length)\n",
    "        MFCCs= MFCCs.T\n",
    "        \n",
    "        if self.transform:\n",
    "            #print('transform')\n",
    "            MFCCs=self.transform(MFCCs).type(torch.float32)# 데이터 0~1 정규화\n",
    "            MFCCs=torch.stack([MFCCs,MFCCs,MFCCs])# 3채널로 복사.\n",
    "            MFCCs = MFCCs.squeeze(dim=1)\n",
    "        else:\n",
    "            #print(\"else\")\n",
    "            MFCCs = torch.from_numpy(MFCCs).type(torch.float32)\n",
    "            MFCCs=MFCCs.unsqueeze(0)#cnn 사용위해서 추가\n",
    "            #MFCCs = MFCCs.permute(2, 0, 1)\n",
    "        return MFCCs, self.classes.index(self.label[idx])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d05129d",
   "metadata": {},
   "source": [
    "# 데이터 로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89052fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. 하이퍼 파라미터\n",
    "BATCH_SIZE =  30 #한 배치당 30개 음성데이터 # 32 배수시에, 1개만 남는 경우가 발생해서.\n",
    "EPOCHS = 40 # 전체 데이터 셋을 40번 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bba97b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA LOADER 함수가 BATCH_size 단위로 분리해 지정.\n",
    "\n",
    "#확인을 위해 데이터셋 하나만 확인\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                           svd_dataset(\n",
    "                                               X_train_list,\n",
    "                                               classes,\n",
    "                                               transform = transforms.ToTensor(),#이걸 composed로 고쳐서 전처리 하도록 수정.\n",
    "                                               data_num=0,\n",
    "                                               training=True\n",
    "                                           ),\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True,\n",
    "                                           ) # 순서가 암기되는것을 막기위해.\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                           svd_dataset(\n",
    "                                               X_valid_list,\n",
    "                                               classes,\n",
    "                                               transform = transforms.ToTensor(),\n",
    "                                               data_num=0,\n",
    "                                               training=False\n",
    "                                           ),\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True,) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5771dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 로더.\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_test_set(\n",
    "                                                   X_test,\n",
    "                                                   classes,\n",
    "                                                   transform = transforms.ToTensor(),\n",
    "                                               ),\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = True,) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b15a86",
   "metadata": {},
   "source": [
    "# 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f866237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :  torch.Size([30, 3, 400, 13]) type: torch.FloatTensor\n",
      "Y_train :  torch.Size([30]) type: torch.LongTensor\n",
      "tensor(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x189cbc98970>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. 데이터 확인하기\n",
    "for (X_train,Y_train) in train_loader:\n",
    "    print(\"X_train : \",X_train.size(),'type:',X_train.type())\n",
    "    print(\"Y_train : \",Y_train.size(),'type:',Y_train.type())\n",
    "    break\n",
    "    \n",
    "print(Y_train[0])\n",
    "librosa.display.specshow(X_train[0][0].numpy().T, sr=50000, x_axis='time')\n",
    "#batch: 32 / frame수: 400  /  feature수: 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a45b51bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valid :  torch.Size([30, 3, 400, 13]) type: torch.FloatTensor\n",
      "Y_valid :  torch.Size([30]) type: torch.LongTensor\n",
      "tensor(1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x189cc007280>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#valiation set 확인\n",
    "for (X_valid,Y_valid) in validation_loader:\n",
    "    print(\"X_valid : \",X_valid.size(),'type:',X_valid.type())\n",
    "    print(\"Y_valid : \",Y_valid.size(),'type:',Y_valid.type())\n",
    "    break\n",
    "\n",
    "print(Y_valid[0])\n",
    "librosa.display.specshow(X_valid[0][0].numpy().T, sr=50000, x_axis='time')\n",
    "#batch: 32 / 3채널 / frame수: 400  /  feature수: 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe011218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valid :  torch.Size([30, 3, 400, 13]) type: torch.FloatTensor\n",
      "Y_valid :  torch.Size([30]) type: torch.LongTensor\n",
      "tensor(1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x189cbf1f730>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test set 확인\n",
    "for (test_data,test_label) in test_loader:\n",
    "    print(\"X_valid : \",test_data.size(),'type:',test_data.type())\n",
    "    print(\"Y_valid : \",test_label.size(),'type:',test_label.type())\n",
    "    break\n",
    "\n",
    "print(Y_valid[0])\n",
    "librosa.display.specshow(test_data[0][0].numpy().T, sr=50000, x_axis='time')\n",
    "#batch: 32 / 3채널 / frame수: 500  /  feature수: 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec40ea4",
   "metadata": {},
   "source": [
    "# RESNET18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e1d59a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 \n",
    "# pretrained\n",
    "\n",
    "\n",
    "def model_initialize():\n",
    "    model = models.resnet18(pretrained=True).cuda()\n",
    "    model.ftrs = model.fc.in_features # in_features : fully connected의 입력수.\n",
    "    num_ftrs = model.fc.in_features\n",
    "\n",
    "    model.fc = nn.Sequential(nn.Linear(num_ftrs, 256),\n",
    "                             nn.BatchNorm1d(256),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(256,128),\n",
    "                             nn.BatchNorm1d(128),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(128,64),\n",
    "                             nn.BatchNorm1d(64),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(64,50),\n",
    "                             nn.BatchNorm1d(50),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(50,2)\n",
    "                            )\n",
    "\n",
    "    model = model.cuda()\n",
    "    return model\n",
    "model=model_initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c26ff30a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.5, inplace=False)\n",
      "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.5, inplace=False)\n",
      "    (12): Linear(in_features=64, out_features=50, bias=True)\n",
      "    (13): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU()\n",
      "    (15): Dropout(p=0.5, inplace=False)\n",
      "    (16): Linear(in_features=50, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6097d312",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 200, 7]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 200, 7]             128\n",
      "              ReLU-3           [-1, 64, 200, 7]               0\n",
      "         MaxPool2d-4           [-1, 64, 100, 4]               0\n",
      "            Conv2d-5           [-1, 64, 100, 4]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 100, 4]             128\n",
      "              ReLU-7           [-1, 64, 100, 4]               0\n",
      "            Conv2d-8           [-1, 64, 100, 4]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 100, 4]             128\n",
      "             ReLU-10           [-1, 64, 100, 4]               0\n",
      "       BasicBlock-11           [-1, 64, 100, 4]               0\n",
      "           Conv2d-12           [-1, 64, 100, 4]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 100, 4]             128\n",
      "             ReLU-14           [-1, 64, 100, 4]               0\n",
      "           Conv2d-15           [-1, 64, 100, 4]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 100, 4]             128\n",
      "             ReLU-17           [-1, 64, 100, 4]               0\n",
      "       BasicBlock-18           [-1, 64, 100, 4]               0\n",
      "           Conv2d-19           [-1, 128, 50, 2]          73,728\n",
      "      BatchNorm2d-20           [-1, 128, 50, 2]             256\n",
      "             ReLU-21           [-1, 128, 50, 2]               0\n",
      "           Conv2d-22           [-1, 128, 50, 2]         147,456\n",
      "      BatchNorm2d-23           [-1, 128, 50, 2]             256\n",
      "           Conv2d-24           [-1, 128, 50, 2]           8,192\n",
      "      BatchNorm2d-25           [-1, 128, 50, 2]             256\n",
      "             ReLU-26           [-1, 128, 50, 2]               0\n",
      "       BasicBlock-27           [-1, 128, 50, 2]               0\n",
      "           Conv2d-28           [-1, 128, 50, 2]         147,456\n",
      "      BatchNorm2d-29           [-1, 128, 50, 2]             256\n",
      "             ReLU-30           [-1, 128, 50, 2]               0\n",
      "           Conv2d-31           [-1, 128, 50, 2]         147,456\n",
      "      BatchNorm2d-32           [-1, 128, 50, 2]             256\n",
      "             ReLU-33           [-1, 128, 50, 2]               0\n",
      "       BasicBlock-34           [-1, 128, 50, 2]               0\n",
      "           Conv2d-35           [-1, 256, 25, 1]         294,912\n",
      "      BatchNorm2d-36           [-1, 256, 25, 1]             512\n",
      "             ReLU-37           [-1, 256, 25, 1]               0\n",
      "           Conv2d-38           [-1, 256, 25, 1]         589,824\n",
      "      BatchNorm2d-39           [-1, 256, 25, 1]             512\n",
      "           Conv2d-40           [-1, 256, 25, 1]          32,768\n",
      "      BatchNorm2d-41           [-1, 256, 25, 1]             512\n",
      "             ReLU-42           [-1, 256, 25, 1]               0\n",
      "       BasicBlock-43           [-1, 256, 25, 1]               0\n",
      "           Conv2d-44           [-1, 256, 25, 1]         589,824\n",
      "      BatchNorm2d-45           [-1, 256, 25, 1]             512\n",
      "             ReLU-46           [-1, 256, 25, 1]               0\n",
      "           Conv2d-47           [-1, 256, 25, 1]         589,824\n",
      "      BatchNorm2d-48           [-1, 256, 25, 1]             512\n",
      "             ReLU-49           [-1, 256, 25, 1]               0\n",
      "       BasicBlock-50           [-1, 256, 25, 1]               0\n",
      "           Conv2d-51           [-1, 512, 13, 1]       1,179,648\n",
      "      BatchNorm2d-52           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-53           [-1, 512, 13, 1]               0\n",
      "           Conv2d-54           [-1, 512, 13, 1]       2,359,296\n",
      "      BatchNorm2d-55           [-1, 512, 13, 1]           1,024\n",
      "           Conv2d-56           [-1, 512, 13, 1]         131,072\n",
      "      BatchNorm2d-57           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-58           [-1, 512, 13, 1]               0\n",
      "       BasicBlock-59           [-1, 512, 13, 1]               0\n",
      "           Conv2d-60           [-1, 512, 13, 1]       2,359,296\n",
      "      BatchNorm2d-61           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-62           [-1, 512, 13, 1]               0\n",
      "           Conv2d-63           [-1, 512, 13, 1]       2,359,296\n",
      "      BatchNorm2d-64           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-65           [-1, 512, 13, 1]               0\n",
      "       BasicBlock-66           [-1, 512, 13, 1]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                  [-1, 256]         131,328\n",
      "      BatchNorm1d-69                  [-1, 256]             512\n",
      "             ReLU-70                  [-1, 256]               0\n",
      "          Dropout-71                  [-1, 256]               0\n",
      "           Linear-72                  [-1, 128]          32,896\n",
      "      BatchNorm1d-73                  [-1, 128]             256\n",
      "             ReLU-74                  [-1, 128]               0\n",
      "          Dropout-75                  [-1, 128]               0\n",
      "           Linear-76                   [-1, 64]           8,256\n",
      "      BatchNorm1d-77                   [-1, 64]             128\n",
      "             ReLU-78                   [-1, 64]               0\n",
      "          Dropout-79                   [-1, 64]               0\n",
      "           Linear-80                   [-1, 50]           3,250\n",
      "      BatchNorm1d-81                   [-1, 50]             100\n",
      "             ReLU-82                   [-1, 50]               0\n",
      "          Dropout-83                   [-1, 50]               0\n",
      "           Linear-84                    [-1, 2]             102\n",
      "================================================================\n",
      "Total params: 11,353,340\n",
      "Trainable params: 11,353,340\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 8.16\n",
      "Params size (MB): 43.31\n",
      "Estimated Total Size (MB): 51.52\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# get the model summary\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 400, 13), device=DEVICE.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f2ca15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. 학습\n",
    "def train(model,train_loader,optimizer, log_interval):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    train_loss = 0\n",
    "    for batch_idx,(image,label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        #데이터들 장비에 할당\n",
    "        optimizer.zero_grad() # device 에 저장된 gradient 제거\n",
    "        output = model(image) # model로 output을 계산\n",
    "        loss = criterion(output, label) #loss 계산\n",
    "        train_loss += loss.item()\n",
    "        prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "        correct += prediction.eq(label.view_as(prediction)).sum().item()# 아웃풋이 배치 사이즈 32개라서.\n",
    "        loss.backward() # loss 값을 이용해 gradient를 계산\n",
    "        optimizer.step() # Gradient 값을 이용해 파라미터 업데이트.\n",
    "    train_loss/=len(train_loader.dataset)\n",
    "    train_accuracy = 100. * correct / len(train_loader.dataset)\n",
    "    return train_loss,train_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b09341bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. 학습 진행하며, validation 데이터로 모델 성능확인\n",
    "def evaluate(model,valid_loader):\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    #no_grad : 그래디언트 값 계산 막기.\n",
    "    with torch.no_grad():\n",
    "        for image, label in valid_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            valid_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()# 아웃풋이 배치 사이즈 32개라서.\n",
    "            #true.false값을 sum해줌. item\n",
    "        valid_loss /= len(valid_loader.dataset)\n",
    "        valid_accuracy = 100. * correct / len(valid_loader.dataset)\n",
    "        return valid_loss,valid_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae179080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 로더 제작 함수\n",
    "\n",
    "def load_data(data_ind):\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_dataset(\n",
    "                                                   X_train_list,\n",
    "                                                   classes,\n",
    "                                                   transform = transforms.ToTensor(),#이걸 composed로 고쳐서 전처리 하도록 수정.\n",
    "                                                   data_num=data_ind,\n",
    "                                                   training=True\n",
    "                                               ),\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = True,\n",
    "                                               ) # 순서가 암기되는것을 막기위해.\n",
    "\n",
    "    validation_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_dataset(\n",
    "                                                   X_valid_list,\n",
    "                                                   classes,\n",
    "                                                   transform = transforms.ToTensor(),\n",
    "                                                   data_num=data_ind,\n",
    "                                                   training=False\n",
    "                                               ),\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = True,) \n",
    "    \n",
    "    return train_loader,validation_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7c8c86f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0250\t Train Acc:51.90 %  | \tValid Loss:0.0229 \tValid Acc: 62.04 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.022909).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0243\t Train Acc:51.77 %  | \tValid Loss:0.0226 \tValid Acc: 64.14 %\n",
      "\n",
      "Validation loss decreased (0.022909 --> 0.022552).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0239\t Train Acc:54.58 %  | \tValid Loss:0.0220 \tValid Acc: 64.40 %\n",
      "\n",
      "Validation loss decreased (0.022552 --> 0.022018).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0233\t Train Acc:55.50 %  | \tValid Loss:0.0220 \tValid Acc: 67.02 %\n",
      "\n",
      "Validation loss decreased (0.022018 --> 0.022001).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0235\t Train Acc:55.04 %  | \tValid Loss:0.0219 \tValid Acc: 67.80 %\n",
      "\n",
      "Validation loss decreased (0.022001 --> 0.021880).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0228\t Train Acc:57.33 %  | \tValid Loss:0.0214 \tValid Acc: 68.59 %\n",
      "\n",
      "Validation loss decreased (0.021880 --> 0.021415).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0226\t Train Acc:58.12 %  | \tValid Loss:0.0215 \tValid Acc: 68.06 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0218\t Train Acc:62.83 %  | \tValid Loss:0.0207 \tValid Acc: 71.73 %\n",
      "\n",
      "Validation loss decreased (0.021415 --> 0.020681).  Saving model ...\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0215\t Train Acc:61.98 %  | \tValid Loss:0.0204 \tValid Acc: 69.90 %\n",
      "\n",
      "Validation loss decreased (0.020681 --> 0.020424).  Saving model ...\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0208\t Train Acc:65.51 %  | \tValid Loss:0.0200 \tValid Acc: 70.16 %\n",
      "\n",
      "Validation loss decreased (0.020424 --> 0.020041).  Saving model ...\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0208\t Train Acc:66.23 %  | \tValid Loss:0.0199 \tValid Acc: 70.42 %\n",
      "\n",
      "Validation loss decreased (0.020041 --> 0.019893).  Saving model ...\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0192\t Train Acc:68.91 %  | \tValid Loss:0.0211 \tValid Acc: 65.45 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0191\t Train Acc:70.75 %  | \tValid Loss:0.0189 \tValid Acc: 73.82 %\n",
      "\n",
      "Validation loss decreased (0.019893 --> 0.018898).  Saving model ...\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0182\t Train Acc:73.56 %  | \tValid Loss:0.0189 \tValid Acc: 73.56 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0173\t Train Acc:75.65 %  | \tValid Loss:0.0184 \tValid Acc: 74.61 %\n",
      "\n",
      "Validation loss decreased (0.018898 --> 0.018444).  Saving model ...\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0164\t Train Acc:77.95 %  | \tValid Loss:0.0178 \tValid Acc: 75.39 %\n",
      "\n",
      "Validation loss decreased (0.018444 --> 0.017832).  Saving model ...\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0156\t Train Acc:81.09 %  | \tValid Loss:0.0177 \tValid Acc: 76.44 %\n",
      "\n",
      "Validation loss decreased (0.017832 --> 0.017725).  Saving model ...\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0150\t Train Acc:81.87 %  | \tValid Loss:0.0177 \tValid Acc: 74.35 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0137\t Train Acc:84.23 %  | \tValid Loss:0.0182 \tValid Acc: 74.08 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:20]\t Train Loss:0.0127\t Train Acc:86.39 %  | \tValid Loss:0.0179 \tValid Acc: 75.39 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:21]\t Train Loss:0.0122\t Train Acc:87.57 %  | \tValid Loss:0.0177 \tValid Acc: 78.27 %\n",
      "\n",
      "Validation loss decreased (0.017725 --> 0.017712).  Saving model ...\n",
      "\n",
      "[EPOCH:22]\t Train Loss:0.0122\t Train Acc:87.70 %  | \tValid Loss:0.0170 \tValid Acc: 76.44 %\n",
      "\n",
      "Validation loss decreased (0.017712 --> 0.016968).  Saving model ...\n",
      "\n",
      "[EPOCH:23]\t Train Loss:0.0100\t Train Acc:90.64 %  | \tValid Loss:0.0167 \tValid Acc: 76.70 %\n",
      "\n",
      "Validation loss decreased (0.016968 --> 0.016698).  Saving model ...\n",
      "\n",
      "[EPOCH:24]\t Train Loss:0.0098\t Train Acc:90.51 %  | \tValid Loss:0.0169 \tValid Acc: 77.75 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:25]\t Train Loss:0.0092\t Train Acc:90.97 %  | \tValid Loss:0.0189 \tValid Acc: 73.82 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:26]\t Train Loss:0.0086\t Train Acc:92.34 %  | \tValid Loss:0.0192 \tValid Acc: 73.82 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:27]\t Train Loss:0.0080\t Train Acc:93.91 %  | \tValid Loss:0.0199 \tValid Acc: 75.39 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:28]\t Train Loss:0.0073\t Train Acc:94.44 %  | \tValid Loss:0.0201 \tValid Acc: 75.13 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[1 교차검증] Early stopping\n",
      "[2 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0266\t Train Acc:49.80 %  | \tValid Loss:0.0233 \tValid Acc: 55.76 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.023285).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0251\t Train Acc:52.16 %  | \tValid Loss:0.0222 \tValid Acc: 62.30 %\n",
      "\n",
      "Validation loss decreased (0.023285 --> 0.022231).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0241\t Train Acc:52.29 %  | \tValid Loss:0.0217 \tValid Acc: 67.28 %\n",
      "\n",
      "Validation loss decreased (0.022231 --> 0.021719).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0236\t Train Acc:54.97 %  | \tValid Loss:0.0206 \tValid Acc: 69.90 %\n",
      "\n",
      "Validation loss decreased (0.021719 --> 0.020576).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0225\t Train Acc:57.53 %  | \tValid Loss:0.0198 \tValid Acc: 69.90 %\n",
      "\n",
      "Validation loss decreased (0.020576 --> 0.019775).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0212\t Train Acc:62.37 %  | \tValid Loss:0.0200 \tValid Acc: 69.37 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0207\t Train Acc:65.25 %  | \tValid Loss:0.0198 \tValid Acc: 70.42 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0209\t Train Acc:63.68 %  | \tValid Loss:0.0199 \tValid Acc: 68.85 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0199\t Train Acc:64.73 %  | \tValid Loss:0.0193 \tValid Acc: 70.68 %\n",
      "\n",
      "Validation loss decreased (0.019775 --> 0.019272).  Saving model ...\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0193\t Train Acc:69.37 %  | \tValid Loss:0.0191 \tValid Acc: 72.25 %\n",
      "\n",
      "Validation loss decreased (0.019272 --> 0.019084).  Saving model ...\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0192\t Train Acc:69.31 %  | \tValid Loss:0.0185 \tValid Acc: 72.51 %\n",
      "\n",
      "Validation loss decreased (0.019084 --> 0.018479).  Saving model ...\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0186\t Train Acc:70.88 %  | \tValid Loss:0.0176 \tValid Acc: 75.65 %\n",
      "\n",
      "Validation loss decreased (0.018479 --> 0.017583).  Saving model ...\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0174\t Train Acc:75.13 %  | \tValid Loss:0.0182 \tValid Acc: 70.94 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0168\t Train Acc:76.31 %  | \tValid Loss:0.0181 \tValid Acc: 72.25 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0164\t Train Acc:77.42 %  | \tValid Loss:0.0177 \tValid Acc: 74.08 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0159\t Train Acc:79.58 %  | \tValid Loss:0.0187 \tValid Acc: 71.20 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0153\t Train Acc:79.84 %  | \tValid Loss:0.0179 \tValid Acc: 73.30 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[2 교차검증] Early stopping\n",
      "[3 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0260\t Train Acc:50.00 %  | \tValid Loss:0.0238 \tValid Acc: 50.26 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.023780).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0246\t Train Acc:49.87 %  | \tValid Loss:0.0226 \tValid Acc: 50.52 %\n",
      "\n",
      "Validation loss decreased (0.023780 --> 0.022595).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0241\t Train Acc:50.85 %  | \tValid Loss:0.0225 \tValid Acc: 50.52 %\n",
      "\n",
      "Validation loss decreased (0.022595 --> 0.022504).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0226\t Train Acc:55.56 %  | \tValid Loss:0.0221 \tValid Acc: 56.02 %\n",
      "\n",
      "Validation loss decreased (0.022504 --> 0.022123).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0218\t Train Acc:58.12 %  | \tValid Loss:0.0213 \tValid Acc: 66.75 %\n",
      "\n",
      "Validation loss decreased (0.022123 --> 0.021303).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0212\t Train Acc:60.47 %  | \tValid Loss:0.0213 \tValid Acc: 67.02 %\n",
      "\n",
      "Validation loss decreased (0.021303 --> 0.021277).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0206\t Train Acc:64.01 %  | \tValid Loss:0.0207 \tValid Acc: 67.80 %\n",
      "\n",
      "Validation loss decreased (0.021277 --> 0.020738).  Saving model ...\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0204\t Train Acc:65.12 %  | \tValid Loss:0.0202 \tValid Acc: 70.68 %\n",
      "\n",
      "Validation loss decreased (0.020738 --> 0.020239).  Saving model ...\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0198\t Train Acc:68.06 %  | \tValid Loss:0.0203 \tValid Acc: 67.80 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0190\t Train Acc:70.88 %  | \tValid Loss:0.0205 \tValid Acc: 69.11 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH:11]\t Train Loss:0.0188\t Train Acc:71.92 %  | \tValid Loss:0.0196 \tValid Acc: 70.68 %\n",
      "\n",
      "Validation loss decreased (0.020239 --> 0.019578).  Saving model ...\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0187\t Train Acc:73.56 %  | \tValid Loss:0.0196 \tValid Acc: 69.63 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0182\t Train Acc:73.76 %  | \tValid Loss:0.0201 \tValid Acc: 67.28 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0171\t Train Acc:76.96 %  | \tValid Loss:0.0189 \tValid Acc: 74.35 %\n",
      "\n",
      "Validation loss decreased (0.019578 --> 0.018896).  Saving model ...\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0167\t Train Acc:78.60 %  | \tValid Loss:0.0191 \tValid Acc: 71.47 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0157\t Train Acc:79.91 %  | \tValid Loss:0.0192 \tValid Acc: 69.90 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0154\t Train Acc:82.26 %  | \tValid Loss:0.0188 \tValid Acc: 72.51 %\n",
      "\n",
      "Validation loss decreased (0.018896 --> 0.018799).  Saving model ...\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0150\t Train Acc:82.13 %  | \tValid Loss:0.0186 \tValid Acc: 73.82 %\n",
      "\n",
      "Validation loss decreased (0.018799 --> 0.018564).  Saving model ...\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0144\t Train Acc:84.23 %  | \tValid Loss:0.0192 \tValid Acc: 69.37 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:20]\t Train Loss:0.0130\t Train Acc:86.13 %  | \tValid Loss:0.0208 \tValid Acc: 70.42 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:21]\t Train Loss:0.0133\t Train Acc:84.29 %  | \tValid Loss:0.0183 \tValid Acc: 74.87 %\n",
      "\n",
      "Validation loss decreased (0.018564 --> 0.018340).  Saving model ...\n",
      "\n",
      "[EPOCH:22]\t Train Loss:0.0126\t Train Acc:86.06 %  | \tValid Loss:0.0164 \tValid Acc: 76.70 %\n",
      "\n",
      "Validation loss decreased (0.018340 --> 0.016419).  Saving model ...\n",
      "\n",
      "[EPOCH:23]\t Train Loss:0.0114\t Train Acc:88.15 %  | \tValid Loss:0.0168 \tValid Acc: 78.01 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:24]\t Train Loss:0.0114\t Train Acc:88.09 %  | \tValid Loss:0.0193 \tValid Acc: 71.73 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:25]\t Train Loss:0.0110\t Train Acc:87.83 %  | \tValid Loss:0.0177 \tValid Acc: 76.18 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:26]\t Train Loss:0.0095\t Train Acc:91.62 %  | \tValid Loss:0.0201 \tValid Acc: 73.56 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:27]\t Train Loss:0.0100\t Train Acc:89.92 %  | \tValid Loss:0.0190 \tValid Acc: 75.39 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[3 교차검증] Early stopping\n",
      "[4 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0270\t Train Acc:48.56 %  | \tValid Loss:0.0233 \tValid Acc: 52.88 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.023345).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0253\t Train Acc:51.11 %  | \tValid Loss:0.0229 \tValid Acc: 61.26 %\n",
      "\n",
      "Validation loss decreased (0.023345 --> 0.022859).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0243\t Train Acc:53.01 %  | \tValid Loss:0.0226 \tValid Acc: 61.26 %\n",
      "\n",
      "Validation loss decreased (0.022859 --> 0.022557).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0236\t Train Acc:55.76 %  | \tValid Loss:0.0223 \tValid Acc: 63.09 %\n",
      "\n",
      "Validation loss decreased (0.022557 --> 0.022295).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0229\t Train Acc:57.79 %  | \tValid Loss:0.0223 \tValid Acc: 64.66 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0225\t Train Acc:59.23 %  | \tValid Loss:0.0216 \tValid Acc: 64.14 %\n",
      "\n",
      "Validation loss decreased (0.022295 --> 0.021636).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0226\t Train Acc:60.60 %  | \tValid Loss:0.0218 \tValid Acc: 64.14 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0222\t Train Acc:61.45 %  | \tValid Loss:0.0217 \tValid Acc: 66.23 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0207\t Train Acc:66.82 %  | \tValid Loss:0.0211 \tValid Acc: 69.63 %\n",
      "\n",
      "Validation loss decreased (0.021636 --> 0.021072).  Saving model ...\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0206\t Train Acc:66.88 %  | \tValid Loss:0.0206 \tValid Acc: 68.85 %\n",
      "\n",
      "Validation loss decreased (0.021072 --> 0.020580).  Saving model ...\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0198\t Train Acc:68.98 %  | \tValid Loss:0.0204 \tValid Acc: 67.28 %\n",
      "\n",
      "Validation loss decreased (0.020580 --> 0.020392).  Saving model ...\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0195\t Train Acc:69.83 %  | \tValid Loss:0.0199 \tValid Acc: 70.94 %\n",
      "\n",
      "Validation loss decreased (0.020392 --> 0.019856).  Saving model ...\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0194\t Train Acc:72.12 %  | \tValid Loss:0.0192 \tValid Acc: 72.77 %\n",
      "\n",
      "Validation loss decreased (0.019856 --> 0.019209).  Saving model ...\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0185\t Train Acc:73.43 %  | \tValid Loss:0.0192 \tValid Acc: 69.90 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0177\t Train Acc:75.46 %  | \tValid Loss:0.0187 \tValid Acc: 72.77 %\n",
      "\n",
      "Validation loss decreased (0.019209 --> 0.018690).  Saving model ...\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0167\t Train Acc:77.23 %  | \tValid Loss:0.0193 \tValid Acc: 70.42 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0162\t Train Acc:80.04 %  | \tValid Loss:0.0180 \tValid Acc: 76.96 %\n",
      "\n",
      "Validation loss decreased (0.018690 --> 0.018028).  Saving model ...\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0147\t Train Acc:82.85 %  | \tValid Loss:0.0183 \tValid Acc: 71.47 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0139\t Train Acc:84.10 %  | \tValid Loss:0.0191 \tValid Acc: 73.56 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:20]\t Train Loss:0.0134\t Train Acc:84.03 %  | \tValid Loss:0.0184 \tValid Acc: 73.30 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:21]\t Train Loss:0.0123\t Train Acc:87.17 %  | \tValid Loss:0.0164 \tValid Acc: 78.27 %\n",
      "\n",
      "Validation loss decreased (0.018028 --> 0.016383).  Saving model ...\n",
      "\n",
      "[EPOCH:22]\t Train Loss:0.0122\t Train Acc:86.91 %  | \tValid Loss:0.0165 \tValid Acc: 80.63 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:23]\t Train Loss:0.0124\t Train Acc:86.65 %  | \tValid Loss:0.0162 \tValid Acc: 79.06 %\n",
      "\n",
      "Validation loss decreased (0.016383 --> 0.016219).  Saving model ...\n",
      "\n",
      "[EPOCH:24]\t Train Loss:0.0109\t Train Acc:88.55 %  | \tValid Loss:0.0192 \tValid Acc: 75.13 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:25]\t Train Loss:0.0096\t Train Acc:90.51 %  | \tValid Loss:0.0162 \tValid Acc: 80.10 %\n",
      "\n",
      "Validation loss decreased (0.016219 --> 0.016198).  Saving model ...\n",
      "\n",
      "[EPOCH:26]\t Train Loss:0.0086\t Train Acc:92.74 %  | \tValid Loss:0.0144 \tValid Acc: 83.25 %\n",
      "\n",
      "Validation loss decreased (0.016198 --> 0.014382).  Saving model ...\n",
      "\n",
      "[EPOCH:27]\t Train Loss:0.0076\t Train Acc:93.91 %  | \tValid Loss:0.0158 \tValid Acc: 79.32 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:28]\t Train Loss:0.0080\t Train Acc:94.04 %  | \tValid Loss:0.0144 \tValid Acc: 82.98 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:29]\t Train Loss:0.0076\t Train Acc:93.59 %  | \tValid Loss:0.0161 \tValid Acc: 78.80 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:30]\t Train Loss:0.0066\t Train Acc:95.35 %  | \tValid Loss:0.0145 \tValid Acc: 83.51 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:31]\t Train Loss:0.0066\t Train Acc:94.63 %  | \tValid Loss:0.0172 \tValid Acc: 79.32 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[4 교차검증] Early stopping\n",
      "[5 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0258\t Train Acc:49.93 %  | \tValid Loss:0.0232 \tValid Acc: 56.54 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.023158).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0252\t Train Acc:52.75 %  | \tValid Loss:0.0228 \tValid Acc: 60.21 %\n",
      "\n",
      "Validation loss decreased (0.023158 --> 0.022774).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0239\t Train Acc:56.35 %  | \tValid Loss:0.0224 \tValid Acc: 64.40 %\n",
      "\n",
      "Validation loss decreased (0.022774 --> 0.022359).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0231\t Train Acc:57.40 %  | \tValid Loss:0.0222 \tValid Acc: 60.73 %\n",
      "\n",
      "Validation loss decreased (0.022359 --> 0.022158).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0222\t Train Acc:59.75 %  | \tValid Loss:0.0214 \tValid Acc: 65.71 %\n",
      "\n",
      "Validation loss decreased (0.022158 --> 0.021368).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0217\t Train Acc:61.26 %  | \tValid Loss:0.0212 \tValid Acc: 64.92 %\n",
      "\n",
      "Validation loss decreased (0.021368 --> 0.021158).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0206\t Train Acc:65.31 %  | \tValid Loss:0.0212 \tValid Acc: 62.57 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0204\t Train Acc:65.18 %  | \tValid Loss:0.0207 \tValid Acc: 65.71 %\n",
      "\n",
      "Validation loss decreased (0.021158 --> 0.020731).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH:9]\t Train Loss:0.0198\t Train Acc:68.19 %  | \tValid Loss:0.0207 \tValid Acc: 65.71 %\n",
      "\n",
      "Validation loss decreased (0.020731 --> 0.020722).  Saving model ...\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0199\t Train Acc:69.31 %  | \tValid Loss:0.0199 \tValid Acc: 67.54 %\n",
      "\n",
      "Validation loss decreased (0.020722 --> 0.019935).  Saving model ...\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0183\t Train Acc:72.64 %  | \tValid Loss:0.0192 \tValid Acc: 72.25 %\n",
      "\n",
      "Validation loss decreased (0.019935 --> 0.019171).  Saving model ...\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0184\t Train Acc:72.51 %  | \tValid Loss:0.0195 \tValid Acc: 70.42 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0177\t Train Acc:72.84 %  | \tValid Loss:0.0186 \tValid Acc: 70.94 %\n",
      "\n",
      "Validation loss decreased (0.019171 --> 0.018574).  Saving model ...\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0172\t Train Acc:74.87 %  | \tValid Loss:0.0185 \tValid Acc: 71.47 %\n",
      "\n",
      "Validation loss decreased (0.018574 --> 0.018535).  Saving model ...\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0162\t Train Acc:78.99 %  | \tValid Loss:0.0184 \tValid Acc: 72.25 %\n",
      "\n",
      "Validation loss decreased (0.018535 --> 0.018395).  Saving model ...\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0158\t Train Acc:78.66 %  | \tValid Loss:0.0199 \tValid Acc: 65.97 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0164\t Train Acc:77.16 %  | \tValid Loss:0.0187 \tValid Acc: 71.99 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0145\t Train Acc:82.40 %  | \tValid Loss:0.0198 \tValid Acc: 69.11 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0143\t Train Acc:82.13 %  | \tValid Loss:0.0189 \tValid Acc: 70.16 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:20]\t Train Loss:0.0145\t Train Acc:81.94 %  | \tValid Loss:0.0184 \tValid Acc: 73.30 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[5 교차검증] Early stopping\n"
     ]
    }
   ],
   "source": [
    "#10. 학습 및 평가.\n",
    "# resnet34 pretrained true\n",
    "# kfold 적용\n",
    "\n",
    "train_accs = []\n",
    "valid_accs = []\n",
    "\n",
    "for data_ind in range(1,6):\n",
    "\n",
    "    check_path = '../checkpoint/checkpoint_resnet18_true_'+str(data_ind)+'_a.pt'\n",
    "\n",
    "    early_stopping = EarlyStopping(patience = 5, verbose = True, path=check_path)\n",
    "    train_loader,validation_loader = load_data(data_ind-1)\n",
    "    \n",
    "    best_train_acc=0 # accuracy 기록용\n",
    "    best_valid_acc=0\n",
    "    \n",
    "    model=model_initialize()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "    \n",
    "    \n",
    "    print(\"[{} 교차검증] 학습 시작\\n ----- \".format(data_ind))\n",
    "    for Epoch in range(1,EPOCHS+1):\n",
    "        train_loss,train_accuracy=train(model,train_loader,optimizer,log_interval=31)\n",
    "        valid_loss,valid_accuracy = evaluate(model, validation_loader)\n",
    "\n",
    "\n",
    "        print(\"\\n[EPOCH:{}]\\t Train Loss:{:.4f}\\t Train Acc:{:.2f} %  | \\tValid Loss:{:.4f} \\tValid Acc: {:.2f} %\\n\".\n",
    "              format(Epoch,train_loss,train_accuracy,valid_loss,valid_accuracy))\n",
    "\n",
    "        early_stopping(valid_loss, model)\n",
    "        if -early_stopping.best_score == valid_loss:\n",
    "            best_train_acc, best_valid_acc = train_accuracy,valid_accuracy\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "                train_accs.append(best_train_acc)\n",
    "                valid_accs.append(best_valid_acc)\n",
    "                print(\"[{} 교차검증] Early stopping\".format(data_ind))\n",
    "                break\n",
    "\n",
    "        if Epoch==EPOCHS:\n",
    "            #만약 early stop 없이 40 epoch라서 중지 된 경우.\n",
    "            train_accs.append(best_train_acc)\n",
    "            valid_accs.append(best_valid_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6767ec8",
   "metadata": {},
   "source": [
    "# 모델 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6824ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 교차검증] train ACC : 90.6414 |\t valid ACC: 76.7016 \n",
      "[2 교차검증] train ACC : 70.8770 |\t valid ACC: 75.6545 \n",
      "[3 교차검증] train ACC : 86.0602 |\t valid ACC: 76.7016 \n",
      "[4 교차검증] train ACC : 92.7356 |\t valid ACC: 83.2461 \n",
      "[5 교차검증] train ACC : 78.9921 |\t valid ACC: 72.2513 \n",
      "평균 검증 정확도 76.91099476439791 %\n"
     ]
    }
   ],
   "source": [
    "sum_valid=0\n",
    "for data_ind in range(5):\n",
    "    print(\"[{} 교차검증] train ACC : {:.4f} |\\t valid ACC: {:.4f} \".format(data_ind+1,train_accs[data_ind],valid_accs[data_ind] ))\n",
    "    sum_valid+=valid_accs[data_ind]\n",
    "    \n",
    "print(\"평균 검증 정확도\",sum_valid/5,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0967cf",
   "metadata": {},
   "source": [
    "# Model Test\n",
    "\n",
    "- test set\n",
    "- confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a19235bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix 계산\n",
    "#test set 계산.\n",
    "def test_evaluate(model,test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    predictions = []\n",
    "    answers = []\n",
    "    #no_grad : 그래디언트 값 계산 막기.\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "            answers +=label\n",
    "            predictions +=prediction\n",
    "            \n",
    "        return predictions,answers,test_loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca2e1ed2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번 모델\n",
      "Accuracy : 69.4960% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.7844\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.7155\n",
      "f score : 0.7484 \n",
      "[[171  68]\n",
      " [ 47  91]]\n",
      "-----\n",
      "2번 모델\n",
      "Accuracy : 60.2122% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.8870\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.4268\n",
      "f score : 0.5763 \n",
      "[[102 137]\n",
      " [ 13 125]]\n",
      "-----\n",
      "3번 모델\n",
      "Accuracy : 68.1698% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.8251\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.6318\n",
      "f score : 0.7156 \n",
      "[[151  88]\n",
      " [ 32 106]]\n",
      "-----\n",
      "4번 모델\n",
      "Accuracy : 63.1300% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.7083\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.7113\n",
      "f score : 0.7098 \n",
      "[[170  69]\n",
      " [ 70  68]]\n",
      "-----\n",
      "5번 모델\n",
      "Accuracy : 62.3342% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.9008\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.4561\n",
      "f score : 0.6056 \n",
      "[[109 130]\n",
      " [ 12 126]]\n",
      "-----\n",
      "평균 acc : 0.6467\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Confusion matrix (resnet18)\n",
    "# kfold의 confusion matrix는 계산 방법이 다르다.\n",
    "# 모델을 각각 불러와서 test set을 평가한다.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf = np.zeros((2,2))\n",
    "cf_list = []\n",
    "average_accuracy = 0\n",
    "\n",
    "for data_ind in range(1,6):\n",
    "\n",
    "    check_path = '../checkpoint/checkpoint_resnet18_true_'+str(data_ind)+'_a.pt'\n",
    "    model.load_state_dict(torch.load(check_path))\n",
    "\n",
    "    predictions,answers,test_loss = test_evaluate(model, test_loader)\n",
    "    predictions=[ dat.cpu().numpy() for dat in predictions]\n",
    "    answers=[ dat.cpu().numpy() for dat in answers]\n",
    "\n",
    "    \n",
    "    cf = confusion_matrix(answers, predictions)\n",
    "    cf_list.append(cf)\n",
    "    \n",
    "    acc = (cf[0,0]+cf[1,1])/(cf[0,0]+cf[0,1]+cf[1,0]+cf[1,1])\n",
    "    average_accuracy+=acc\n",
    "    precision=cf[0,0]/(cf[0,0]+cf[1,0])\n",
    "    recall=cf[0,0]/(cf[0,0]+cf[0,1])\n",
    "    fscore=2*precision*recall/(precision+recall)\n",
    "    print('{}번 모델'.format(data_ind))\n",
    "    print(\"Accuracy : {:.4f}% \".format(acc*100))\n",
    "    print(\"Precision (pathology 예측한 것중 맞는 것) : {:.4f}\".format(precision))\n",
    "    print(\"recall (실제 pathology 중  예측이 맞는 것) : {:.4f}\".format(recall))\n",
    "    print(\"f score : {:.4f} \".format(fscore))\n",
    "    print(cf)\n",
    "    print(\"-----\")\n",
    "\n",
    "print(\"평균 acc : {:.4f}\".format(average_accuracy/5))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "455.111px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
