{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37664ece",
   "metadata": {},
   "source": [
    "- http://keunwoochoi.blogspot.com/2016/03/2.html\n",
    "- http://www.rex-ai.info/docs/AI_Example_CNN_speech_recognize\n",
    "- https://www.youtube.com/watch?v=oltGIc4uo5c\n",
    "- https://youdaeng-com.tistory.com/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "275b8092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pytorch version :  1.10.0  Device :  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn # 인공 신경망 모델들 모아놓은 모듈\n",
    "import torch.nn.functional as F #그중 자주 쓰이는것들을 F로\n",
    "from torchvision import transforms, datasets\n",
    "import cv2\n",
    "from torchvision import transforms, datasets\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "p = os.path.abspath('..') # 상위 폴더를 사용하기 위해서.\n",
    "sys.path.insert(1, p)\n",
    "from pytorchtools.pytorchtools import EarlyStopping # 현재 폴더에 추가된 모듈.\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "#DEVICE = torch.device('cpu')\n",
    "print('Using Pytorch version : ',torch.__version__,' Device : ',DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ebea6",
   "metadata": {},
   "source": [
    "# SVD 문장 데이터에서 Feature 추출\n",
    "- mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "114a1b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa, librosa.display \n",
    "import matplotlib.pyplot as plt\n",
    "#window sizde : FFT를 할때 참조할 그래프 길이 ( 프레임 하나당 sample 수 )\n",
    "#자연어 처리에서는 25ms 사용. https://ahnjg.tistory.com/93\n",
    "#초당 50000hz 중 1250개씩 윈도우 사이즈로 사용.\n",
    "sr=50000\n",
    "win_length =  np.int64(50000/40) # 1250\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c72d82e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pathology data 수 :  1195\n",
      "healthy data 수 :  687\n",
      "가장 긴 path sample : 130793\n",
      "가장 긴 healthy sample : 194501\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa, librosa.display \n",
    "import matplotlib.pyplot as plt\n",
    "#window sizde : FFT를 할때 참조할 그래프 길이 ( 프레임 하나당 sample 수 )\n",
    "#자연어 처리에서는 25ms 사용. https://ahnjg.tistory.com/93\n",
    "#초당 50000hz 중 1250개씩 윈도우 사이즈로 사용.\n",
    "sr=50000\n",
    "win_length =  np.int64(50000/40) # 1250\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다.\n",
    "\n",
    "pathology_sig=[]\n",
    "healthy_sig=[]\n",
    "\n",
    "pathology=[]\n",
    "healthy=[]\n",
    "\n",
    "\n",
    "#PATHOLOGY DATA\n",
    "for audio_path in os.listdir('../../voice_data/pathology_new/u/export'):\n",
    "    sig, sr = librosa.load('../../voice_data/pathology_new/u/export/'+audio_path, sr=50000)# 논문에서 f_s = 50 000HZ\n",
    "    pathology_sig.append(sig)\n",
    "    MFCCs = librosa.feature.mfcc(sig, sr, win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "    pathology.append(MFCCs)\n",
    "    \n",
    "\n",
    "#Healthy data\n",
    "for audio_path in os.listdir('../../voice_data/healthy_new/u/export'):\n",
    "    sig, sr = librosa.load('../../voice_data/healthy_new/u/export/'+audio_path, sr=50000)# 논문에서 f_s = 50 000HZ\n",
    "    healthy_sig.append(sig)\n",
    "    MFCCs = librosa.feature.mfcc(sig, sr, win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "    healthy.append(MFCCs)\n",
    "    \n",
    "print(\"pathology data 수 : \",len(pathology))\n",
    "print(\"healthy data 수 : \",len(healthy))\n",
    "\n",
    "\n",
    "path_max=max([ len(samples) for samples in pathology_sig])\n",
    "healthy_max=max([ len(samples) for samples in healthy_sig])\n",
    "print(\"가장 긴 path sample :\" ,path_max)\n",
    "print(\"가장 긴 healthy sample :\" ,healthy_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "636bede8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.61586 초\n",
      "3.89002 초\n"
     ]
    }
   ],
   "source": [
    "print(path_max/sr,\"초\")\n",
    "print(healthy_max/sr,\"초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5915f64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 :  1.2356882510460252\n",
      "평균 :  1.3178440174672488\n"
     ]
    }
   ],
   "source": [
    "print('평균 : ',np.mean([ len(samples) for samples in pathology_sig])/sr)\n",
    "print('평균 : ',np.mean([ len(samples) for samples in healthy_sig])/sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91bd1989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.504"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "400*313/sr\n",
    "#400 frame은 약 2.5초 이상."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148ec668",
   "metadata": {},
   "source": [
    "# 결과 확인\n",
    "- 1 row당 1 frame으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a48f3297",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>mfcc5</th>\n",
       "      <th>mfcc6</th>\n",
       "      <th>mfcc7</th>\n",
       "      <th>mfcc8</th>\n",
       "      <th>mfcc9</th>\n",
       "      <th>mfcc10</th>\n",
       "      <th>mfcc11</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-272.275146</td>\n",
       "      <td>208.902557</td>\n",
       "      <td>44.434441</td>\n",
       "      <td>40.349213</td>\n",
       "      <td>-25.458517</td>\n",
       "      <td>12.826863</td>\n",
       "      <td>-3.920654</td>\n",
       "      <td>-8.411410</td>\n",
       "      <td>3.417778</td>\n",
       "      <td>7.566922</td>\n",
       "      <td>-2.498518</td>\n",
       "      <td>-6.284049</td>\n",
       "      <td>-2.326992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-292.371613</td>\n",
       "      <td>203.497162</td>\n",
       "      <td>55.854485</td>\n",
       "      <td>54.128845</td>\n",
       "      <td>-19.807659</td>\n",
       "      <td>14.410148</td>\n",
       "      <td>-1.129526</td>\n",
       "      <td>-7.547229</td>\n",
       "      <td>2.966858</td>\n",
       "      <td>11.841558</td>\n",
       "      <td>1.122357</td>\n",
       "      <td>-0.466148</td>\n",
       "      <td>-0.014877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-326.458984</td>\n",
       "      <td>179.993637</td>\n",
       "      <td>64.711746</td>\n",
       "      <td>65.344246</td>\n",
       "      <td>-17.435101</td>\n",
       "      <td>19.880333</td>\n",
       "      <td>2.197647</td>\n",
       "      <td>-1.880868</td>\n",
       "      <td>-4.580058</td>\n",
       "      <td>4.086713</td>\n",
       "      <td>3.976766</td>\n",
       "      <td>1.293952</td>\n",
       "      <td>6.717286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-324.657288</td>\n",
       "      <td>174.853928</td>\n",
       "      <td>61.641129</td>\n",
       "      <td>64.695351</td>\n",
       "      <td>-10.726300</td>\n",
       "      <td>23.473757</td>\n",
       "      <td>-8.347025</td>\n",
       "      <td>-9.129495</td>\n",
       "      <td>-7.556191</td>\n",
       "      <td>10.262231</td>\n",
       "      <td>8.042992</td>\n",
       "      <td>2.768127</td>\n",
       "      <td>9.962308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-317.942169</td>\n",
       "      <td>182.751175</td>\n",
       "      <td>64.051483</td>\n",
       "      <td>59.415588</td>\n",
       "      <td>-17.222746</td>\n",
       "      <td>18.475574</td>\n",
       "      <td>-8.616613</td>\n",
       "      <td>-10.723660</td>\n",
       "      <td>-0.691800</td>\n",
       "      <td>12.757200</td>\n",
       "      <td>7.716760</td>\n",
       "      <td>2.235234</td>\n",
       "      <td>4.562744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>-354.029236</td>\n",
       "      <td>172.662659</td>\n",
       "      <td>72.229408</td>\n",
       "      <td>51.822090</td>\n",
       "      <td>-19.475491</td>\n",
       "      <td>24.674398</td>\n",
       "      <td>-14.183729</td>\n",
       "      <td>-14.277061</td>\n",
       "      <td>-8.532803</td>\n",
       "      <td>3.395573</td>\n",
       "      <td>14.948679</td>\n",
       "      <td>-4.153752</td>\n",
       "      <td>7.948050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>-363.935699</td>\n",
       "      <td>166.532837</td>\n",
       "      <td>73.193100</td>\n",
       "      <td>50.661980</td>\n",
       "      <td>-21.652119</td>\n",
       "      <td>21.548904</td>\n",
       "      <td>-14.202366</td>\n",
       "      <td>-13.243938</td>\n",
       "      <td>-2.112081</td>\n",
       "      <td>3.580634</td>\n",
       "      <td>10.965590</td>\n",
       "      <td>-10.593177</td>\n",
       "      <td>3.021251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>-364.039581</td>\n",
       "      <td>163.347534</td>\n",
       "      <td>80.410004</td>\n",
       "      <td>55.608833</td>\n",
       "      <td>-18.868038</td>\n",
       "      <td>21.568939</td>\n",
       "      <td>-14.416084</td>\n",
       "      <td>-12.026213</td>\n",
       "      <td>-2.639414</td>\n",
       "      <td>5.210083</td>\n",
       "      <td>14.799844</td>\n",
       "      <td>-4.204784</td>\n",
       "      <td>2.161280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>-360.334564</td>\n",
       "      <td>167.725281</td>\n",
       "      <td>81.819809</td>\n",
       "      <td>53.282486</td>\n",
       "      <td>-13.211727</td>\n",
       "      <td>18.665279</td>\n",
       "      <td>-17.974466</td>\n",
       "      <td>-14.677999</td>\n",
       "      <td>-6.362213</td>\n",
       "      <td>-0.718999</td>\n",
       "      <td>20.342644</td>\n",
       "      <td>-3.675610</td>\n",
       "      <td>-3.875287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>-350.499359</td>\n",
       "      <td>175.658173</td>\n",
       "      <td>78.769157</td>\n",
       "      <td>45.172649</td>\n",
       "      <td>-10.140876</td>\n",
       "      <td>15.867226</td>\n",
       "      <td>-21.012016</td>\n",
       "      <td>-10.770565</td>\n",
       "      <td>-3.238189</td>\n",
       "      <td>0.111002</td>\n",
       "      <td>20.215496</td>\n",
       "      <td>-3.303527</td>\n",
       "      <td>-4.188798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>341 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mfcc1       mfcc2      mfcc3      mfcc4      mfcc5      mfcc6  \\\n",
       "0   -272.275146  208.902557  44.434441  40.349213 -25.458517  12.826863   \n",
       "1   -292.371613  203.497162  55.854485  54.128845 -19.807659  14.410148   \n",
       "2   -326.458984  179.993637  64.711746  65.344246 -17.435101  19.880333   \n",
       "3   -324.657288  174.853928  61.641129  64.695351 -10.726300  23.473757   \n",
       "4   -317.942169  182.751175  64.051483  59.415588 -17.222746  18.475574   \n",
       "..          ...         ...        ...        ...        ...        ...   \n",
       "336 -354.029236  172.662659  72.229408  51.822090 -19.475491  24.674398   \n",
       "337 -363.935699  166.532837  73.193100  50.661980 -21.652119  21.548904   \n",
       "338 -364.039581  163.347534  80.410004  55.608833 -18.868038  21.568939   \n",
       "339 -360.334564  167.725281  81.819809  53.282486 -13.211727  18.665279   \n",
       "340 -350.499359  175.658173  78.769157  45.172649 -10.140876  15.867226   \n",
       "\n",
       "         mfcc7      mfcc8     mfcc9     mfcc10     mfcc11     mfcc12    mfcc13  \n",
       "0    -3.920654  -8.411410  3.417778   7.566922  -2.498518  -6.284049 -2.326992  \n",
       "1    -1.129526  -7.547229  2.966858  11.841558   1.122357  -0.466148 -0.014877  \n",
       "2     2.197647  -1.880868 -4.580058   4.086713   3.976766   1.293952  6.717286  \n",
       "3    -8.347025  -9.129495 -7.556191  10.262231   8.042992   2.768127  9.962308  \n",
       "4    -8.616613 -10.723660 -0.691800  12.757200   7.716760   2.235234  4.562744  \n",
       "..         ...        ...       ...        ...        ...        ...       ...  \n",
       "336 -14.183729 -14.277061 -8.532803   3.395573  14.948679  -4.153752  7.948050  \n",
       "337 -14.202366 -13.243938 -2.112081   3.580634  10.965590 -10.593177  3.021251  \n",
       "338 -14.416084 -12.026213 -2.639414   5.210083  14.799844  -4.204784  2.161280  \n",
       "339 -17.974466 -14.677999 -6.362213  -0.718999  20.342644  -3.675610 -3.875287  \n",
       "340 -21.012016 -10.770565 -3.238189   0.111002  20.215496  -3.303527 -4.188798  \n",
       "\n",
       "[341 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(healthy[0][2]) #1번 : 파일. 2번:mfcc\n",
    "headers = \"mfcc1 mfcc2 mfcc3 mfcc4 mfcc5 mfcc6 mfcc7 mfcc8 mfcc9 mfcc10 mfcc11 mfcc12 mfcc13\".split()\n",
    "pd.DataFrame(healthy[1].T,columns=headers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "186be135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthy[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73d328bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "del pathology\n",
    "del healthy\n",
    "del pathology_sig\n",
    "del healthy_sig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23a4c15",
   "metadata": {},
   "source": [
    "# 데이터 나누기 - Stratified KFold\n",
    "\n",
    "- pathology : 1195 / healthy : 687 . 총 : 1882\n",
    "- k = 5\n",
    "- random over sampling 추가 ( healthy 데이터가 부족하기 때문)\n",
    "- 변경 후 -> pathology : 1195 / healthy : 1195 / 총: 2390"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7b3872f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pathology :  1195\n",
      "Healthy:  687\n",
      "총 데이터수 :  1882\n",
      "before dataset shape Counter({'pathology': 1195, 'healthy': 687})\n",
      "Resampled dataset shape Counter({'pathology': 1195, 'healthy': 1195})\n"
     ]
    }
   ],
   "source": [
    "#1. train, test 나누기\n",
    "# random over sampling\n",
    "\n",
    "import os\n",
    "import random #데이터 shuffle 사용\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "pathology = glob('../../voice_data/pathology_new/u/export/*.wav')\n",
    "healthy = glob('../../voice_data/healthy_new/u/export/*.wav')\n",
    "print(\"Pathology : \",len(pathology))\n",
    "print(\"Healthy: \",len(healthy))\n",
    "\n",
    "X = pathology+healthy # path 데이터 합\n",
    "print(\"총 데이터수 : \",len(X))\n",
    "Y = [] # 라벨\n",
    "for idx,x in enumerate(X):\n",
    "    if idx<1195:\n",
    "        Y.append(\"pathology\")\n",
    "    else:\n",
    "        Y.append(\"healthy\")\n",
    "X = np.array(X).reshape(-1,1)#각 데이터를 다 행으로 넣음. (1194,1)\n",
    "#Y = np.array(Y)\n",
    "ros = RandomOverSampler(random_state = 123)\n",
    "X_res,Y_res = ros.fit_resample(X,Y)\n",
    "\n",
    "print('before dataset shape {}'.format(Counter(Y)) )\n",
    "print('Resampled dataset shape {}'.format(Counter(Y_res)) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed918e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['../../voice_data/pathology_new/u/export\\\\101-u_n.wav'],\n",
       "       ['../../voice_data/pathology_new/u/export\\\\1039-u_n.wav'],\n",
       "       ['../../voice_data/pathology_new/u/export\\\\1042-u_n.wav'],\n",
       "       ...,\n",
       "       ['../../voice_data/healthy_new/u/export\\\\1524-u_n.wav'],\n",
       "       ['../../voice_data/healthy_new/u/export\\\\1350-u_n.wav'],\n",
       "       ['../../voice_data/healthy_new/u/export\\\\72-u_n.wav']],\n",
       "      dtype='<U52')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9ef5184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 데이터수 :  2390\n",
      "복사된 수 :  508\n"
     ]
    }
   ],
   "source": [
    "#원래대로 돌리기\n",
    "X=X_res.reshape(1, -1)\n",
    "print( '총 데이터수 : ',X[0].size )\n",
    "print(  '복사된 수 : ',X[0].size - np.unique(X[0]).size )\n",
    "\n",
    "X=X[0].tolist()\n",
    "Y=Y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fada6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 : 1\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 956, 'pathology': 956}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 239, 'pathology': 239} \n",
      "\n",
      "교차 검증 : 2\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 956, 'pathology': 956}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 239, 'pathology': 239} \n",
      "\n",
      "교차 검증 : 3\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 956, 'pathology': 956}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 239, 'pathology': 239} \n",
      "\n",
      "교차 검증 : 4\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 956, 'pathology': 956}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 239, 'pathology': 239} \n",
      "\n",
      "교차 검증 : 5\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 956, 'pathology': 956}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 239, 'pathology': 239} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. train, test 나누기\n",
    "#stratified kfold\n",
    "import os\n",
    "import random #데이터 shuffle 사용\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "skf_iris = StratifiedKFold(n_splits=5)\n",
    "cnt_iter = 0\n",
    "\n",
    "X_train_list = [] #데이터 셋 보관\n",
    "Y_train_list = []\n",
    "\n",
    "X_test_list = []\n",
    "Y_test_list = []\n",
    "\n",
    "for train_idx, test_idx in skf_iris.split(X,Y):\n",
    "    \n",
    "    #split으로 반환된 인덱스를 이용하여, 학습 검증용 테스트 데이터 추출\n",
    "    cnt_iter += 1\n",
    "    X_train, X_test = [X[idx] for idx in train_idx.tolist() ], [X[idx] for idx in test_idx.tolist() ]\n",
    "    Y_train, Y_test = [Y[idx] for idx in train_idx.tolist() ], [Y[idx] for idx in test_idx.tolist() ]\n",
    "    \n",
    "    X_train_list.append(X_train)\n",
    "    X_test_list.append(X_test)\n",
    "    \n",
    "    Y_test_list.append(Y_test)\n",
    "    Y_train_list.append(Y_train)\n",
    "    \n",
    "    #학습 및 예측\n",
    "    \n",
    "    label_train = Y_train\n",
    "    label_test = Y_test\n",
    "    unique_train, train_counts = np.unique(label_train, return_counts = True)\n",
    "    unique_test, test_counts = np.unique(label_test, return_counts = True)\n",
    "    \n",
    "    uniq_cnt_train = dict(zip(unique_train, train_counts))\n",
    "    uniq_cnt_test = dict(zip(unique_test, test_counts))\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('교차 검증 : {}'.format(cnt_iter))\n",
    "    print('학습 레이블 데이터 분포 : \\n', uniq_cnt_train)\n",
    "    print('검증 레이블 데이터 분포 : \\n', uniq_cnt_test,'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a663f0",
   "metadata": {},
   "source": [
    "# 데이터 정의\n",
    "- 추가적으로 데이터의 크기를 맞춰주기 위해 3초로 padding 및 truncate 실시 https://sequencedata.tistory.com/25 FixAudioLength\n",
    "- 논문에서는 400frame으로 설정.\n",
    "- 전처리 방법 결정.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2febf8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "classes = [\"pathology\",\"healthy\"]\n",
    "sr=50000\n",
    "win_length =  np.int64(50000/40) # 1250\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다.\n",
    "\n",
    "class svd_dataset(Dataset):\n",
    "    def __init__(self,data_path_list,classes,data_num,training,transform=None):\n",
    "        #클래스에서 사용할 인자를 받아 인스턴스 변수로 저장하는 일을 한다.\n",
    "        #예를들면, 이미지의 경로 리스트를 저장하는 일을 하게 된다.\n",
    "        \n",
    "        #data_num : k 개 데이터 셋 중 어떤것을 쓸지\n",
    "        #test인지 아닌지.\n",
    "        \n",
    "        self.path_list = data_path_list[data_num]\n",
    "        self.data_num = data_num\n",
    "        self.training = training\n",
    "        self.label = svd_dataset.get_label(self.path_list,training,data_num)\n",
    "        self.classes=classes\n",
    "        self.transform=transform\n",
    "        \n",
    "    \n",
    "    @classmethod\n",
    "    def get_label(cls,data_path_list,training,data_num):\n",
    "        label_list=[]\n",
    "        \n",
    "        if training:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_train_list[data_num][idx])\n",
    "        else:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_test_list[data_num][idx])\n",
    "        #print(label_list)\n",
    "        return label_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "        #데이터 셋의 길이를 정수로 반환한다. \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        1. path를 받아서, 소리에서 mfcc를 추출\n",
    "        2. mfcc를 500프레임으로 패딩.\n",
    "        3. resnet에 사용되기 위해 3채널로 복사(rgb 처럼)\n",
    "        4. 0~1 정규화\n",
    "        \n",
    "        \"\"\"\n",
    "        sig, sr = librosa.load(self.path_list[idx], sr=50000)# 논문에서 f_s = 50 000HZ\n",
    "        \n",
    "        MFCCs = librosa.feature.mfcc(sig, sr, win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "        #mfcc 400 FRAME이 되도록 패딩.\n",
    "        length = 400\n",
    "        pad2d = lambda a, i: a[:, 0:i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0], i-a.shape[1]))))\n",
    "        MFCCs = pad2d(MFCCs, length)\n",
    "        MFCCs= MFCCs.T\n",
    "        \n",
    "        if self.transform:\n",
    "            #print('transform')\n",
    "            MFCCs=self.transform(MFCCs).type(torch.float32)# 데이터 0~1 정규화\n",
    "            MFCCs=torch.stack([MFCCs,MFCCs,MFCCs])# 3채널로 복사.\n",
    "            MFCCs = MFCCs.squeeze(dim=1)\n",
    "        else:\n",
    "            #print(\"else\")\n",
    "            MFCCs = torch.from_numpy(MFCCs).type(torch.float32)\n",
    "            MFCCs=MFCCs.unsqueeze(0) #cnn 사용위해서 추가\n",
    "            #MFCCs = MFCCs.permute(2, 0, 1)\n",
    "        return MFCCs, self.classes.index(self.label[idx])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d05129d",
   "metadata": {},
   "source": [
    "# 데이터 로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89052fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. 하이퍼 파라미터\n",
    "BATCH_SIZE =  30 #한 배치당 30개 음성데이터 # 32 배수시에, 1개만 남는 경우가 발생해서.\n",
    "EPOCHS = 40 # 전체 데이터 셋을 40번 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bba97b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA LOADER 함수가 BATCH_size 단위로 분리해 지정.\n",
    "\n",
    "#확인을 위해 데이터셋 하나만 확인\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                           svd_dataset(\n",
    "                                               X_train_list,\n",
    "                                               classes,\n",
    "                                               transform = transforms.ToTensor(),#이걸 composed로 고쳐서 전처리 하도록 수정.\n",
    "                                               data_num=0,\n",
    "                                               training=True\n",
    "                                           ),\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True,\n",
    "                                           ) # 순서가 암기되는것을 막기위해.\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                           svd_dataset(\n",
    "                                               X_test_list,\n",
    "                                               classes,\n",
    "                                               transform = transforms.ToTensor(),\n",
    "                                               data_num=0,\n",
    "                                               training=False\n",
    "                                           ),\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True,) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b15a86",
   "metadata": {},
   "source": [
    "# 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f866237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :  torch.Size([30, 3, 400, 13]) type: torch.FloatTensor\n",
      "Y_train :  torch.Size([30]) type: torch.LongTensor\n",
      "tensor(1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x29d8bff1d60>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. 데이터 확인하기\n",
    "for (X_train,Y_train) in train_loader:\n",
    "    print(\"X_train : \",X_train.size(),'type:',X_train.type())\n",
    "    print(\"Y_train : \",Y_train.size(),'type:',Y_train.type())\n",
    "    break\n",
    "    \n",
    "print(Y_train[0])\n",
    "librosa.display.specshow(X_train[0][0].numpy().T, sr=50000, x_axis='time')\n",
    "#batch: 32 / frame수: 400  /  feature수: 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a45b51bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valid :  torch.Size([30, 3, 400, 13]) type: torch.FloatTensor\n",
      "Y_valid :  torch.Size([30]) type: torch.LongTensor\n",
      "tensor(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x29dacea7520>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#valiation set 확인\n",
    "for (X_valid,Y_valid) in validation_loader:\n",
    "    print(\"X_valid : \",X_valid.size(),'type:',X_valid.type())\n",
    "    print(\"Y_valid : \",Y_valid.size(),'type:',Y_valid.type())\n",
    "    break\n",
    "\n",
    "print(Y_valid[0])\n",
    "librosa.display.specshow(X_valid[0][0].numpy().T, sr=50000, x_axis='time')\n",
    "#batch: 32 / 3채널 / frame수: 400  /  feature수: 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec40ea4",
   "metadata": {},
   "source": [
    "# RESNET18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e1d59a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 \n",
    "# pretrained\n",
    "\n",
    "\n",
    "def model_initialize():\n",
    "    model = models.resnet18(pretrained=True).cuda()\n",
    "    model.ftrs = model.fc.in_features # in_features : fully connected의 입력수.\n",
    "    num_ftrs = model.fc.in_features\n",
    "\n",
    "    model.fc = nn.Sequential(nn.Linear(num_ftrs, 256),\n",
    "                             nn.BatchNorm1d(256),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(256,128),\n",
    "                             nn.BatchNorm1d(128),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(128,64),\n",
    "                             nn.BatchNorm1d(64),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(64,50),\n",
    "                             nn.BatchNorm1d(50),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(50,2)\n",
    "                            )\n",
    "\n",
    "    model = model.cuda()\n",
    "    return model\n",
    "model=model_initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c26ff30a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.5, inplace=False)\n",
      "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.5, inplace=False)\n",
      "    (12): Linear(in_features=64, out_features=50, bias=True)\n",
      "    (13): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU()\n",
      "    (15): Dropout(p=0.5, inplace=False)\n",
      "    (16): Linear(in_features=50, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6097d312",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 200, 7]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 200, 7]             128\n",
      "              ReLU-3           [-1, 64, 200, 7]               0\n",
      "         MaxPool2d-4           [-1, 64, 100, 4]               0\n",
      "            Conv2d-5           [-1, 64, 100, 4]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 100, 4]             128\n",
      "              ReLU-7           [-1, 64, 100, 4]               0\n",
      "            Conv2d-8           [-1, 64, 100, 4]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 100, 4]             128\n",
      "             ReLU-10           [-1, 64, 100, 4]               0\n",
      "       BasicBlock-11           [-1, 64, 100, 4]               0\n",
      "           Conv2d-12           [-1, 64, 100, 4]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 100, 4]             128\n",
      "             ReLU-14           [-1, 64, 100, 4]               0\n",
      "           Conv2d-15           [-1, 64, 100, 4]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 100, 4]             128\n",
      "             ReLU-17           [-1, 64, 100, 4]               0\n",
      "       BasicBlock-18           [-1, 64, 100, 4]               0\n",
      "           Conv2d-19           [-1, 128, 50, 2]          73,728\n",
      "      BatchNorm2d-20           [-1, 128, 50, 2]             256\n",
      "             ReLU-21           [-1, 128, 50, 2]               0\n",
      "           Conv2d-22           [-1, 128, 50, 2]         147,456\n",
      "      BatchNorm2d-23           [-1, 128, 50, 2]             256\n",
      "           Conv2d-24           [-1, 128, 50, 2]           8,192\n",
      "      BatchNorm2d-25           [-1, 128, 50, 2]             256\n",
      "             ReLU-26           [-1, 128, 50, 2]               0\n",
      "       BasicBlock-27           [-1, 128, 50, 2]               0\n",
      "           Conv2d-28           [-1, 128, 50, 2]         147,456\n",
      "      BatchNorm2d-29           [-1, 128, 50, 2]             256\n",
      "             ReLU-30           [-1, 128, 50, 2]               0\n",
      "           Conv2d-31           [-1, 128, 50, 2]         147,456\n",
      "      BatchNorm2d-32           [-1, 128, 50, 2]             256\n",
      "             ReLU-33           [-1, 128, 50, 2]               0\n",
      "       BasicBlock-34           [-1, 128, 50, 2]               0\n",
      "           Conv2d-35           [-1, 256, 25, 1]         294,912\n",
      "      BatchNorm2d-36           [-1, 256, 25, 1]             512\n",
      "             ReLU-37           [-1, 256, 25, 1]               0\n",
      "           Conv2d-38           [-1, 256, 25, 1]         589,824\n",
      "      BatchNorm2d-39           [-1, 256, 25, 1]             512\n",
      "           Conv2d-40           [-1, 256, 25, 1]          32,768\n",
      "      BatchNorm2d-41           [-1, 256, 25, 1]             512\n",
      "             ReLU-42           [-1, 256, 25, 1]               0\n",
      "       BasicBlock-43           [-1, 256, 25, 1]               0\n",
      "           Conv2d-44           [-1, 256, 25, 1]         589,824\n",
      "      BatchNorm2d-45           [-1, 256, 25, 1]             512\n",
      "             ReLU-46           [-1, 256, 25, 1]               0\n",
      "           Conv2d-47           [-1, 256, 25, 1]         589,824\n",
      "      BatchNorm2d-48           [-1, 256, 25, 1]             512\n",
      "             ReLU-49           [-1, 256, 25, 1]               0\n",
      "       BasicBlock-50           [-1, 256, 25, 1]               0\n",
      "           Conv2d-51           [-1, 512, 13, 1]       1,179,648\n",
      "      BatchNorm2d-52           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-53           [-1, 512, 13, 1]               0\n",
      "           Conv2d-54           [-1, 512, 13, 1]       2,359,296\n",
      "      BatchNorm2d-55           [-1, 512, 13, 1]           1,024\n",
      "           Conv2d-56           [-1, 512, 13, 1]         131,072\n",
      "      BatchNorm2d-57           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-58           [-1, 512, 13, 1]               0\n",
      "       BasicBlock-59           [-1, 512, 13, 1]               0\n",
      "           Conv2d-60           [-1, 512, 13, 1]       2,359,296\n",
      "      BatchNorm2d-61           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-62           [-1, 512, 13, 1]               0\n",
      "           Conv2d-63           [-1, 512, 13, 1]       2,359,296\n",
      "      BatchNorm2d-64           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-65           [-1, 512, 13, 1]               0\n",
      "       BasicBlock-66           [-1, 512, 13, 1]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                  [-1, 256]         131,328\n",
      "      BatchNorm1d-69                  [-1, 256]             512\n",
      "             ReLU-70                  [-1, 256]               0\n",
      "          Dropout-71                  [-1, 256]               0\n",
      "           Linear-72                  [-1, 128]          32,896\n",
      "      BatchNorm1d-73                  [-1, 128]             256\n",
      "             ReLU-74                  [-1, 128]               0\n",
      "          Dropout-75                  [-1, 128]               0\n",
      "           Linear-76                   [-1, 64]           8,256\n",
      "      BatchNorm1d-77                   [-1, 64]             128\n",
      "             ReLU-78                   [-1, 64]               0\n",
      "          Dropout-79                   [-1, 64]               0\n",
      "           Linear-80                   [-1, 50]           3,250\n",
      "      BatchNorm1d-81                   [-1, 50]             100\n",
      "             ReLU-82                   [-1, 50]               0\n",
      "          Dropout-83                   [-1, 50]               0\n",
      "           Linear-84                    [-1, 2]             102\n",
      "================================================================\n",
      "Total params: 11,353,340\n",
      "Trainable params: 11,353,340\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 8.16\n",
      "Params size (MB): 43.31\n",
      "Estimated Total Size (MB): 51.52\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# get the model summary\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 400, 13), device=DEVICE.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f2ca15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. 학습\n",
    "def train(model,train_loader,optimizer, log_interval):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    train_loss = 0\n",
    "    for batch_idx,(image,label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        #데이터들 장비에 할당\n",
    "        optimizer.zero_grad() # device 에 저장된 gradient 제거\n",
    "        output = model(image) # model로 output을 계산\n",
    "        loss = criterion(output, label) #loss 계산\n",
    "        train_loss += loss.item()\n",
    "        prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "        correct += prediction.eq(label.view_as(prediction)).sum().item()# 아웃풋이 배치 사이즈 32개라서.\n",
    "        loss.backward() # loss 값을 이용해 gradient를 계산\n",
    "        optimizer.step() # Gradient 값을 이용해 파라미터 업데이트.\n",
    "    train_loss/=len(train_loader.dataset)\n",
    "    train_accuracy = 100. * correct / len(train_loader.dataset)\n",
    "    return train_loss,train_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b09341bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. 학습 진행하며, validation 데이터로 모델 성능확인\n",
    "def evaluate(model,valid_loader):\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    #no_grad : 그래디언트 값 계산 막기.\n",
    "    with torch.no_grad():\n",
    "        for image, label in valid_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            valid_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()# 아웃풋이 배치 사이즈 32개라서.\n",
    "            #true.false값을 sum해줌. item\n",
    "        valid_loss /= len(valid_loader.dataset)\n",
    "        valid_accuracy = 100. * correct / len(valid_loader.dataset)\n",
    "        return valid_loss,valid_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae179080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 로더 제작 함수\n",
    "\n",
    "def load_data(data_ind):\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_dataset(\n",
    "                                                   X_train_list,\n",
    "                                                   classes,\n",
    "                                                   transform = transforms.ToTensor(),#이걸 composed로 고쳐서 전처리 하도록 수정.\n",
    "                                                   data_num=data_ind,\n",
    "                                                   training=True\n",
    "                                               ),\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = True,\n",
    "                                               ) # 순서가 암기되는것을 막기위해.\n",
    "\n",
    "    validation_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_dataset(\n",
    "                                                   X_test_list,\n",
    "                                                   classes,\n",
    "                                                   transform = transforms.ToTensor(),\n",
    "                                                   data_num=data_ind,\n",
    "                                                   training=False\n",
    "                                               ),\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = True,) \n",
    "    return train_loader,validation_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7c8c86f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0244\t Train Acc:50.73 %  | \tValid Loss:0.0227 \tValid Acc: 57.74 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.022689).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0244\t Train Acc:51.05 %  | \tValid Loss:0.0225 \tValid Acc: 60.46 %\n",
      "\n",
      "Validation loss decreased (0.022689 --> 0.022506).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0245\t Train Acc:51.78 %  | \tValid Loss:0.0222 \tValid Acc: 59.00 %\n",
      "\n",
      "Validation loss decreased (0.022506 --> 0.022206).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0239\t Train Acc:52.88 %  | \tValid Loss:0.0220 \tValid Acc: 64.64 %\n",
      "\n",
      "Validation loss decreased (0.022206 --> 0.021962).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0234\t Train Acc:53.87 %  | \tValid Loss:0.0218 \tValid Acc: 64.02 %\n",
      "\n",
      "Validation loss decreased (0.021962 --> 0.021780).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0231\t Train Acc:55.13 %  | \tValid Loss:0.0212 \tValid Acc: 63.60 %\n",
      "\n",
      "Validation loss decreased (0.021780 --> 0.021205).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0231\t Train Acc:55.70 %  | \tValid Loss:0.0207 \tValid Acc: 66.11 %\n",
      "\n",
      "Validation loss decreased (0.021205 --> 0.020729).  Saving model ...\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0229\t Train Acc:56.38 %  | \tValid Loss:0.0203 \tValid Acc: 64.02 %\n",
      "\n",
      "Validation loss decreased (0.020729 --> 0.020342).  Saving model ...\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0227\t Train Acc:58.16 %  | \tValid Loss:0.0209 \tValid Acc: 62.97 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0221\t Train Acc:57.01 %  | \tValid Loss:0.0208 \tValid Acc: 66.95 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0221\t Train Acc:58.79 %  | \tValid Loss:0.0201 \tValid Acc: 65.90 %\n",
      "\n",
      "Validation loss decreased (0.020342 --> 0.020092).  Saving model ...\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0217\t Train Acc:60.83 %  | \tValid Loss:0.0201 \tValid Acc: 67.78 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0208\t Train Acc:63.28 %  | \tValid Loss:0.0195 \tValid Acc: 68.62 %\n",
      "\n",
      "Validation loss decreased (0.020092 --> 0.019517).  Saving model ...\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0204\t Train Acc:66.27 %  | \tValid Loss:0.0207 \tValid Acc: 63.81 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0198\t Train Acc:66.63 %  | \tValid Loss:0.0197 \tValid Acc: 66.53 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0197\t Train Acc:69.61 %  | \tValid Loss:0.0198 \tValid Acc: 65.69 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0191\t Train Acc:69.61 %  | \tValid Loss:0.0189 \tValid Acc: 70.92 %\n",
      "\n",
      "Validation loss decreased (0.019517 --> 0.018935).  Saving model ...\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0180\t Train Acc:74.06 %  | \tValid Loss:0.0201 \tValid Acc: 69.25 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0174\t Train Acc:75.58 %  | \tValid Loss:0.0195 \tValid Acc: 68.20 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:20]\t Train Loss:0.0174\t Train Acc:75.52 %  | \tValid Loss:0.0223 \tValid Acc: 61.92 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:21]\t Train Loss:0.0163\t Train Acc:77.93 %  | \tValid Loss:0.0205 \tValid Acc: 66.11 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:22]\t Train Loss:0.0153\t Train Acc:81.01 %  | \tValid Loss:0.0193 \tValid Acc: 70.71 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[1 교차검증] Early stopping\n",
      "[2 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0254\t Train Acc:50.00 %  | \tValid Loss:0.0235 \tValid Acc: 50.21 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.023452).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0251\t Train Acc:50.58 %  | \tValid Loss:0.0238 \tValid Acc: 50.00 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0244\t Train Acc:52.62 %  | \tValid Loss:0.0230 \tValid Acc: 52.09 %\n",
      "\n",
      "Validation loss decreased (0.023452 --> 0.023032).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0236\t Train Acc:54.18 %  | \tValid Loss:0.0229 \tValid Acc: 54.81 %\n",
      "\n",
      "Validation loss decreased (0.023032 --> 0.022909).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0235\t Train Acc:55.44 %  | \tValid Loss:0.0231 \tValid Acc: 56.07 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0229\t Train Acc:56.80 %  | \tValid Loss:0.0233 \tValid Acc: 57.74 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0228\t Train Acc:59.26 %  | \tValid Loss:0.0230 \tValid Acc: 57.95 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0222\t Train Acc:60.04 %  | \tValid Loss:0.0225 \tValid Acc: 58.58 %\n",
      "\n",
      "Validation loss decreased (0.022909 --> 0.022522).  Saving model ...\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0213\t Train Acc:61.66 %  | \tValid Loss:0.0221 \tValid Acc: 63.18 %\n",
      "\n",
      "Validation loss decreased (0.022522 --> 0.022093).  Saving model ...\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0213\t Train Acc:63.96 %  | \tValid Loss:0.0231 \tValid Acc: 54.60 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0203\t Train Acc:67.00 %  | \tValid Loss:0.0225 \tValid Acc: 62.13 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0201\t Train Acc:69.72 %  | \tValid Loss:0.0226 \tValid Acc: 59.00 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0191\t Train Acc:70.50 %  | \tValid Loss:0.0227 \tValid Acc: 58.79 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0187\t Train Acc:72.28 %  | \tValid Loss:0.0224 \tValid Acc: 60.88 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[2 교차검증] Early stopping\n",
      "[3 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0256\t Train Acc:47.96 %  | \tValid Loss:0.0232 \tValid Acc: 52.93 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.023208).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0245\t Train Acc:51.46 %  | \tValid Loss:0.0233 \tValid Acc: 48.33 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0242\t Train Acc:51.94 %  | \tValid Loss:0.0229 \tValid Acc: 49.58 %\n",
      "\n",
      "Validation loss decreased (0.023208 --> 0.022927).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0237\t Train Acc:53.97 %  | \tValid Loss:0.0229 \tValid Acc: 52.51 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0234\t Train Acc:54.39 %  | \tValid Loss:0.0229 \tValid Acc: 53.35 %\n",
      "\n",
      "Validation loss decreased (0.022927 --> 0.022907).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0229\t Train Acc:57.37 %  | \tValid Loss:0.0226 \tValid Acc: 53.77 %\n",
      "\n",
      "Validation loss decreased (0.022907 --> 0.022556).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0223\t Train Acc:58.73 %  | \tValid Loss:0.0224 \tValid Acc: 59.83 %\n",
      "\n",
      "Validation loss decreased (0.022556 --> 0.022384).  Saving model ...\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0219\t Train Acc:61.98 %  | \tValid Loss:0.0220 \tValid Acc: 59.62 %\n",
      "\n",
      "Validation loss decreased (0.022384 --> 0.022011).  Saving model ...\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0218\t Train Acc:61.82 %  | \tValid Loss:0.0219 \tValid Acc: 59.00 %\n",
      "\n",
      "Validation loss decreased (0.022011 --> 0.021871).  Saving model ...\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0215\t Train Acc:63.65 %  | \tValid Loss:0.0215 \tValid Acc: 62.13 %\n",
      "\n",
      "Validation loss decreased (0.021871 --> 0.021541).  Saving model ...\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0206\t Train Acc:65.27 %  | \tValid Loss:0.0215 \tValid Acc: 60.88 %\n",
      "\n",
      "Validation loss decreased (0.021541 --> 0.021474).  Saving model ...\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0203\t Train Acc:68.15 %  | \tValid Loss:0.0214 \tValid Acc: 61.30 %\n",
      "\n",
      "Validation loss decreased (0.021474 --> 0.021379).  Saving model ...\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0198\t Train Acc:68.41 %  | \tValid Loss:0.0213 \tValid Acc: 62.97 %\n",
      "\n",
      "Validation loss decreased (0.021379 --> 0.021334).  Saving model ...\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0193\t Train Acc:69.61 %  | \tValid Loss:0.0219 \tValid Acc: 58.16 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0199\t Train Acc:67.94 %  | \tValid Loss:0.0217 \tValid Acc: 59.41 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0188\t Train Acc:72.33 %  | \tValid Loss:0.0216 \tValid Acc: 60.88 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0180\t Train Acc:72.70 %  | \tValid Loss:0.0197 \tValid Acc: 70.29 %\n",
      "\n",
      "Validation loss decreased (0.021334 --> 0.019740).  Saving model ...\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0170\t Train Acc:76.31 %  | \tValid Loss:0.0199 \tValid Acc: 62.76 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0164\t Train Acc:77.82 %  | \tValid Loss:0.0226 \tValid Acc: 63.18 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:20]\t Train Loss:0.0160\t Train Acc:77.62 %  | \tValid Loss:0.0202 \tValid Acc: 69.04 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:21]\t Train Loss:0.0146\t Train Acc:81.28 %  | \tValid Loss:0.0210 \tValid Acc: 65.48 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH:22]\t Train Loss:0.0137\t Train Acc:82.27 %  | \tValid Loss:0.0239 \tValid Acc: 61.09 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[3 교차검증] Early stopping\n",
      "[4 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0252\t Train Acc:50.68 %  | \tValid Loss:0.0231 \tValid Acc: 50.42 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.023099).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0249\t Train Acc:50.84 %  | \tValid Loss:0.0231 \tValid Acc: 55.44 %\n",
      "\n",
      "Validation loss decreased (0.023099 --> 0.023098).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0247\t Train Acc:52.09 %  | \tValid Loss:0.0228 \tValid Acc: 58.37 %\n",
      "\n",
      "Validation loss decreased (0.023098 --> 0.022822).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0244\t Train Acc:51.78 %  | \tValid Loss:0.0230 \tValid Acc: 52.72 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0242\t Train Acc:53.24 %  | \tValid Loss:0.0222 \tValid Acc: 59.21 %\n",
      "\n",
      "Validation loss decreased (0.022822 --> 0.022170).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0238\t Train Acc:54.34 %  | \tValid Loss:0.0222 \tValid Acc: 61.09 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0242\t Train Acc:54.08 %  | \tValid Loss:0.0216 \tValid Acc: 60.88 %\n",
      "\n",
      "Validation loss decreased (0.022170 --> 0.021648).  Saving model ...\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0234\t Train Acc:57.58 %  | \tValid Loss:0.0215 \tValid Acc: 62.97 %\n",
      "\n",
      "Validation loss decreased (0.021648 --> 0.021539).  Saving model ...\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0229\t Train Acc:56.69 %  | \tValid Loss:0.0211 \tValid Acc: 64.64 %\n",
      "\n",
      "Validation loss decreased (0.021539 --> 0.021077).  Saving model ...\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0227\t Train Acc:56.54 %  | \tValid Loss:0.0219 \tValid Acc: 62.34 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0226\t Train Acc:57.85 %  | \tValid Loss:0.0209 \tValid Acc: 64.85 %\n",
      "\n",
      "Validation loss decreased (0.021077 --> 0.020944).  Saving model ...\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0223\t Train Acc:59.83 %  | \tValid Loss:0.0214 \tValid Acc: 64.44 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0220\t Train Acc:60.30 %  | \tValid Loss:0.0212 \tValid Acc: 63.81 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0213\t Train Acc:64.07 %  | \tValid Loss:0.0213 \tValid Acc: 61.30 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0214\t Train Acc:62.13 %  | \tValid Loss:0.0212 \tValid Acc: 63.18 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0208\t Train Acc:65.38 %  | \tValid Loss:0.0206 \tValid Acc: 67.15 %\n",
      "\n",
      "Validation loss decreased (0.020944 --> 0.020640).  Saving model ...\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0206\t Train Acc:66.42 %  | \tValid Loss:0.0193 \tValid Acc: 69.87 %\n",
      "\n",
      "Validation loss decreased (0.020640 --> 0.019261).  Saving model ...\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0199\t Train Acc:68.31 %  | \tValid Loss:0.0205 \tValid Acc: 65.69 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0197\t Train Acc:69.14 %  | \tValid Loss:0.0198 \tValid Acc: 69.04 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:20]\t Train Loss:0.0188\t Train Acc:71.60 %  | \tValid Loss:0.0196 \tValid Acc: 68.20 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:21]\t Train Loss:0.0184\t Train Acc:74.27 %  | \tValid Loss:0.0201 \tValid Acc: 66.74 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:22]\t Train Loss:0.0175\t Train Acc:75.89 %  | \tValid Loss:0.0181 \tValid Acc: 76.57 %\n",
      "\n",
      "Validation loss decreased (0.019261 --> 0.018131).  Saving model ...\n",
      "\n",
      "[EPOCH:23]\t Train Loss:0.0162\t Train Acc:79.34 %  | \tValid Loss:0.0181 \tValid Acc: 71.34 %\n",
      "\n",
      "Validation loss decreased (0.018131 --> 0.018115).  Saving model ...\n",
      "\n",
      "[EPOCH:24]\t Train Loss:0.0157\t Train Acc:81.54 %  | \tValid Loss:0.0173 \tValid Acc: 76.36 %\n",
      "\n",
      "Validation loss decreased (0.018115 --> 0.017269).  Saving model ...\n",
      "\n",
      "[EPOCH:25]\t Train Loss:0.0153\t Train Acc:80.75 %  | \tValid Loss:0.0208 \tValid Acc: 64.64 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:26]\t Train Loss:0.0146\t Train Acc:82.74 %  | \tValid Loss:0.0153 \tValid Acc: 81.38 %\n",
      "\n",
      "Validation loss decreased (0.017269 --> 0.015276).  Saving model ...\n",
      "\n",
      "[EPOCH:27]\t Train Loss:0.0136\t Train Acc:84.31 %  | \tValid Loss:0.0161 \tValid Acc: 78.24 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:28]\t Train Loss:0.0134\t Train Acc:83.73 %  | \tValid Loss:0.0163 \tValid Acc: 78.24 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:29]\t Train Loss:0.0127\t Train Acc:85.62 %  | \tValid Loss:0.0170 \tValid Acc: 76.99 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:30]\t Train Loss:0.0118\t Train Acc:86.61 %  | \tValid Loss:0.0161 \tValid Acc: 75.73 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:31]\t Train Loss:0.0098\t Train Acc:91.00 %  | \tValid Loss:0.0138 \tValid Acc: 83.47 %\n",
      "\n",
      "Validation loss decreased (0.015276 --> 0.013777).  Saving model ...\n",
      "\n",
      "[EPOCH:32]\t Train Loss:0.0103\t Train Acc:89.70 %  | \tValid Loss:0.0148 \tValid Acc: 80.33 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:33]\t Train Loss:0.0094\t Train Acc:91.16 %  | \tValid Loss:0.0174 \tValid Acc: 76.15 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:34]\t Train Loss:0.0094\t Train Acc:90.59 %  | \tValid Loss:0.0172 \tValid Acc: 75.73 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:35]\t Train Loss:0.0079\t Train Acc:92.94 %  | \tValid Loss:0.0122 \tValid Acc: 85.36 %\n",
      "\n",
      "Validation loss decreased (0.013777 --> 0.012168).  Saving model ...\n",
      "\n",
      "[EPOCH:36]\t Train Loss:0.0071\t Train Acc:94.46 %  | \tValid Loss:0.0122 \tValid Acc: 85.36 %\n",
      "\n",
      "Validation loss decreased (0.012168 --> 0.012162).  Saving model ...\n",
      "\n",
      "[EPOCH:37]\t Train Loss:0.0057\t Train Acc:95.66 %  | \tValid Loss:0.0108 \tValid Acc: 88.08 %\n",
      "\n",
      "Validation loss decreased (0.012162 --> 0.010811).  Saving model ...\n",
      "\n",
      "[EPOCH:38]\t Train Loss:0.0067\t Train Acc:94.67 %  | \tValid Loss:0.0147 \tValid Acc: 80.54 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:39]\t Train Loss:0.0074\t Train Acc:92.73 %  | \tValid Loss:0.0118 \tValid Acc: 86.61 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:40]\t Train Loss:0.0057\t Train Acc:95.61 %  | \tValid Loss:0.0155 \tValid Acc: 81.80 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "[5 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0251\t Train Acc:50.42 %  | \tValid Loss:0.0229 \tValid Acc: 60.46 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.022853).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0249\t Train Acc:49.95 %  | \tValid Loss:0.0228 \tValid Acc: 58.37 %\n",
      "\n",
      "Validation loss decreased (0.022853 --> 0.022782).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0240\t Train Acc:52.77 %  | \tValid Loss:0.0221 \tValid Acc: 59.62 %\n",
      "\n",
      "Validation loss decreased (0.022782 --> 0.022117).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0234\t Train Acc:55.65 %  | \tValid Loss:0.0214 \tValid Acc: 65.69 %\n",
      "\n",
      "Validation loss decreased (0.022117 --> 0.021416).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0233\t Train Acc:54.86 %  | \tValid Loss:0.0213 \tValid Acc: 66.74 %\n",
      "\n",
      "Validation loss decreased (0.021416 --> 0.021341).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0230\t Train Acc:56.01 %  | \tValid Loss:0.0209 \tValid Acc: 69.87 %\n",
      "\n",
      "Validation loss decreased (0.021341 --> 0.020879).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0225\t Train Acc:58.32 %  | \tValid Loss:0.0206 \tValid Acc: 71.55 %\n",
      "\n",
      "Validation loss decreased (0.020879 --> 0.020583).  Saving model ...\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0219\t Train Acc:60.72 %  | \tValid Loss:0.0199 \tValid Acc: 70.29 %\n",
      "\n",
      "Validation loss decreased (0.020583 --> 0.019917).  Saving model ...\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0218\t Train Acc:60.36 %  | \tValid Loss:0.0201 \tValid Acc: 66.95 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0214\t Train Acc:62.66 %  | \tValid Loss:0.0211 \tValid Acc: 62.55 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0210\t Train Acc:63.02 %  | \tValid Loss:0.0197 \tValid Acc: 73.01 %\n",
      "\n",
      "Validation loss decreased (0.019917 --> 0.019703).  Saving model ...\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0212\t Train Acc:63.18 %  | \tValid Loss:0.0195 \tValid Acc: 69.25 %\n",
      "\n",
      "Validation loss decreased (0.019703 --> 0.019498).  Saving model ...\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0206\t Train Acc:65.48 %  | \tValid Loss:0.0204 \tValid Acc: 64.44 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0201\t Train Acc:67.21 %  | \tValid Loss:0.0192 \tValid Acc: 68.62 %\n",
      "\n",
      "Validation loss decreased (0.019498 --> 0.019191).  Saving model ...\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0202\t Train Acc:66.37 %  | \tValid Loss:0.0189 \tValid Acc: 71.55 %\n",
      "\n",
      "Validation loss decreased (0.019191 --> 0.018857).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH:16]\t Train Loss:0.0198\t Train Acc:69.40 %  | \tValid Loss:0.0182 \tValid Acc: 70.92 %\n",
      "\n",
      "Validation loss decreased (0.018857 --> 0.018205).  Saving model ...\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0197\t Train Acc:68.04 %  | \tValid Loss:0.0195 \tValid Acc: 65.69 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0191\t Train Acc:69.67 %  | \tValid Loss:0.0186 \tValid Acc: 70.08 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0187\t Train Acc:71.86 %  | \tValid Loss:0.0197 \tValid Acc: 66.53 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:20]\t Train Loss:0.0183\t Train Acc:72.96 %  | \tValid Loss:0.0183 \tValid Acc: 72.80 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:21]\t Train Loss:0.0177\t Train Acc:74.06 %  | \tValid Loss:0.0182 \tValid Acc: 70.50 %\n",
      "\n",
      "Validation loss decreased (0.018205 --> 0.018163).  Saving model ...\n",
      "\n",
      "[EPOCH:22]\t Train Loss:0.0169\t Train Acc:77.51 %  | \tValid Loss:0.0185 \tValid Acc: 69.67 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:23]\t Train Loss:0.0167\t Train Acc:76.94 %  | \tValid Loss:0.0170 \tValid Acc: 75.10 %\n",
      "\n",
      "Validation loss decreased (0.018163 --> 0.016989).  Saving model ...\n",
      "\n",
      "[EPOCH:24]\t Train Loss:0.0160\t Train Acc:78.35 %  | \tValid Loss:0.0149 \tValid Acc: 79.50 %\n",
      "\n",
      "Validation loss decreased (0.016989 --> 0.014914).  Saving model ...\n",
      "\n",
      "[EPOCH:25]\t Train Loss:0.0153\t Train Acc:80.23 %  | \tValid Loss:0.0188 \tValid Acc: 69.04 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:26]\t Train Loss:0.0153\t Train Acc:80.28 %  | \tValid Loss:0.0162 \tValid Acc: 78.03 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:27]\t Train Loss:0.0137\t Train Acc:83.53 %  | \tValid Loss:0.0185 \tValid Acc: 71.13 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:28]\t Train Loss:0.0130\t Train Acc:85.09 %  | \tValid Loss:0.0152 \tValid Acc: 80.96 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:29]\t Train Loss:0.0125\t Train Acc:85.46 %  | \tValid Loss:0.0163 \tValid Acc: 76.99 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[5 교차검증] Early stopping\n"
     ]
    }
   ],
   "source": [
    "#10. 학습 및 평가.\n",
    "# resnet34 pretrained true\n",
    "# kfold 적용\n",
    "\n",
    "train_accs = []\n",
    "valid_accs = []\n",
    "\n",
    "for data_ind in range(1,6):\n",
    "\n",
    "    check_path = '../checkpoint/checkpoint_resnet18_true_'+str(data_ind)+'_u.pt'\n",
    "\n",
    "    early_stopping = EarlyStopping(patience = 5, verbose = True, path=check_path)\n",
    "    train_loader,validation_loader = load_data(data_ind-1)\n",
    "    \n",
    "    best_train_acc=0 # accuracy 기록용\n",
    "    best_valid_acc=0\n",
    "    \n",
    "    model=model_initialize()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "    \n",
    "    \n",
    "    print(\"[{} 교차검증] 학습 시작\\n ----- \".format(data_ind))\n",
    "    for Epoch in range(1,EPOCHS+1):\n",
    "        train_loss,train_accuracy=train(model,train_loader,optimizer,log_interval=31)\n",
    "        valid_loss,valid_accuracy = evaluate(model, validation_loader)\n",
    "\n",
    "\n",
    "        print(\"\\n[EPOCH:{}]\\t Train Loss:{:.4f}\\t Train Acc:{:.2f} %  | \\tValid Loss:{:.4f} \\tValid Acc: {:.2f} %\\n\".\n",
    "              format(Epoch,train_loss,train_accuracy,valid_loss,valid_accuracy))\n",
    "\n",
    "        early_stopping(valid_loss, model)\n",
    "        if -early_stopping.best_score == valid_loss:\n",
    "            best_train_acc, best_valid_acc = train_accuracy,valid_accuracy\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "                train_accs.append(best_train_acc)\n",
    "                valid_accs.append(best_valid_acc)\n",
    "                print(\"[{} 교차검증] Early stopping\".format(data_ind))\n",
    "                break\n",
    "        \n",
    "        if Epoch==EPOCHS:\n",
    "            #만약 early stop 없이 40 epoch라서 중지 된 경우.\n",
    "            train_accs.append(best_train_acc)\n",
    "            valid_accs.append(best_valid_acc)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6767ec8",
   "metadata": {},
   "source": [
    "# 모델 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a6824ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 교차검증] train ACC : 69.6130 |\t valid ACC: 70.9205 \n",
      "[2 교차검증] train ACC : 61.6632 |\t valid ACC: 63.1799 \n",
      "[3 교차검증] train ACC : 72.6987 |\t valid ACC: 70.2929 \n",
      "[4 교차검증] train ACC : 95.6600 |\t valid ACC: 88.0800 \n",
      "[5 교차검증] train ACC : 78.3473 |\t valid ACC: 79.4979 \n",
      "평균 검증 정확도 74.39424267782427 %\n"
     ]
    }
   ],
   "source": [
    "sum_valid=0\n",
    "for data_ind in range(5):\n",
    "    print(\"[{} 교차검증] train ACC : {:.4f} |\\t valid ACC: {:.4f} \".format(data_ind+1,train_accs[data_ind],valid_accs[data_ind] ))\n",
    "    sum_valid+=valid_accs[data_ind]\n",
    "    \n",
    "print(\"평균 검증 정확도\",sum_valid/5,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0967cf",
   "metadata": {},
   "source": [
    "# Model Test\n",
    "\n",
    "- test set\n",
    "- confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a19235bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix 계산\n",
    "#test set 계산.\n",
    "def test_evaluate(model,test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    predictions = []\n",
    "    answers = []\n",
    "    #no_grad : 그래디언트 값 계산 막기.\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "            answers +=label\n",
    "            predictions +=prediction\n",
    "            \n",
    "        return predictions,answers,test_loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca2e1ed2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[156.  83.]\n",
      " [ 56. 183.]]\n",
      "[[298. 180.]\n",
      " [135. 343.]]\n",
      "[[474. 243.]\n",
      " [214. 503.]]\n",
      "[[684. 272.]\n",
      " [242. 714.]]\n",
      "[[837. 358.]\n",
      " [254. 941.]]\n",
      "Accuracy : 74.3933% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.7672\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.7004\n",
      "f score : 0.7323 \n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix (resnet18)\n",
    "# kfold의 confusion matrix는 계산 방법이 다르다.\n",
    "# 모델을 각각 불러와서 결과를 모두 합쳐줘야한다.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf = np.zeros((2,2))\n",
    "\n",
    "for data_ind in range(1,6):\n",
    "\n",
    "    check_path = '../checkpoint/checkpoint_resnet18_true_'+str(data_ind)+'_u.pt'\n",
    "    model.load_state_dict(torch.load(check_path))\n",
    "    _,validation_loader = load_data(data_ind-1)\n",
    "\n",
    "    predictions,answers,test_loss = test_evaluate(model, validation_loader)\n",
    "    predictions=[ dat.cpu().numpy() for dat in predictions]\n",
    "    answers=[ dat.cpu().numpy() for dat in answers]\n",
    "\n",
    "\n",
    "    cf += confusion_matrix(answers, predictions)\n",
    "    print(cf)\n",
    "\n",
    "acc = (cf[0,0]+cf[1,1])/(cf[0,0]+cf[0,1]+cf[1,0]+cf[1,1])\n",
    "precision=cf[0,0]/(cf[0,0]+cf[1,0])\n",
    "recall=cf[0,0]/(cf[0,0]+cf[0,1])\n",
    "fscore=2*precision*recall/(precision+recall)\n",
    "\n",
    "print(\"Accuracy : {:.4f}% \".format(acc*100))\n",
    "print(\"Precision (pathology 예측한 것중 맞는 것) : {:.4f}\".format(precision))\n",
    "print(\"recall (실제 pathology 중  예측이 맞는 것) : {:.4f}\".format(recall))\n",
    "print(\"f score : {:.4f} \".format(fscore))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51549b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "455.111px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
