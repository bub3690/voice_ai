{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37664ece",
   "metadata": {},
   "source": [
    "- http://keunwoochoi.blogspot.com/2016/03/2.html\n",
    "- http://www.rex-ai.info/docs/AI_Example_CNN_speech_recognize\n",
    "- https://www.youtube.com/watch?v=oltGIc4uo5c\n",
    "- https://youdaeng-com.tistory.com/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "275b8092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pytorch version :  1.10.0  Device :  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn # 인공 신경망 모델들 모아놓은 모듈\n",
    "import torch.nn.functional as F #그중 자주 쓰이는것들을 F로\n",
    "from torchvision import transforms, datasets\n",
    "import cv2\n",
    "from torchvision import transforms, datasets\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "p = os.path.abspath('..') # 상위 폴더를 사용하기 위해서.\n",
    "sys.path.insert(1, p)\n",
    "from pytorchtools.pytorchtools import EarlyStopping # 현재 폴더에 추가된 모듈.\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "#DEVICE = torch.device('cpu')\n",
    "print('Using Pytorch version : ',torch.__version__,' Device : ',DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ebea6",
   "metadata": {},
   "source": [
    "# SVD 문장 데이터에서 Feature 추출\n",
    "- mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "114a1b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa, librosa.display \n",
    "import matplotlib.pyplot as plt\n",
    "#window sizde : FFT를 할때 참조할 그래프 길이 ( 프레임 하나당 sample 수 )\n",
    "#자연어 처리에서는 25ms 사용. https://ahnjg.tistory.com/93\n",
    "#초당 50000hz 중 1250개씩 윈도우 사이즈로 사용.\n",
    "sr=50000\n",
    "win_length =  np.int64(50000/40) # 1250\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c72d82e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pathology data 수 :  1355\n",
      "healthy data 수 :  687\n",
      "가장 긴 path sample : 130793\n",
      "가장 긴 healthy sample : 194501\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa, librosa.display \n",
    "import matplotlib.pyplot as plt\n",
    "#window sizde : FFT를 할때 참조할 그래프 길이 ( 프레임 하나당 sample 수 )\n",
    "#자연어 처리에서는 25ms 사용. https://ahnjg.tistory.com/93\n",
    "#초당 50000hz 중 1250개씩 윈도우 사이즈로 사용.\n",
    "sr=50000\n",
    "win_length =  np.int64(50000/40) # 1250\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다.\n",
    "\n",
    "pathology_sig=[]\n",
    "healthy_sig=[]\n",
    "\n",
    "pathology=[]\n",
    "healthy=[]\n",
    "\n",
    "\n",
    "#PATHOLOGY DATA\n",
    "for audio_path in os.listdir('../../voice_data/pathology_u/export/'):\n",
    "    sig, sr = librosa.load('../../voice_data/pathology_u/export/'+audio_path, sr=50000)# 논문에서 f_s = 50 000HZ\n",
    "    pathology_sig.append(sig)\n",
    "    MFCCs = librosa.feature.mfcc(sig, sr, win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "    pathology.append(MFCCs)\n",
    "    \n",
    "\n",
    "#Healthy data\n",
    "for audio_path in os.listdir('../../voice_data/healthy_u/export/'):\n",
    "    sig, sr = librosa.load('../../voice_data/healthy_u/export/'+audio_path, sr=50000)# 논문에서 f_s = 50 000HZ\n",
    "    healthy_sig.append(sig)\n",
    "    MFCCs = librosa.feature.mfcc(sig, sr, win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "    healthy.append(MFCCs)\n",
    "    \n",
    "print(\"pathology data 수 : \",len(pathology))\n",
    "print(\"healthy data 수 : \",len(healthy))\n",
    "\n",
    "\n",
    "path_max=max([ len(samples) for samples in pathology_sig])\n",
    "healthy_max=max([ len(samples) for samples in healthy_sig])\n",
    "print(\"가장 긴 path sample :\" ,path_max)\n",
    "print(\"가장 긴 healthy sample :\" ,healthy_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "636bede8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.61586 초\n",
      "3.89002 초\n"
     ]
    }
   ],
   "source": [
    "print(path_max/sr,\"초\")\n",
    "print(healthy_max/sr,\"초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5915f64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 :  1.2528839409594097\n",
      "평균 :  1.3178440174672488\n"
     ]
    }
   ],
   "source": [
    "print('평균 : ',np.mean([ len(samples) for samples in pathology_sig])/sr)\n",
    "print('평균 : ',np.mean([ len(samples) for samples in healthy_sig])/sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91bd1989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.504"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "400*313/sr\n",
    "#400 frame은 약 2.5초 이상."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148ec668",
   "metadata": {},
   "source": [
    "# 결과 확인\n",
    "- 1 row당 1 frame으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a48f3297",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>mfcc5</th>\n",
       "      <th>mfcc6</th>\n",
       "      <th>mfcc7</th>\n",
       "      <th>mfcc8</th>\n",
       "      <th>mfcc9</th>\n",
       "      <th>mfcc10</th>\n",
       "      <th>mfcc11</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-272.275146</td>\n",
       "      <td>208.902557</td>\n",
       "      <td>44.434441</td>\n",
       "      <td>40.349213</td>\n",
       "      <td>-25.458517</td>\n",
       "      <td>12.826863</td>\n",
       "      <td>-3.920654</td>\n",
       "      <td>-8.411410</td>\n",
       "      <td>3.417778</td>\n",
       "      <td>7.566922</td>\n",
       "      <td>-2.498518</td>\n",
       "      <td>-6.284049</td>\n",
       "      <td>-2.326992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-292.371613</td>\n",
       "      <td>203.497162</td>\n",
       "      <td>55.854485</td>\n",
       "      <td>54.128845</td>\n",
       "      <td>-19.807659</td>\n",
       "      <td>14.410148</td>\n",
       "      <td>-1.129526</td>\n",
       "      <td>-7.547229</td>\n",
       "      <td>2.966858</td>\n",
       "      <td>11.841558</td>\n",
       "      <td>1.122357</td>\n",
       "      <td>-0.466148</td>\n",
       "      <td>-0.014877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-326.458984</td>\n",
       "      <td>179.993637</td>\n",
       "      <td>64.711746</td>\n",
       "      <td>65.344246</td>\n",
       "      <td>-17.435101</td>\n",
       "      <td>19.880333</td>\n",
       "      <td>2.197647</td>\n",
       "      <td>-1.880868</td>\n",
       "      <td>-4.580058</td>\n",
       "      <td>4.086713</td>\n",
       "      <td>3.976766</td>\n",
       "      <td>1.293952</td>\n",
       "      <td>6.717286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-324.657288</td>\n",
       "      <td>174.853928</td>\n",
       "      <td>61.641129</td>\n",
       "      <td>64.695351</td>\n",
       "      <td>-10.726300</td>\n",
       "      <td>23.473757</td>\n",
       "      <td>-8.347025</td>\n",
       "      <td>-9.129495</td>\n",
       "      <td>-7.556191</td>\n",
       "      <td>10.262231</td>\n",
       "      <td>8.042992</td>\n",
       "      <td>2.768127</td>\n",
       "      <td>9.962308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-317.942169</td>\n",
       "      <td>182.751175</td>\n",
       "      <td>64.051483</td>\n",
       "      <td>59.415588</td>\n",
       "      <td>-17.222746</td>\n",
       "      <td>18.475574</td>\n",
       "      <td>-8.616613</td>\n",
       "      <td>-10.723660</td>\n",
       "      <td>-0.691800</td>\n",
       "      <td>12.757200</td>\n",
       "      <td>7.716760</td>\n",
       "      <td>2.235234</td>\n",
       "      <td>4.562744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>-354.029236</td>\n",
       "      <td>172.662659</td>\n",
       "      <td>72.229408</td>\n",
       "      <td>51.822090</td>\n",
       "      <td>-19.475491</td>\n",
       "      <td>24.674398</td>\n",
       "      <td>-14.183729</td>\n",
       "      <td>-14.277061</td>\n",
       "      <td>-8.532803</td>\n",
       "      <td>3.395573</td>\n",
       "      <td>14.948679</td>\n",
       "      <td>-4.153752</td>\n",
       "      <td>7.948050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>-363.935699</td>\n",
       "      <td>166.532837</td>\n",
       "      <td>73.193100</td>\n",
       "      <td>50.661980</td>\n",
       "      <td>-21.652119</td>\n",
       "      <td>21.548904</td>\n",
       "      <td>-14.202366</td>\n",
       "      <td>-13.243938</td>\n",
       "      <td>-2.112081</td>\n",
       "      <td>3.580634</td>\n",
       "      <td>10.965590</td>\n",
       "      <td>-10.593177</td>\n",
       "      <td>3.021251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>-364.039581</td>\n",
       "      <td>163.347534</td>\n",
       "      <td>80.410004</td>\n",
       "      <td>55.608833</td>\n",
       "      <td>-18.868038</td>\n",
       "      <td>21.568939</td>\n",
       "      <td>-14.416084</td>\n",
       "      <td>-12.026213</td>\n",
       "      <td>-2.639414</td>\n",
       "      <td>5.210083</td>\n",
       "      <td>14.799844</td>\n",
       "      <td>-4.204784</td>\n",
       "      <td>2.161280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>-360.334564</td>\n",
       "      <td>167.725281</td>\n",
       "      <td>81.819809</td>\n",
       "      <td>53.282486</td>\n",
       "      <td>-13.211727</td>\n",
       "      <td>18.665279</td>\n",
       "      <td>-17.974466</td>\n",
       "      <td>-14.677999</td>\n",
       "      <td>-6.362213</td>\n",
       "      <td>-0.718999</td>\n",
       "      <td>20.342644</td>\n",
       "      <td>-3.675610</td>\n",
       "      <td>-3.875287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>-350.499359</td>\n",
       "      <td>175.658173</td>\n",
       "      <td>78.769157</td>\n",
       "      <td>45.172649</td>\n",
       "      <td>-10.140876</td>\n",
       "      <td>15.867226</td>\n",
       "      <td>-21.012016</td>\n",
       "      <td>-10.770565</td>\n",
       "      <td>-3.238189</td>\n",
       "      <td>0.111002</td>\n",
       "      <td>20.215496</td>\n",
       "      <td>-3.303527</td>\n",
       "      <td>-4.188798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>341 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mfcc1       mfcc2      mfcc3      mfcc4      mfcc5      mfcc6  \\\n",
       "0   -272.275146  208.902557  44.434441  40.349213 -25.458517  12.826863   \n",
       "1   -292.371613  203.497162  55.854485  54.128845 -19.807659  14.410148   \n",
       "2   -326.458984  179.993637  64.711746  65.344246 -17.435101  19.880333   \n",
       "3   -324.657288  174.853928  61.641129  64.695351 -10.726300  23.473757   \n",
       "4   -317.942169  182.751175  64.051483  59.415588 -17.222746  18.475574   \n",
       "..          ...         ...        ...        ...        ...        ...   \n",
       "336 -354.029236  172.662659  72.229408  51.822090 -19.475491  24.674398   \n",
       "337 -363.935699  166.532837  73.193100  50.661980 -21.652119  21.548904   \n",
       "338 -364.039581  163.347534  80.410004  55.608833 -18.868038  21.568939   \n",
       "339 -360.334564  167.725281  81.819809  53.282486 -13.211727  18.665279   \n",
       "340 -350.499359  175.658173  78.769157  45.172649 -10.140876  15.867226   \n",
       "\n",
       "         mfcc7      mfcc8     mfcc9     mfcc10     mfcc11     mfcc12    mfcc13  \n",
       "0    -3.920654  -8.411410  3.417778   7.566922  -2.498518  -6.284049 -2.326992  \n",
       "1    -1.129526  -7.547229  2.966858  11.841558   1.122357  -0.466148 -0.014877  \n",
       "2     2.197647  -1.880868 -4.580058   4.086713   3.976766   1.293952  6.717286  \n",
       "3    -8.347025  -9.129495 -7.556191  10.262231   8.042992   2.768127  9.962308  \n",
       "4    -8.616613 -10.723660 -0.691800  12.757200   7.716760   2.235234  4.562744  \n",
       "..         ...        ...       ...        ...        ...        ...       ...  \n",
       "336 -14.183729 -14.277061 -8.532803   3.395573  14.948679  -4.153752  7.948050  \n",
       "337 -14.202366 -13.243938 -2.112081   3.580634  10.965590 -10.593177  3.021251  \n",
       "338 -14.416084 -12.026213 -2.639414   5.210083  14.799844  -4.204784  2.161280  \n",
       "339 -17.974466 -14.677999 -6.362213  -0.718999  20.342644  -3.675610 -3.875287  \n",
       "340 -21.012016 -10.770565 -3.238189   0.111002  20.215496  -3.303527 -4.188798  \n",
       "\n",
       "[341 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(healthy[0][2]) #1번 : 파일. 2번:mfcc\n",
    "headers = \"mfcc1 mfcc2 mfcc3 mfcc4 mfcc5 mfcc6 mfcc7 mfcc8 mfcc9 mfcc10 mfcc11 mfcc12 mfcc13\".split()\n",
    "pd.DataFrame(healthy[1].T,columns=headers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "186be135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthy[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73d328bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "del pathology\n",
    "del healthy\n",
    "del pathology_sig\n",
    "del healthy_sig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23a4c15",
   "metadata": {},
   "source": [
    "# 데이터 나누기 - Stratified KFold\n",
    "- k =5\n",
    "- pathology : 1354 / healthy : 687 . 총 : 2041"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fada6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pathology :  1355\n",
      "Healthy:  687\n",
      "총 데이터수 :  2042\n",
      "교차 검증 : 1\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 549, 'pathology': 1084}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 138, 'pathology': 271} \n",
      "\n",
      "교차 검증 : 2\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 549, 'pathology': 1084}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 138, 'pathology': 271} \n",
      "\n",
      "교차 검증 : 3\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 550, 'pathology': 1084}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 137, 'pathology': 271} \n",
      "\n",
      "교차 검증 : 4\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 550, 'pathology': 1084}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 137, 'pathology': 271} \n",
      "\n",
      "교차 검증 : 5\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 550, 'pathology': 1084}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 137, 'pathology': 271} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. train, test 나누기\n",
    "import os\n",
    "import random #데이터 shuffle 사용\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "    \n",
    "pathology = glob('../../voice_data/pathology_u/export/*.wav')\n",
    "healthy = glob('../../voice_data/healthy_u/export/*.wav')\n",
    "print(\"Pathology : \",len(pathology))\n",
    "print(\"Healthy: \",len(healthy))\n",
    "\n",
    "X = pathology+healthy # path 데이터 합\n",
    "print(\"총 데이터수 : \",len(X))\n",
    "Y = [] # 라벨\n",
    "for idx,x in enumerate(X):\n",
    "    if idx<1355:\n",
    "        Y.append(\"pathology\")\n",
    "    else:\n",
    "        Y.append(\"healthy\")\n",
    "\n",
    "\n",
    "skf_iris = StratifiedKFold(n_splits=5)\n",
    "cnt_iter = 0\n",
    "\n",
    "X_train_list = [] #데이터 셋 보관\n",
    "Y_train_list = []\n",
    "\n",
    "X_test_list = []\n",
    "Y_test_list = []\n",
    "\n",
    "for train_idx, test_idx in skf_iris.split(X,Y):\n",
    "    \n",
    "    #split으로 반환된 인덱스를 이용하여, 학습 검증용 테스트 데이터 추출\n",
    "    cnt_iter += 1\n",
    "    X_train, X_test = [X[idx] for idx in train_idx.tolist() ], [X[idx] for idx in test_idx.tolist() ]\n",
    "    Y_train, Y_test = [Y[idx] for idx in train_idx.tolist() ], [Y[idx] for idx in test_idx.tolist() ]\n",
    "    \n",
    "    X_train_list.append(X_train)\n",
    "    X_test_list.append(X_test)\n",
    "    \n",
    "    Y_test_list.append(Y_test)\n",
    "    Y_train_list.append(Y_train)\n",
    "    \n",
    "    #학습 및 예측\n",
    "    \n",
    "    label_train = Y_train\n",
    "    label_test = Y_test\n",
    "    unique_train, train_counts = np.unique(label_train, return_counts = True)\n",
    "    unique_test, test_counts = np.unique(label_test, return_counts = True)\n",
    "    \n",
    "    uniq_cnt_train = dict(zip(unique_train, train_counts))\n",
    "    uniq_cnt_test = dict(zip(unique_test, test_counts))\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('교차 검증 : {}'.format(cnt_iter))\n",
    "    print('학습 레이블 데이터 분포 : \\n', uniq_cnt_train)\n",
    "    print('검증 레이블 데이터 분포 : \\n', uniq_cnt_test,'\\n')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a663f0",
   "metadata": {},
   "source": [
    "# 데이터 정의\n",
    "- 추가적으로 데이터의 크기를 맞춰주기 위해 3초로 padding 및 truncate 실시 https://sequencedata.tistory.com/25 FixAudioLength\n",
    "- 논문에서는 400frame으로 설정.\n",
    "- 전처리 방법 결정.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2febf8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "classes = [\"pathology\",\"healthy\"]\n",
    "sr=50000\n",
    "win_length =  np.int64(50000/40) # 1250\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다.\n",
    "\n",
    "class svd_dataset(Dataset):\n",
    "    def __init__(self,data_path_list,classes,data_num,training,transform=None):\n",
    "        #클래스에서 사용할 인자를 받아 인스턴스 변수로 저장하는 일을 한다.\n",
    "        #예를들면, 이미지의 경로 리스트를 저장하는 일을 하게 된다.\n",
    "        \n",
    "        #data_num : k 개 데이터 셋 중 어떤것을 쓸지\n",
    "        #test인지 아닌지.\n",
    "        \n",
    "        self.path_list = data_path_list[data_num]\n",
    "        self.data_num = data_num\n",
    "        self.training = training\n",
    "        self.label = svd_dataset.get_label(self.path_list,training,data_num)\n",
    "        self.classes=classes\n",
    "        self.transform=transform\n",
    "        \n",
    "    \n",
    "    @classmethod\n",
    "    def get_label(cls,data_path_list,training,data_num):\n",
    "        label_list=[]\n",
    "        \n",
    "        if training:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_train_list[data_num][idx])\n",
    "        else:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_test_list[data_num][idx])\n",
    "        #print(label_list)\n",
    "        return label_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "        #데이터 셋의 길이를 정수로 반환한다. \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        1. path를 받아서, 소리에서 mfcc를 추출\n",
    "        2. mfcc를 500프레임으로 패딩.\n",
    "        3. resnet에 사용되기 위해 3채널로 복사(rgb 처럼)\n",
    "        4. 0~1 정규화\n",
    "        \n",
    "        \"\"\"\n",
    "        sig, sr = librosa.load(self.path_list[idx], sr=50000)# 논문에서 f_s = 50 000HZ\n",
    "        \n",
    "        MFCCs = librosa.feature.mfcc(sig, sr, win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "        #mfcc 400 FRAME이 되도록 패딩.\n",
    "        length = 400\n",
    "        pad2d = lambda a, i: a[:, 0:i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0], i-a.shape[1]))))\n",
    "        MFCCs = pad2d(MFCCs, length)\n",
    "        MFCCs= MFCCs.T\n",
    "        \n",
    "        if self.transform:\n",
    "            #print('transform')\n",
    "            MFCCs=self.transform(MFCCs).type(torch.float32)# 데이터 0~1 정규화\n",
    "            MFCCs=torch.stack([MFCCs,MFCCs,MFCCs])# 3채널로 복사.\n",
    "            MFCCs = MFCCs.squeeze(dim=1)\n",
    "        else:\n",
    "            #print(\"else\")\n",
    "            MFCCs = torch.from_numpy(MFCCs).type(torch.float32)\n",
    "            MFCCs=MFCCs.unsqueeze(0) #cnn 사용위해서 추가\n",
    "            #MFCCs = MFCCs.permute(2, 0, 1)\n",
    "        return MFCCs, self.classes.index(self.label[idx])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d05129d",
   "metadata": {},
   "source": [
    "# 데이터 로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89052fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. 하이퍼 파라미터\n",
    "BATCH_SIZE =  30 #한 배치당 30개 음성데이터 # 32 배수시에, 1개만 남는 경우가 발생해서.\n",
    "EPOCHS = 40 # 전체 데이터 셋을 40번 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bba97b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA LOADER 함수가 BATCH_size 단위로 분리해 지정.\n",
    "\n",
    "#확인을 위해 데이터셋 하나만 확인\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                           svd_dataset(\n",
    "                                               X_train_list,\n",
    "                                               classes,\n",
    "                                               transform = transforms.ToTensor(),#이걸 composed로 고쳐서 전처리 하도록 수정.\n",
    "                                               data_num=0,\n",
    "                                               training=True\n",
    "                                           ),\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True,\n",
    "                                           ) # 순서가 암기되는것을 막기위해.\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                           svd_dataset(\n",
    "                                               X_test_list,\n",
    "                                               classes,\n",
    "                                               transform = transforms.ToTensor(),\n",
    "                                               data_num=0,\n",
    "                                               training=False\n",
    "                                           ),\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True,) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b15a86",
   "metadata": {},
   "source": [
    "# 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f866237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :  torch.Size([30, 3, 400, 13]) type: torch.FloatTensor\n",
      "Y_train :  torch.Size([30]) type: torch.LongTensor\n",
      "tensor(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x19d3dc9ce20>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. 데이터 확인하기\n",
    "for (X_train,Y_train) in train_loader:\n",
    "    print(\"X_train : \",X_train.size(),'type:',X_train.type())\n",
    "    print(\"Y_train : \",Y_train.size(),'type:',Y_train.type())\n",
    "    break\n",
    "    \n",
    "print(Y_train[0])\n",
    "librosa.display.specshow(X_train[0][0].numpy().T, sr=50000, x_axis='time')\n",
    "#batch: 32 / frame수: 400  /  feature수: 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a45b51bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valid :  torch.Size([30, 3, 400, 13]) type: torch.FloatTensor\n",
      "Y_valid :  torch.Size([30]) type: torch.LongTensor\n",
      "tensor(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x19d3ddbebb0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#valiation set 확인\n",
    "for (X_valid,Y_valid) in validation_loader:\n",
    "    print(\"X_valid : \",X_valid.size(),'type:',X_valid.type())\n",
    "    print(\"Y_valid : \",Y_valid.size(),'type:',Y_valid.type())\n",
    "    break\n",
    "\n",
    "print(Y_valid[0])\n",
    "librosa.display.specshow(X_valid[0][0].numpy().T, sr=50000, x_axis='time')\n",
    "#batch: 32 / 3채널 / frame수: 400  /  feature수: 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec40ea4",
   "metadata": {},
   "source": [
    "# RESNET18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e1d59a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 \n",
    "# pretrained\n",
    "\n",
    "\n",
    "def model_initialize():\n",
    "    model = models.resnet18(pretrained=True).cuda()\n",
    "    model.ftrs = model.fc.in_features # in_features : fully connected의 입력수.\n",
    "    num_ftrs = model.fc.in_features\n",
    "\n",
    "    model.fc = nn.Sequential(nn.Linear(num_ftrs, 256),\n",
    "                             nn.BatchNorm1d(256),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(256,128),\n",
    "                             nn.BatchNorm1d(128),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(128,64),\n",
    "                             nn.BatchNorm1d(64),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(64,50),\n",
    "                             nn.BatchNorm1d(50),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(50,2)\n",
    "                            )\n",
    "\n",
    "    model = model.cuda()\n",
    "    return model\n",
    "model=model_initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c26ff30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.5, inplace=False)\n",
      "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.5, inplace=False)\n",
      "    (12): Linear(in_features=64, out_features=50, bias=True)\n",
      "    (13): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU()\n",
      "    (15): Dropout(p=0.5, inplace=False)\n",
      "    (16): Linear(in_features=50, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6097d312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 200, 7]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 200, 7]             128\n",
      "              ReLU-3           [-1, 64, 200, 7]               0\n",
      "         MaxPool2d-4           [-1, 64, 100, 4]               0\n",
      "            Conv2d-5           [-1, 64, 100, 4]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 100, 4]             128\n",
      "              ReLU-7           [-1, 64, 100, 4]               0\n",
      "            Conv2d-8           [-1, 64, 100, 4]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 100, 4]             128\n",
      "             ReLU-10           [-1, 64, 100, 4]               0\n",
      "       BasicBlock-11           [-1, 64, 100, 4]               0\n",
      "           Conv2d-12           [-1, 64, 100, 4]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 100, 4]             128\n",
      "             ReLU-14           [-1, 64, 100, 4]               0\n",
      "           Conv2d-15           [-1, 64, 100, 4]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 100, 4]             128\n",
      "             ReLU-17           [-1, 64, 100, 4]               0\n",
      "       BasicBlock-18           [-1, 64, 100, 4]               0\n",
      "           Conv2d-19           [-1, 128, 50, 2]          73,728\n",
      "      BatchNorm2d-20           [-1, 128, 50, 2]             256\n",
      "             ReLU-21           [-1, 128, 50, 2]               0\n",
      "           Conv2d-22           [-1, 128, 50, 2]         147,456\n",
      "      BatchNorm2d-23           [-1, 128, 50, 2]             256\n",
      "           Conv2d-24           [-1, 128, 50, 2]           8,192\n",
      "      BatchNorm2d-25           [-1, 128, 50, 2]             256\n",
      "             ReLU-26           [-1, 128, 50, 2]               0\n",
      "       BasicBlock-27           [-1, 128, 50, 2]               0\n",
      "           Conv2d-28           [-1, 128, 50, 2]         147,456\n",
      "      BatchNorm2d-29           [-1, 128, 50, 2]             256\n",
      "             ReLU-30           [-1, 128, 50, 2]               0\n",
      "           Conv2d-31           [-1, 128, 50, 2]         147,456\n",
      "      BatchNorm2d-32           [-1, 128, 50, 2]             256\n",
      "             ReLU-33           [-1, 128, 50, 2]               0\n",
      "       BasicBlock-34           [-1, 128, 50, 2]               0\n",
      "           Conv2d-35           [-1, 256, 25, 1]         294,912\n",
      "      BatchNorm2d-36           [-1, 256, 25, 1]             512\n",
      "             ReLU-37           [-1, 256, 25, 1]               0\n",
      "           Conv2d-38           [-1, 256, 25, 1]         589,824\n",
      "      BatchNorm2d-39           [-1, 256, 25, 1]             512\n",
      "           Conv2d-40           [-1, 256, 25, 1]          32,768\n",
      "      BatchNorm2d-41           [-1, 256, 25, 1]             512\n",
      "             ReLU-42           [-1, 256, 25, 1]               0\n",
      "       BasicBlock-43           [-1, 256, 25, 1]               0\n",
      "           Conv2d-44           [-1, 256, 25, 1]         589,824\n",
      "      BatchNorm2d-45           [-1, 256, 25, 1]             512\n",
      "             ReLU-46           [-1, 256, 25, 1]               0\n",
      "           Conv2d-47           [-1, 256, 25, 1]         589,824\n",
      "      BatchNorm2d-48           [-1, 256, 25, 1]             512\n",
      "             ReLU-49           [-1, 256, 25, 1]               0\n",
      "       BasicBlock-50           [-1, 256, 25, 1]               0\n",
      "           Conv2d-51           [-1, 512, 13, 1]       1,179,648\n",
      "      BatchNorm2d-52           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-53           [-1, 512, 13, 1]               0\n",
      "           Conv2d-54           [-1, 512, 13, 1]       2,359,296\n",
      "      BatchNorm2d-55           [-1, 512, 13, 1]           1,024\n",
      "           Conv2d-56           [-1, 512, 13, 1]         131,072\n",
      "      BatchNorm2d-57           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-58           [-1, 512, 13, 1]               0\n",
      "       BasicBlock-59           [-1, 512, 13, 1]               0\n",
      "           Conv2d-60           [-1, 512, 13, 1]       2,359,296\n",
      "      BatchNorm2d-61           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-62           [-1, 512, 13, 1]               0\n",
      "           Conv2d-63           [-1, 512, 13, 1]       2,359,296\n",
      "      BatchNorm2d-64           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-65           [-1, 512, 13, 1]               0\n",
      "       BasicBlock-66           [-1, 512, 13, 1]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                  [-1, 256]         131,328\n",
      "      BatchNorm1d-69                  [-1, 256]             512\n",
      "             ReLU-70                  [-1, 256]               0\n",
      "          Dropout-71                  [-1, 256]               0\n",
      "           Linear-72                  [-1, 128]          32,896\n",
      "      BatchNorm1d-73                  [-1, 128]             256\n",
      "             ReLU-74                  [-1, 128]               0\n",
      "          Dropout-75                  [-1, 128]               0\n",
      "           Linear-76                   [-1, 64]           8,256\n",
      "      BatchNorm1d-77                   [-1, 64]             128\n",
      "             ReLU-78                   [-1, 64]               0\n",
      "          Dropout-79                   [-1, 64]               0\n",
      "           Linear-80                   [-1, 50]           3,250\n",
      "      BatchNorm1d-81                   [-1, 50]             100\n",
      "             ReLU-82                   [-1, 50]               0\n",
      "          Dropout-83                   [-1, 50]               0\n",
      "           Linear-84                    [-1, 2]             102\n",
      "================================================================\n",
      "Total params: 11,353,340\n",
      "Trainable params: 11,353,340\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 8.16\n",
      "Params size (MB): 43.31\n",
      "Estimated Total Size (MB): 51.52\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# get the model summary\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 400, 13), device=DEVICE.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f2ca15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. 학습\n",
    "def train(model,train_loader,optimizer, log_interval):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    train_loss = 0\n",
    "    for batch_idx,(image,label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        #데이터들 장비에 할당\n",
    "        optimizer.zero_grad() # device 에 저장된 gradient 제거\n",
    "        output = model(image) # model로 output을 계산\n",
    "        loss = criterion(output, label) #loss 계산\n",
    "        train_loss += loss.item()\n",
    "        prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "        correct += prediction.eq(label.view_as(prediction)).sum().item()# 아웃풋이 배치 사이즈 32개라서.\n",
    "        loss.backward() # loss 값을 이용해 gradient를 계산\n",
    "        optimizer.step() # Gradient 값을 이용해 파라미터 업데이트.\n",
    "    train_loss/=len(train_loader.dataset)\n",
    "    train_accuracy = 100. * correct / len(train_loader.dataset)\n",
    "    return train_loss,train_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b09341bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. 학습 진행하며, validation 데이터로 모델 성능확인\n",
    "def evaluate(model,valid_loader):\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    #no_grad : 그래디언트 값 계산 막기.\n",
    "    with torch.no_grad():\n",
    "        for image, label in valid_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            valid_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()# 아웃풋이 배치 사이즈 32개라서.\n",
    "            #true.false값을 sum해줌. item\n",
    "        valid_loss /= len(valid_loader.dataset)\n",
    "        valid_accuracy = 100. * correct / len(valid_loader.dataset)\n",
    "        return valid_loss,valid_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae179080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 로더 제작 함수\n",
    "\n",
    "def load_data(data_ind):\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_dataset(\n",
    "                                                   X_train_list,\n",
    "                                                   classes,\n",
    "                                                   transform = transforms.ToTensor(),#이걸 composed로 고쳐서 전처리 하도록 수정.\n",
    "                                                   data_num=data_ind,\n",
    "                                                   training=True\n",
    "                                               ),\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = True,\n",
    "                                               ) # 순서가 암기되는것을 막기위해.\n",
    "\n",
    "    validation_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_dataset(\n",
    "                                                   X_test_list,\n",
    "                                                   classes,\n",
    "                                                   transform = transforms.ToTensor(),\n",
    "                                                   data_num=data_ind,\n",
    "                                                   training=False\n",
    "                                               ),\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = True,) \n",
    "    return train_loader,validation_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7c8c86f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0247\t Train Acc:49.48 %  | \tValid Loss:0.0235 \tValid Acc: 57.70 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.023476).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0241\t Train Acc:54.56 %  | \tValid Loss:0.0230 \tValid Acc: 61.86 %\n",
      "\n",
      "Validation loss decreased (0.023476 --> 0.023039).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0236\t Train Acc:57.26 %  | \tValid Loss:0.0228 \tValid Acc: 66.50 %\n",
      "\n",
      "Validation loss decreased (0.023039 --> 0.022788).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0232\t Train Acc:57.56 %  | \tValid Loss:0.0227 \tValid Acc: 65.77 %\n",
      "\n",
      "Validation loss decreased (0.022788 --> 0.022743).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0228\t Train Acc:60.50 %  | \tValid Loss:0.0225 \tValid Acc: 63.08 %\n",
      "\n",
      "Validation loss decreased (0.022743 --> 0.022456).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0223\t Train Acc:61.54 %  | \tValid Loss:0.0223 \tValid Acc: 64.55 %\n",
      "\n",
      "Validation loss decreased (0.022456 --> 0.022271).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0218\t Train Acc:62.89 %  | \tValid Loss:0.0219 \tValid Acc: 65.53 %\n",
      "\n",
      "Validation loss decreased (0.022271 --> 0.021946).  Saving model ...\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0216\t Train Acc:63.87 %  | \tValid Loss:0.0220 \tValid Acc: 65.77 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0212\t Train Acc:63.63 %  | \tValid Loss:0.0215 \tValid Acc: 65.77 %\n",
      "\n",
      "Validation loss decreased (0.021946 --> 0.021462).  Saving model ...\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0212\t Train Acc:64.85 %  | \tValid Loss:0.0210 \tValid Acc: 65.53 %\n",
      "\n",
      "Validation loss decreased (0.021462 --> 0.020959).  Saving model ...\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0210\t Train Acc:64.18 %  | \tValid Loss:0.0214 \tValid Acc: 66.75 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0206\t Train Acc:65.95 %  | \tValid Loss:0.0204 \tValid Acc: 66.50 %\n",
      "\n",
      "Validation loss decreased (0.020959 --> 0.020390).  Saving model ...\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0201\t Train Acc:66.38 %  | \tValid Loss:0.0203 \tValid Acc: 66.50 %\n",
      "\n",
      "Validation loss decreased (0.020390 --> 0.020288).  Saving model ...\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0201\t Train Acc:65.22 %  | \tValid Loss:0.0203 \tValid Acc: 68.95 %\n",
      "\n",
      "Validation loss decreased (0.020288 --> 0.020280).  Saving model ...\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0196\t Train Acc:66.44 %  | \tValid Loss:0.0206 \tValid Acc: 64.30 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0193\t Train Acc:66.26 %  | \tValid Loss:0.0205 \tValid Acc: 66.26 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0193\t Train Acc:66.32 %  | \tValid Loss:0.0200 \tValid Acc: 68.46 %\n",
      "\n",
      "Validation loss decreased (0.020280 --> 0.019980).  Saving model ...\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0195\t Train Acc:65.89 %  | \tValid Loss:0.0201 \tValid Acc: 65.53 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0186\t Train Acc:67.48 %  | \tValid Loss:0.0195 \tValid Acc: 65.77 %\n",
      "\n",
      "Validation loss decreased (0.019980 --> 0.019540).  Saving model ...\n",
      "\n",
      "[EPOCH:20]\t Train Loss:0.0183\t Train Acc:69.81 %  | \tValid Loss:0.0200 \tValid Acc: 64.79 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:21]\t Train Loss:0.0183\t Train Acc:69.08 %  | \tValid Loss:0.0208 \tValid Acc: 63.57 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:22]\t Train Loss:0.0188\t Train Acc:68.10 %  | \tValid Loss:0.0192 \tValid Acc: 66.01 %\n",
      "\n",
      "Validation loss decreased (0.019540 --> 0.019219).  Saving model ...\n",
      "\n",
      "[EPOCH:23]\t Train Loss:0.0180\t Train Acc:69.44 %  | \tValid Loss:0.0207 \tValid Acc: 65.04 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:24]\t Train Loss:0.0177\t Train Acc:70.42 %  | \tValid Loss:0.0202 \tValid Acc: 63.33 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:25]\t Train Loss:0.0168\t Train Acc:73.30 %  | \tValid Loss:0.0206 \tValid Acc: 61.37 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:26]\t Train Loss:0.0168\t Train Acc:73.91 %  | \tValid Loss:0.0205 \tValid Acc: 67.73 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:27]\t Train Loss:0.0164\t Train Acc:73.24 %  | \tValid Loss:0.0215 \tValid Acc: 60.15 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[1 교차검증] Early stopping\n",
      "[2 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0276\t Train Acc:42.74 %  | \tValid Loss:0.0265 \tValid Acc: 34.72 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.026473).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0261\t Train Acc:46.79 %  | \tValid Loss:0.0265 \tValid Acc: 35.70 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0249\t Train Acc:51.07 %  | \tValid Loss:0.0256 \tValid Acc: 38.14 %\n",
      "\n",
      "Validation loss decreased (0.026473 --> 0.025581).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0246\t Train Acc:52.11 %  | \tValid Loss:0.0249 \tValid Acc: 40.59 %\n",
      "\n",
      "Validation loss decreased (0.025581 --> 0.024868).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0234\t Train Acc:56.77 %  | \tValid Loss:0.0238 \tValid Acc: 53.79 %\n",
      "\n",
      "Validation loss decreased (0.024868 --> 0.023813).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0229\t Train Acc:57.26 %  | \tValid Loss:0.0233 \tValid Acc: 52.81 %\n",
      "\n",
      "Validation loss decreased (0.023813 --> 0.023313).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0222\t Train Acc:61.11 %  | \tValid Loss:0.0233 \tValid Acc: 56.72 %\n",
      "\n",
      "Validation loss decreased (0.023313 --> 0.023295).  Saving model ...\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0221\t Train Acc:61.73 %  | \tValid Loss:0.0237 \tValid Acc: 51.34 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0220\t Train Acc:60.62 %  | \tValid Loss:0.0237 \tValid Acc: 48.66 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0214\t Train Acc:61.48 %  | \tValid Loss:0.0224 \tValid Acc: 59.90 %\n",
      "\n",
      "Validation loss decreased (0.023295 --> 0.022371).  Saving model ...\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0207\t Train Acc:63.81 %  | \tValid Loss:0.0232 \tValid Acc: 52.08 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0205\t Train Acc:65.34 %  | \tValid Loss:0.0222 \tValid Acc: 58.92 %\n",
      "\n",
      "Validation loss decreased (0.022371 --> 0.022173).  Saving model ...\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0202\t Train Acc:63.87 %  | \tValid Loss:0.0235 \tValid Acc: 50.86 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0203\t Train Acc:66.20 %  | \tValid Loss:0.0221 \tValid Acc: 59.66 %\n",
      "\n",
      "Validation loss decreased (0.022173 --> 0.022148).  Saving model ...\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0195\t Train Acc:67.18 %  | \tValid Loss:0.0227 \tValid Acc: 53.55 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0189\t Train Acc:69.87 %  | \tValid Loss:0.0226 \tValid Acc: 53.79 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0189\t Train Acc:68.83 %  | \tValid Loss:0.0214 \tValid Acc: 61.86 %\n",
      "\n",
      "Validation loss decreased (0.022148 --> 0.021406).  Saving model ...\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0187\t Train Acc:69.81 %  | \tValid Loss:0.0223 \tValid Acc: 54.77 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0184\t Train Acc:71.03 %  | \tValid Loss:0.0229 \tValid Acc: 55.01 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:20]\t Train Loss:0.0184\t Train Acc:70.42 %  | \tValid Loss:0.0220 \tValid Acc: 57.95 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:21]\t Train Loss:0.0191\t Train Acc:69.08 %  | \tValid Loss:0.0210 \tValid Acc: 61.61 %\n",
      "\n",
      "Validation loss decreased (0.021406 --> 0.020951).  Saving model ...\n",
      "\n",
      "[EPOCH:22]\t Train Loss:0.0175\t Train Acc:72.20 %  | \tValid Loss:0.0220 \tValid Acc: 58.19 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:23]\t Train Loss:0.0176\t Train Acc:70.97 %  | \tValid Loss:0.0222 \tValid Acc: 58.44 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:24]\t Train Loss:0.0168\t Train Acc:73.36 %  | \tValid Loss:0.0239 \tValid Acc: 51.34 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:25]\t Train Loss:0.0168\t Train Acc:74.46 %  | \tValid Loss:0.0227 \tValid Acc: 56.23 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:26]\t Train Loss:0.0168\t Train Acc:74.95 %  | \tValid Loss:0.0222 \tValid Acc: 58.19 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[2 교차검증] Early stopping\n",
      "[3 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0243\t Train Acc:54.96 %  | \tValid Loss:0.0231 \tValid Acc: 62.25 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.023086).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0235\t Train Acc:57.22 %  | \tValid Loss:0.0223 \tValid Acc: 65.69 %\n",
      "\n",
      "Validation loss decreased (0.023086 --> 0.022340).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0233\t Train Acc:59.24 %  | \tValid Loss:0.0223 \tValid Acc: 67.40 %\n",
      "\n",
      "Validation loss decreased (0.022340 --> 0.022269).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH:4]\t Train Loss:0.0230\t Train Acc:59.49 %  | \tValid Loss:0.0225 \tValid Acc: 67.16 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0231\t Train Acc:61.08 %  | \tValid Loss:0.0223 \tValid Acc: 65.44 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0224\t Train Acc:61.75 %  | \tValid Loss:0.0222 \tValid Acc: 65.44 %\n",
      "\n",
      "Validation loss decreased (0.022269 --> 0.022185).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0223\t Train Acc:62.85 %  | \tValid Loss:0.0219 \tValid Acc: 66.67 %\n",
      "\n",
      "Validation loss decreased (0.022185 --> 0.021903).  Saving model ...\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0218\t Train Acc:63.46 %  | \tValid Loss:0.0217 \tValid Acc: 65.93 %\n",
      "\n",
      "Validation loss decreased (0.021903 --> 0.021667).  Saving model ...\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0222\t Train Acc:60.89 %  | \tValid Loss:0.0220 \tValid Acc: 65.20 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0214\t Train Acc:63.22 %  | \tValid Loss:0.0219 \tValid Acc: 68.38 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0210\t Train Acc:64.50 %  | \tValid Loss:0.0219 \tValid Acc: 69.85 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0205\t Train Acc:65.67 %  | \tValid Loss:0.0218 \tValid Acc: 65.44 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0204\t Train Acc:65.24 %  | \tValid Loss:0.0217 \tValid Acc: 68.87 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[3 교차검증] Early stopping\n",
      "[4 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0283\t Train Acc:45.04 %  | \tValid Loss:0.0256 \tValid Acc: 34.80 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.025557).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0267\t Train Acc:46.57 %  | \tValid Loss:0.0245 \tValid Acc: 41.91 %\n",
      "\n",
      "Validation loss decreased (0.025557 --> 0.024475).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0256\t Train Acc:49.51 %  | \tValid Loss:0.0243 \tValid Acc: 45.34 %\n",
      "\n",
      "Validation loss decreased (0.024475 --> 0.024324).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0248\t Train Acc:53.00 %  | \tValid Loss:0.0230 \tValid Acc: 58.09 %\n",
      "\n",
      "Validation loss decreased (0.024324 --> 0.023001).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0242\t Train Acc:53.61 %  | \tValid Loss:0.0230 \tValid Acc: 59.07 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0234\t Train Acc:57.04 %  | \tValid Loss:0.0221 \tValid Acc: 66.67 %\n",
      "\n",
      "Validation loss decreased (0.023001 --> 0.022145).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0225\t Train Acc:58.14 %  | \tValid Loss:0.0228 \tValid Acc: 59.07 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0223\t Train Acc:57.77 %  | \tValid Loss:0.0225 \tValid Acc: 59.56 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0223\t Train Acc:59.06 %  | \tValid Loss:0.0226 \tValid Acc: 60.29 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0213\t Train Acc:60.77 %  | \tValid Loss:0.0216 \tValid Acc: 64.95 %\n",
      "\n",
      "Validation loss decreased (0.022145 --> 0.021551).  Saving model ...\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0212\t Train Acc:62.12 %  | \tValid Loss:0.0214 \tValid Acc: 66.67 %\n",
      "\n",
      "Validation loss decreased (0.021551 --> 0.021413).  Saving model ...\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0207\t Train Acc:64.81 %  | \tValid Loss:0.0215 \tValid Acc: 65.20 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0204\t Train Acc:64.44 %  | \tValid Loss:0.0210 \tValid Acc: 63.48 %\n",
      "\n",
      "Validation loss decreased (0.021413 --> 0.020976).  Saving model ...\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0201\t Train Acc:64.69 %  | \tValid Loss:0.0214 \tValid Acc: 62.25 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0203\t Train Acc:64.93 %  | \tValid Loss:0.0208 \tValid Acc: 64.95 %\n",
      "\n",
      "Validation loss decreased (0.020976 --> 0.020813).  Saving model ...\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0198\t Train Acc:64.75 %  | \tValid Loss:0.0210 \tValid Acc: 63.48 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0196\t Train Acc:65.30 %  | \tValid Loss:0.0207 \tValid Acc: 63.73 %\n",
      "\n",
      "Validation loss decreased (0.020813 --> 0.020746).  Saving model ...\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0190\t Train Acc:69.22 %  | \tValid Loss:0.0208 \tValid Acc: 69.12 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0189\t Train Acc:68.24 %  | \tValid Loss:0.0227 \tValid Acc: 53.43 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:20]\t Train Loss:0.0189\t Train Acc:67.20 %  | \tValid Loss:0.0198 \tValid Acc: 66.91 %\n",
      "\n",
      "Validation loss decreased (0.020746 --> 0.019847).  Saving model ...\n",
      "\n",
      "[EPOCH:21]\t Train Loss:0.0186\t Train Acc:67.93 %  | \tValid Loss:0.0201 \tValid Acc: 64.22 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:22]\t Train Loss:0.0189\t Train Acc:68.12 %  | \tValid Loss:0.0206 \tValid Acc: 64.71 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:23]\t Train Loss:0.0187\t Train Acc:66.77 %  | \tValid Loss:0.0190 \tValid Acc: 68.87 %\n",
      "\n",
      "Validation loss decreased (0.019847 --> 0.018978).  Saving model ...\n",
      "\n",
      "[EPOCH:24]\t Train Loss:0.0181\t Train Acc:70.87 %  | \tValid Loss:0.0210 \tValid Acc: 63.73 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:25]\t Train Loss:0.0173\t Train Acc:71.60 %  | \tValid Loss:0.0192 \tValid Acc: 70.34 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:26]\t Train Loss:0.0173\t Train Acc:72.09 %  | \tValid Loss:0.0207 \tValid Acc: 63.24 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:27]\t Train Loss:0.0174\t Train Acc:70.50 %  | \tValid Loss:0.0205 \tValid Acc: 63.97 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:28]\t Train Loss:0.0171\t Train Acc:70.81 %  | \tValid Loss:0.0214 \tValid Acc: 60.29 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[4 교차검증] Early stopping\n",
      "[5 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0246\t Train Acc:49.94 %  | \tValid Loss:0.0242 \tValid Acc: 44.36 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.024247).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0240\t Train Acc:56.18 %  | \tValid Loss:0.0231 \tValid Acc: 59.80 %\n",
      "\n",
      "Validation loss decreased (0.024247 --> 0.023113).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0238\t Train Acc:55.94 %  | \tValid Loss:0.0228 \tValid Acc: 65.93 %\n",
      "\n",
      "Validation loss decreased (0.023113 --> 0.022831).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0232\t Train Acc:59.61 %  | \tValid Loss:0.0229 \tValid Acc: 63.24 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0230\t Train Acc:59.06 %  | \tValid Loss:0.0226 \tValid Acc: 65.44 %\n",
      "\n",
      "Validation loss decreased (0.022831 --> 0.022597).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0225\t Train Acc:61.26 %  | \tValid Loss:0.0219 \tValid Acc: 67.16 %\n",
      "\n",
      "Validation loss decreased (0.022597 --> 0.021927).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0221\t Train Acc:62.55 %  | \tValid Loss:0.0222 \tValid Acc: 67.16 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0219\t Train Acc:62.61 %  | \tValid Loss:0.0216 \tValid Acc: 65.93 %\n",
      "\n",
      "Validation loss decreased (0.021927 --> 0.021586).  Saving model ...\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0215\t Train Acc:62.91 %  | \tValid Loss:0.0215 \tValid Acc: 66.18 %\n",
      "\n",
      "Validation loss decreased (0.021586 --> 0.021516).  Saving model ...\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0211\t Train Acc:64.99 %  | \tValid Loss:0.0214 \tValid Acc: 64.71 %\n",
      "\n",
      "Validation loss decreased (0.021516 --> 0.021418).  Saving model ...\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0210\t Train Acc:66.16 %  | \tValid Loss:0.0209 \tValid Acc: 66.42 %\n",
      "\n",
      "Validation loss decreased (0.021418 --> 0.020898).  Saving model ...\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0207\t Train Acc:65.73 %  | \tValid Loss:0.0214 \tValid Acc: 62.50 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0206\t Train Acc:65.61 %  | \tValid Loss:0.0208 \tValid Acc: 66.42 %\n",
      "\n",
      "Validation loss decreased (0.020898 --> 0.020775).  Saving model ...\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0201\t Train Acc:66.65 %  | \tValid Loss:0.0206 \tValid Acc: 66.91 %\n",
      "\n",
      "Validation loss decreased (0.020775 --> 0.020645).  Saving model ...\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0200\t Train Acc:66.95 %  | \tValid Loss:0.0214 \tValid Acc: 67.16 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0193\t Train Acc:69.34 %  | \tValid Loss:0.0202 \tValid Acc: 65.20 %\n",
      "\n",
      "Validation loss decreased (0.020645 --> 0.020174).  Saving model ...\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0199\t Train Acc:67.69 %  | \tValid Loss:0.0206 \tValid Acc: 66.42 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0189\t Train Acc:69.28 %  | \tValid Loss:0.0203 \tValid Acc: 67.65 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0193\t Train Acc:68.91 %  | \tValid Loss:0.0204 \tValid Acc: 66.18 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH:20]\t Train Loss:0.0184\t Train Acc:70.50 %  | \tValid Loss:0.0215 \tValid Acc: 62.25 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:21]\t Train Loss:0.0186\t Train Acc:70.01 %  | \tValid Loss:0.0209 \tValid Acc: 65.44 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[5 교차검증] Early stopping\n"
     ]
    }
   ],
   "source": [
    "#10. 학습 및 평가.\n",
    "# resnet34 pretrained true\n",
    "# kfold 적용\n",
    "\n",
    "train_accs = []\n",
    "valid_accs = []\n",
    "\n",
    "for data_ind in range(1,6):\n",
    "\n",
    "    check_path = '../checkpoint/checkpoint_resnet18_true_'+str(data_ind)+'_u.pt'\n",
    "\n",
    "    early_stopping = EarlyStopping(patience = 5, verbose = True, path=check_path)\n",
    "    train_loader,validation_loader = load_data(data_ind-1)\n",
    "    \n",
    "    best_train_acc=0 # accuracy 기록용\n",
    "    best_valid_acc=0\n",
    "    \n",
    "    model=model_initialize()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "    \n",
    "    \n",
    "    print(\"[{} 교차검증] 학습 시작\\n ----- \".format(data_ind))\n",
    "    for Epoch in range(1,EPOCHS+1):\n",
    "        train_loss,train_accuracy=train(model,train_loader,optimizer,log_interval=31)\n",
    "        valid_loss,valid_accuracy = evaluate(model, validation_loader)\n",
    "\n",
    "\n",
    "        print(\"\\n[EPOCH:{}]\\t Train Loss:{:.4f}\\t Train Acc:{:.2f} %  | \\tValid Loss:{:.4f} \\tValid Acc: {:.2f} %\\n\".\n",
    "              format(Epoch,train_loss,train_accuracy,valid_loss,valid_accuracy))\n",
    "\n",
    "        early_stopping(valid_loss, model)\n",
    "        if -early_stopping.best_score == valid_loss:\n",
    "            best_train_acc, best_valid_acc = train_accuracy,valid_accuracy\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "                train_accs.append(best_train_acc)\n",
    "                valid_accs.append(best_valid_acc)\n",
    "                print(\"[{} 교차검증] Early stopping\".format(data_ind))\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6767ec8",
   "metadata": {},
   "source": [
    "# 모델 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6824ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 교차검증] train ACC : 68.0955 |\t valid ACC: 66.0147 \n",
      "[2 교차검증] train ACC : 69.0753 |\t valid ACC: 61.6137 \n",
      "[3 교차검증] train ACC : 63.4639 |\t valid ACC: 65.9314 \n",
      "[4 교차검증] train ACC : 66.7687 |\t valid ACC: 68.8725 \n",
      "[5 교차검증] train ACC : 69.3390 |\t valid ACC: 65.1961 \n",
      "평균 검증 정확도 65.52567237163814 %\n"
     ]
    }
   ],
   "source": [
    "sum_valid=0\n",
    "for data_ind in range(5):\n",
    "    print(\"[{} 교차검증] train ACC : {:.4f} |\\t valid ACC: {:.4f} \".format(data_ind+1,train_accs[data_ind],valid_accs[data_ind] ))\n",
    "    sum_valid+=valid_accs[data_ind]\n",
    "    \n",
    "print(\"평균 검증 정확도\",sum_valid/5,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0967cf",
   "metadata": {},
   "source": [
    "# Model Test\n",
    "\n",
    "- test set\n",
    "- confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a19235bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix 계산\n",
    "#test set 계산.\n",
    "def test_evaluate(model,test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    predictions = []\n",
    "    answers = []\n",
    "    #no_grad : 그래디언트 값 계산 막기.\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "            answers +=label\n",
    "            predictions +=prediction\n",
    "            \n",
    "        return predictions,answers,test_loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca2e1ed2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[221.  50.]\n",
      " [ 89.  49.]]\n",
      "[[389. 153.]\n",
      " [143. 133.]]\n",
      "[[657. 156.]\n",
      " [279. 134.]]\n",
      "[[859. 225.]\n",
      " [337. 213.]]\n",
      "[[1093.  262.]\n",
      " [ 442.  245.]]\n",
      "Accuracy : 65.5240% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.7121\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.8066\n",
      "f score : 0.7564 \n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix (resnet18)\n",
    "# kfold의 confusion matrix는 계산 방법이 다르다.\n",
    "# 모델을 각각 불러와서 결과를 모두 합쳐줘야한다.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf = np.zeros((2,2))\n",
    "\n",
    "for data_ind in range(1,6):\n",
    "\n",
    "    check_path = '../checkpoint/checkpoint_resnet18_true_'+str(data_ind)+'_u.pt'\n",
    "    model.load_state_dict(torch.load(check_path))\n",
    "    _,validation_loader = load_data(data_ind-1)\n",
    "\n",
    "    predictions,answers,test_loss = test_evaluate(model, validation_loader)\n",
    "    predictions=[ dat.cpu().numpy() for dat in predictions]\n",
    "    answers=[ dat.cpu().numpy() for dat in answers]\n",
    "\n",
    "\n",
    "    cf += confusion_matrix(answers, predictions)\n",
    "    print(cf)\n",
    "\n",
    "acc = (cf[0,0]+cf[1,1])/(cf[0,0]+cf[0,1]+cf[1,0]+cf[1,1])\n",
    "precision=cf[0,0]/(cf[0,0]+cf[1,0])\n",
    "recall=cf[0,0]/(cf[0,0]+cf[0,1])\n",
    "fscore=2*precision*recall/(precision+recall)\n",
    "\n",
    "print(\"Accuracy : {:.4f}% \".format(acc*100))\n",
    "print(\"Precision (pathology 예측한 것중 맞는 것) : {:.4f}\".format(precision))\n",
    "print(\"recall (실제 pathology 중  예측이 맞는 것) : {:.4f}\".format(recall))\n",
    "print(\"f score : {:.4f} \".format(fscore))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51549b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "455.111px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
