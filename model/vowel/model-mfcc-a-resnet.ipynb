{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37664ece",
   "metadata": {},
   "source": [
    "- http://keunwoochoi.blogspot.com/2016/03/2.html\n",
    "- http://www.rex-ai.info/docs/AI_Example_CNN_speech_recognize\n",
    "- https://www.youtube.com/watch?v=oltGIc4uo5c\n",
    "- https://youdaeng-com.tistory.com/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "275b8092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pytorch version :  1.10.0  Device :  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn # 인공 신경망 모델들 모아놓은 모듈\n",
    "import torch.nn.functional as F #그중 자주 쓰이는것들을 F로\n",
    "from torchvision import transforms, datasets\n",
    "import cv2\n",
    "from torchvision import transforms, datasets\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "p = os.path.abspath('..') # 상위 폴더를 사용하기 위해서.\n",
    "sys.path.insert(1, p)\n",
    "from pytorchtools.pytorchtools import EarlyStopping # 현재 폴더에 추가된 모듈.\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "#DEVICE = torch.device('cpu')\n",
    "print('Using Pytorch version : ',torch.__version__,' Device : ',DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ebea6",
   "metadata": {},
   "source": [
    "# SVD 문장 데이터에서 Feature 추출\n",
    "- mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "114a1b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa, librosa.display \n",
    "import matplotlib.pyplot as plt\n",
    "#window sizde : FFT를 할때 참조할 그래프 길이 ( 프레임 하나당 sample 수 )\n",
    "#자연어 처리에서는 25ms 사용. https://ahnjg.tistory.com/93\n",
    "#초당 50000hz 중 1250개씩 윈도우 사이즈로 사용.\n",
    "sr=50000\n",
    "win_length =  np.int64(50000/40) # 1250\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c72d82e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pathology data 수 :  1194\n",
      "healthy data 수 :  687\n",
      "가장 긴 path sample : 131655\n",
      "가장 긴 healthy sample : 219501\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa, librosa.display \n",
    "import matplotlib.pyplot as plt\n",
    "#window sizde : FFT를 할때 참조할 그래프 길이 ( 프레임 하나당 sample 수 )\n",
    "#자연어 처리에서는 25ms 사용. https://ahnjg.tistory.com/93\n",
    "#초당 50000hz 중 1250개씩 윈도우 사이즈로 사용.\n",
    "sr=50000\n",
    "win_length =  np.int64(50000/40) # 1250\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다.\n",
    "\n",
    "pathology_sig=[]\n",
    "healthy_sig=[]\n",
    "\n",
    "pathology=[]\n",
    "healthy=[]\n",
    "\n",
    "\n",
    "#PATHOLOGY DATA\n",
    "for audio_path in os.listdir('../../voice_data/pathology_new/a/export'):\n",
    "    sig, sr = librosa.load('../../voice_data/pathology_new/a/export/'+audio_path, sr=50000)# 논문에서 f_s = 50 000HZ\n",
    "    pathology_sig.append(sig)\n",
    "    MFCCs = librosa.feature.mfcc(sig, sr, win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "    pathology.append(MFCCs)\n",
    "    \n",
    "\n",
    "#Healthy data\n",
    "for audio_path in os.listdir('../../voice_data/healthy_new/a/export'):\n",
    "    sig, sr = librosa.load('../../voice_data/healthy_new/a/export/'+audio_path, sr=50000)# 논문에서 f_s = 50 000HZ\n",
    "    healthy_sig.append(sig)\n",
    "    MFCCs = librosa.feature.mfcc(sig, sr, win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "    healthy.append(MFCCs)\n",
    "    \n",
    "print(\"pathology data 수 : \",len(pathology))\n",
    "print(\"healthy data 수 : \",len(healthy))\n",
    "\n",
    "\n",
    "path_max=max([ len(samples) for samples in pathology_sig])\n",
    "healthy_max=max([ len(samples) for samples in healthy_sig])\n",
    "print(\"가장 긴 path sample :\" ,path_max)\n",
    "print(\"가장 긴 healthy sample :\" ,healthy_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "636bede8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6331 초\n",
      "4.39002 초\n"
     ]
    }
   ],
   "source": [
    "print(path_max/sr,\"초\")\n",
    "print(healthy_max/sr,\"초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5915f64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 :  1.2573740201005026\n",
      "평균 :  1.314699767103348\n"
     ]
    }
   ],
   "source": [
    "print('평균 : ',np.mean([ len(samples) for samples in pathology_sig])/sr)\n",
    "print('평균 : ',np.mean([ len(samples) for samples in healthy_sig])/sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91bd1989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.504"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "400*313/sr\n",
    "#400 frame은 약 2.5초 이상."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148ec668",
   "metadata": {},
   "source": [
    "# 결과 확인\n",
    "- 1 row당 1 frame으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a48f3297",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>mfcc5</th>\n",
       "      <th>mfcc6</th>\n",
       "      <th>mfcc7</th>\n",
       "      <th>mfcc8</th>\n",
       "      <th>mfcc9</th>\n",
       "      <th>mfcc10</th>\n",
       "      <th>mfcc11</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-214.176651</td>\n",
       "      <td>207.977264</td>\n",
       "      <td>1.462625</td>\n",
       "      <td>13.944162</td>\n",
       "      <td>-63.319916</td>\n",
       "      <td>-2.144712</td>\n",
       "      <td>-16.828245</td>\n",
       "      <td>-21.429878</td>\n",
       "      <td>7.964348</td>\n",
       "      <td>-0.085761</td>\n",
       "      <td>-1.125562</td>\n",
       "      <td>-21.268238</td>\n",
       "      <td>-16.084270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-222.949982</td>\n",
       "      <td>209.148163</td>\n",
       "      <td>2.133819</td>\n",
       "      <td>17.240515</td>\n",
       "      <td>-52.081551</td>\n",
       "      <td>2.385664</td>\n",
       "      <td>-18.650604</td>\n",
       "      <td>-24.606426</td>\n",
       "      <td>3.663574</td>\n",
       "      <td>-1.903811</td>\n",
       "      <td>-8.280209</td>\n",
       "      <td>-16.000689</td>\n",
       "      <td>-12.138484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-248.733551</td>\n",
       "      <td>195.559235</td>\n",
       "      <td>-2.844307</td>\n",
       "      <td>7.977224</td>\n",
       "      <td>-52.356590</td>\n",
       "      <td>-1.202414</td>\n",
       "      <td>-16.476841</td>\n",
       "      <td>-20.510300</td>\n",
       "      <td>5.527544</td>\n",
       "      <td>-0.318386</td>\n",
       "      <td>-15.725111</td>\n",
       "      <td>-8.803049</td>\n",
       "      <td>-4.176742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-246.802917</td>\n",
       "      <td>198.915344</td>\n",
       "      <td>-3.477466</td>\n",
       "      <td>8.681169</td>\n",
       "      <td>-53.547142</td>\n",
       "      <td>-5.144975</td>\n",
       "      <td>-17.089766</td>\n",
       "      <td>-22.173811</td>\n",
       "      <td>4.114779</td>\n",
       "      <td>-1.155015</td>\n",
       "      <td>-14.204550</td>\n",
       "      <td>-9.640966</td>\n",
       "      <td>-2.181946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-245.827591</td>\n",
       "      <td>200.687988</td>\n",
       "      <td>0.568132</td>\n",
       "      <td>6.174569</td>\n",
       "      <td>-51.041344</td>\n",
       "      <td>-1.792537</td>\n",
       "      <td>-17.918312</td>\n",
       "      <td>-18.034185</td>\n",
       "      <td>5.677939</td>\n",
       "      <td>-2.018642</td>\n",
       "      <td>-12.768702</td>\n",
       "      <td>-11.336535</td>\n",
       "      <td>-1.299195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>-242.007767</td>\n",
       "      <td>200.297760</td>\n",
       "      <td>3.961174</td>\n",
       "      <td>14.153851</td>\n",
       "      <td>-52.725536</td>\n",
       "      <td>7.545429</td>\n",
       "      <td>-5.822221</td>\n",
       "      <td>-22.547153</td>\n",
       "      <td>6.216630</td>\n",
       "      <td>7.461223</td>\n",
       "      <td>-12.434643</td>\n",
       "      <td>-15.016934</td>\n",
       "      <td>12.251122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>-245.131500</td>\n",
       "      <td>196.616119</td>\n",
       "      <td>2.222031</td>\n",
       "      <td>15.436684</td>\n",
       "      <td>-56.961128</td>\n",
       "      <td>6.723224</td>\n",
       "      <td>-5.488671</td>\n",
       "      <td>-19.845875</td>\n",
       "      <td>7.457106</td>\n",
       "      <td>2.931230</td>\n",
       "      <td>-13.481985</td>\n",
       "      <td>-15.816978</td>\n",
       "      <td>13.508206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>-247.851624</td>\n",
       "      <td>198.925278</td>\n",
       "      <td>2.341530</td>\n",
       "      <td>14.167100</td>\n",
       "      <td>-54.980747</td>\n",
       "      <td>11.598038</td>\n",
       "      <td>-2.436407</td>\n",
       "      <td>-18.352262</td>\n",
       "      <td>8.678156</td>\n",
       "      <td>8.914279</td>\n",
       "      <td>-9.958929</td>\n",
       "      <td>-16.050816</td>\n",
       "      <td>15.700717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>-232.978348</td>\n",
       "      <td>215.946442</td>\n",
       "      <td>14.133223</td>\n",
       "      <td>16.482494</td>\n",
       "      <td>-50.424297</td>\n",
       "      <td>13.806274</td>\n",
       "      <td>-4.241011</td>\n",
       "      <td>-16.475407</td>\n",
       "      <td>5.775840</td>\n",
       "      <td>7.153922</td>\n",
       "      <td>-11.623649</td>\n",
       "      <td>-19.136692</td>\n",
       "      <td>15.453394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>-218.726624</td>\n",
       "      <td>225.969635</td>\n",
       "      <td>17.963581</td>\n",
       "      <td>17.724133</td>\n",
       "      <td>-46.865860</td>\n",
       "      <td>8.419164</td>\n",
       "      <td>-2.978050</td>\n",
       "      <td>-13.858909</td>\n",
       "      <td>9.973724</td>\n",
       "      <td>11.311474</td>\n",
       "      <td>-11.353134</td>\n",
       "      <td>-16.323940</td>\n",
       "      <td>12.591789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mfcc1       mfcc2      mfcc3      mfcc4      mfcc5      mfcc6  \\\n",
       "0   -214.176651  207.977264   1.462625  13.944162 -63.319916  -2.144712   \n",
       "1   -222.949982  209.148163   2.133819  17.240515 -52.081551   2.385664   \n",
       "2   -248.733551  195.559235  -2.844307   7.977224 -52.356590  -1.202414   \n",
       "3   -246.802917  198.915344  -3.477466   8.681169 -53.547142  -5.144975   \n",
       "4   -245.827591  200.687988   0.568132   6.174569 -51.041344  -1.792537   \n",
       "..          ...         ...        ...        ...        ...        ...   \n",
       "333 -242.007767  200.297760   3.961174  14.153851 -52.725536   7.545429   \n",
       "334 -245.131500  196.616119   2.222031  15.436684 -56.961128   6.723224   \n",
       "335 -247.851624  198.925278   2.341530  14.167100 -54.980747  11.598038   \n",
       "336 -232.978348  215.946442  14.133223  16.482494 -50.424297  13.806274   \n",
       "337 -218.726624  225.969635  17.963581  17.724133 -46.865860   8.419164   \n",
       "\n",
       "         mfcc7      mfcc8     mfcc9     mfcc10     mfcc11     mfcc12  \\\n",
       "0   -16.828245 -21.429878  7.964348  -0.085761  -1.125562 -21.268238   \n",
       "1   -18.650604 -24.606426  3.663574  -1.903811  -8.280209 -16.000689   \n",
       "2   -16.476841 -20.510300  5.527544  -0.318386 -15.725111  -8.803049   \n",
       "3   -17.089766 -22.173811  4.114779  -1.155015 -14.204550  -9.640966   \n",
       "4   -17.918312 -18.034185  5.677939  -2.018642 -12.768702 -11.336535   \n",
       "..         ...        ...       ...        ...        ...        ...   \n",
       "333  -5.822221 -22.547153  6.216630   7.461223 -12.434643 -15.016934   \n",
       "334  -5.488671 -19.845875  7.457106   2.931230 -13.481985 -15.816978   \n",
       "335  -2.436407 -18.352262  8.678156   8.914279  -9.958929 -16.050816   \n",
       "336  -4.241011 -16.475407  5.775840   7.153922 -11.623649 -19.136692   \n",
       "337  -2.978050 -13.858909  9.973724  11.311474 -11.353134 -16.323940   \n",
       "\n",
       "        mfcc13  \n",
       "0   -16.084270  \n",
       "1   -12.138484  \n",
       "2    -4.176742  \n",
       "3    -2.181946  \n",
       "4    -1.299195  \n",
       "..         ...  \n",
       "333  12.251122  \n",
       "334  13.508206  \n",
       "335  15.700717  \n",
       "336  15.453394  \n",
       "337  12.591789  \n",
       "\n",
       "[338 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(healthy[0][2]) #1번 : 파일. 2번:mfcc\n",
    "headers = \"mfcc1 mfcc2 mfcc3 mfcc4 mfcc5 mfcc6 mfcc7 mfcc8 mfcc9 mfcc10 mfcc11 mfcc12 mfcc13\".split()\n",
    "pd.DataFrame(healthy[1].T,columns=headers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "186be135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthy[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73d328bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "del pathology\n",
    "del healthy\n",
    "del pathology_sig\n",
    "del healthy_sig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23a4c15",
   "metadata": {},
   "source": [
    "# 데이터 나누기 - Stratified KFold\n",
    "\n",
    "- pathology : 1194 / healthy : 687 / 총 1881\n",
    "- k = 5\n",
    "- random over sampling 추가 ( healthy 데이터가 부족하기 때문)\n",
    "- 변경 후 -> pathology : 1194 / healthy : 1194 / 총: 2388"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bdff43",
   "metadata": {},
   "source": [
    "kfold와 random over sampling을 같이 실시하려면, 미리 test set을 나눠야 한다.\n",
    "\n",
    "먼저 테스트셋을 나누고, 그 후에 random over sampling을 실시한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3071a27",
   "metadata": {},
   "source": [
    "## 1. test/ train 나누기\n",
    "\n",
    "- train+valid :1504  / test : 377\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5175e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pathology :  1194\n",
      "Healthy:  687\n",
      "총 데이터수 :  1881\n",
      "---\n",
      "훈련 셋 :  1504 Counter({'pathology': 955, 'healthy': 549})\n",
      "테스트 셋 :  377 Counter({'pathology': 239, 'healthy': 138})\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "#1. train, test 나누기\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split # train , test 분리에 사용.\n",
    "\n",
    "pathology = glob('../../voice_data/pathology_new/a/export/*.wav')\n",
    "healthy = glob('../../voice_data/healthy_new/a/export/*.wav')\n",
    "print(\"Pathology : \",len(pathology))\n",
    "print(\"Healthy: \",len(healthy))\n",
    "\n",
    "X = pathology+healthy # path 데이터 합\n",
    "print(\"총 데이터수 : \",len(X))\n",
    "Y = [] # 라벨\n",
    "for idx,x in enumerate(X):\n",
    "    if idx<1194:\n",
    "        Y.append(\"pathology\")\n",
    "    else:\n",
    "        Y.append(\"healthy\")\n",
    "\n",
    "#train 1504   test: 377\n",
    "X, X_test, Y, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True, stratify=Y, random_state=456)\n",
    "#stratify를 넣어서, test에도 라벨별 잘 분류되게 한다.\n",
    "\n",
    "print(\"---\")\n",
    "print(\"훈련 셋 : \",len(Y),Counter(Y))\n",
    "print(\"테스트 셋 : \",len(Y_test),Counter(Y_test))\n",
    "print(\"---\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dc6b50",
   "metadata": {},
   "source": [
    "## 2. random over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc4a0dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before dataset shape Counter({'pathology': 955, 'healthy': 549})\n",
      "Resampled dataset shape Counter({'healthy': 955, 'pathology': 955})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = np.array(X).reshape(-1,1)#각 데이터를 다 행으로 넣음. (1194,1)\n",
    "#Y = np.array(Y)\n",
    "ros = RandomOverSampler(random_state = 123)\n",
    "X_res,Y_res = ros.fit_resample(X,Y)\n",
    "\n",
    "print('before dataset shape {}'.format(Counter(Y)) )\n",
    "print('Resampled dataset shape {}'.format(Counter(Y_res)) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09f636fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['../../voice_data/healthy_new/a/export\\\\60-a_n.wav'],\n",
       "       ['../../voice_data/pathology_new/a/export\\\\2421-a_n.wav'],\n",
       "       ['../../voice_data/pathology_new/a/export\\\\1270-a_n.wav'],\n",
       "       ...,\n",
       "       ['../../voice_data/healthy_new/a/export\\\\1127-a_n.wav'],\n",
       "       ['../../voice_data/healthy_new/a/export\\\\1533-a_n.wav'],\n",
       "       ['../../voice_data/healthy_new/a/export\\\\1359-a_n.wav']],\n",
       "      dtype='<U52')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e3e54dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 데이터수 :  1910\n",
      "복사된 수 :  406\n"
     ]
    }
   ],
   "source": [
    "#원래대로 돌리기\n",
    "X=X_res.reshape(1, -1)\n",
    "print( '총 데이터수 : ',X[0].size )\n",
    "print(  '복사된 수 : ',X[0].size - np.unique(X[0]).size )\n",
    "\n",
    "X=X[0].tolist()\n",
    "Y=Y_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e266880",
   "metadata": {},
   "source": [
    "## 3. stratified k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fada6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 : 1\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 764, 'pathology': 764}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 191, 'pathology': 191} \n",
      "\n",
      "교차 검증 : 2\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 764, 'pathology': 764}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 191, 'pathology': 191} \n",
      "\n",
      "교차 검증 : 3\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 764, 'pathology': 764}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 191, 'pathology': 191} \n",
      "\n",
      "교차 검증 : 4\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 764, 'pathology': 764}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 191, 'pathology': 191} \n",
      "\n",
      "교차 검증 : 5\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 764, 'pathology': 764}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 191, 'pathology': 191} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. train, test 나누기\n",
    "#stratified kfold\n",
    "import os\n",
    "import random #데이터 shuffle 사용\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "skf_iris = StratifiedKFold(n_splits=5,shuffle=True,random_state=456)\n",
    "cnt_iter = 0\n",
    "\n",
    "X_train_list = [] #데이터 셋 보관\n",
    "Y_train_list = []\n",
    "\n",
    "X_valid_list = []\n",
    "Y_valid_list = []\n",
    "\n",
    "for train_idx, test_idx in skf_iris.split(X,Y):\n",
    "    \n",
    "    #split으로 반환된 인덱스를 이용하여, 학습 검증용 테스트 데이터 추출\n",
    "    cnt_iter += 1\n",
    "    X_train, X_valid = [X[idx] for idx in train_idx.tolist() ], [X[idx] for idx in test_idx.tolist() ]\n",
    "    Y_train, Y_valid = [Y[idx] for idx in train_idx.tolist() ], [Y[idx] for idx in test_idx.tolist() ]\n",
    "    \n",
    "    X_train_list.append(X_train)\n",
    "    X_valid_list.append(X_valid)\n",
    "    \n",
    "    Y_train_list.append(Y_train)\n",
    "    Y_valid_list.append(Y_valid)\n",
    "    \n",
    "    \n",
    "    #학습 및 예측\n",
    "    \n",
    "    label_train = Y_train\n",
    "    label_test = Y_valid\n",
    "    unique_train, train_counts = np.unique(label_train, return_counts = True)\n",
    "    unique_test, test_counts = np.unique(label_test, return_counts = True)\n",
    "    \n",
    "    uniq_cnt_train = dict(zip(unique_train, train_counts))\n",
    "    uniq_cnt_test = dict(zip(unique_test, test_counts))\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('교차 검증 : {}'.format(cnt_iter))\n",
    "    print('학습 레이블 데이터 분포 : \\n', uniq_cnt_train)\n",
    "    print('검증 레이블 데이터 분포 : \\n', uniq_cnt_test,'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a663f0",
   "metadata": {},
   "source": [
    "# 데이터 정의\n",
    "- 추가적으로 데이터의 크기를 맞춰주기 위해 3초로 padding 및 truncate 실시 https://sequencedata.tistory.com/25 FixAudioLength\n",
    "- 논문에서는 400frame으로 설정.\n",
    "- 전처리 방법 결정.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2febf8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "classes = [\"pathology\",\"healthy\"]\n",
    "sr=50000\n",
    "win_length =  np.int64(50000/40) # 1250\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다.\n",
    "\n",
    "\n",
    "\n",
    "class svd_dataset(Dataset):\n",
    "    def __init__(self,data_path_list,classes,data_num,training,transform=None):\n",
    "        #클래스에서 사용할 인자를 받아 인스턴스 변수로 저장하는 일을 한다.\n",
    "        #예를들면, 이미지의 경로 리스트를 저장하는 일을 하게 된다.\n",
    "        \n",
    "        #data_num : k 개 데이터 셋 중 어떤것을 쓸지\n",
    "        #test인지 아닌지.\n",
    "        \n",
    "        self.path_list = data_path_list[data_num]\n",
    "        self.data_num = data_num\n",
    "        self.training = training\n",
    "        self.label = svd_dataset.get_label(self.path_list,training,data_num)\n",
    "        self.classes=classes\n",
    "        self.transform=transform\n",
    "        \n",
    "    \n",
    "    @classmethod\n",
    "    def get_label(cls,data_path_list,training,data_num):\n",
    "        label_list=[]\n",
    "        \n",
    "        if training:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_train_list[data_num][idx])\n",
    "        else:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_valid_list[data_num][idx])\n",
    "        #print(label_list)\n",
    "        return label_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "        #데이터 셋의 길이를 정수로 반환한다. \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        1. path를 받아서, 소리에서 mfcc를 추출\n",
    "        2. mfcc를 500프레임으로 패딩.\n",
    "        3. resnet에 사용되기 위해 3채널로 복사(rgb 처럼)\n",
    "        4. 0~1 정규화\n",
    "        \n",
    "        \"\"\"\n",
    "        sig, sr = librosa.load(self.path_list[idx], sr=50000)# 논문에서 f_s = 50 000HZ\n",
    "        \n",
    "        MFCCs = librosa.feature.mfcc(sig, sr, win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "        #mfcc 500 FRAME이 되도록 패딩.\n",
    "        length = 500\n",
    "        pad2d = lambda a, i: a[:, 0:i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0], i-a.shape[1]))))\n",
    "        MFCCs = pad2d(MFCCs, length)\n",
    "        MFCCs= MFCCs.T\n",
    "        \n",
    "        if self.transform:\n",
    "            #print('transform')\n",
    "            MFCCs=self.transform(MFCCs).type(torch.float32)# 데이터 0~1 정규화\n",
    "            MFCCs=torch.stack([MFCCs,MFCCs,MFCCs])# 3채널로 복사.\n",
    "            MFCCs = MFCCs.squeeze(dim=1)\n",
    "        else:\n",
    "            #print(\"else\")\n",
    "            MFCCs = torch.from_numpy(MFCCs).type(torch.float32)\n",
    "            MFCCs=MFCCs.unsqueeze(0)#cnn 사용위해서 추가\n",
    "            #MFCCs = MFCCs.permute(2, 0, 1)\n",
    "        return MFCCs, self.classes.index(self.label[idx])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599de2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set 제작을 위한 class\n",
    "class svd_test_set(Dataset):\n",
    "    def __init__(self,data_path_list,classes,transform=None):\n",
    "        #클래스에서 사용할 인자를 받아 인스턴스 변수로 저장하는 일을 한다.\n",
    "        #예를들면, 이미지의 경로 리스트를 저장하는 일을 하게 된다.\n",
    "        \n",
    "        #data_num : k 개 데이터 셋 중 어떤것을 쓸지\n",
    "        #test인지 아닌지.\n",
    "        \n",
    "        self.path_list = data_path_list\n",
    "        self.label = svd_test_set.get_label(self.path_list)\n",
    "        self.classes=classes\n",
    "        self.transform=transform\n",
    "        \n",
    "    \n",
    "    @classmethod\n",
    "    def get_label(cls,data_path_list):\n",
    "        label_list=[]\n",
    "        \n",
    "        for idx,x in enumerate(data_path_list):\n",
    "            label_list.append(Y_test[idx])\n",
    "        #print(label_list)\n",
    "        return label_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "        #데이터 셋의 길이를 정수로 반환한다. \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        1. path를 받아서, 소리에서 mfcc를 추출\n",
    "        2. mfcc를 500프레임으로 패딩.\n",
    "        3. resnet에 사용되기 위해 3채널로 복사(rgb 처럼)\n",
    "        4. 0~1 정규화\n",
    "        \n",
    "        \"\"\"\n",
    "        sig, sr = librosa.load(self.path_list[idx], sr=50000)# 논문에서 f_s = 50 000HZ\n",
    "        \n",
    "        MFCCs = librosa.feature.mfcc(sig, sr, win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "        #mfcc 500 FRAME이 되도록 패딩.\n",
    "        length = 500\n",
    "        pad2d = lambda a, i: a[:, 0:i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0], i-a.shape[1]))))\n",
    "        MFCCs = pad2d(MFCCs, length)\n",
    "        MFCCs= MFCCs.T\n",
    "        \n",
    "        if self.transform:\n",
    "            #print('transform')\n",
    "            MFCCs=self.transform(MFCCs).type(torch.float32)# 데이터 0~1 정규화\n",
    "            MFCCs=torch.stack([MFCCs,MFCCs,MFCCs])# 3채널로 복사.\n",
    "            MFCCs = MFCCs.squeeze(dim=1)\n",
    "        else:\n",
    "            #print(\"else\")\n",
    "            MFCCs = torch.from_numpy(MFCCs).type(torch.float32)\n",
    "            MFCCs=MFCCs.unsqueeze(0)#cnn 사용위해서 추가\n",
    "            #MFCCs = MFCCs.permute(2, 0, 1)\n",
    "        return MFCCs, self.classes.index(self.label[idx])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d05129d",
   "metadata": {},
   "source": [
    "# 데이터 로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89052fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. 하이퍼 파라미터\n",
    "BATCH_SIZE =  30 #한 배치당 30개 음성데이터 # 32 배수시에, 1개만 남는 경우가 발생해서.\n",
    "EPOCHS = 40 # 전체 데이터 셋을 40번 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bba97b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA LOADER 함수가 BATCH_size 단위로 분리해 지정.\n",
    "\n",
    "#확인을 위해 데이터셋 하나만 확인\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                           svd_dataset(\n",
    "                                               X_train_list,\n",
    "                                               classes,\n",
    "                                               transform = transforms.ToTensor(),#이걸 composed로 고쳐서 전처리 하도록 수정.\n",
    "                                               data_num=0,\n",
    "                                               training=True\n",
    "                                           ),\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True,\n",
    "                                           ) # 순서가 암기되는것을 막기위해.\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                           svd_dataset(\n",
    "                                               X_valid_list,\n",
    "                                               classes,\n",
    "                                               transform = transforms.ToTensor(),\n",
    "                                               data_num=0,\n",
    "                                               training=False\n",
    "                                           ),\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True,) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba4e003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 로더.\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_test_set(\n",
    "                                                   X_test,\n",
    "                                                   classes,\n",
    "                                                   transform = transforms.ToTensor(),\n",
    "                                               ),\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = True,) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b15a86",
   "metadata": {},
   "source": [
    "# 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f866237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :  torch.Size([30, 3, 400, 13]) type: torch.FloatTensor\n",
      "Y_train :  torch.Size([30]) type: torch.LongTensor\n",
      "tensor(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x23b0f92aa90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. 데이터 확인하기\n",
    "for (X_train,Y_train) in train_loader:\n",
    "    print(\"X_train : \",X_train.size(),'type:',X_train.type())\n",
    "    print(\"Y_train : \",Y_train.size(),'type:',Y_train.type())\n",
    "    break\n",
    "    \n",
    "print(Y_train[0])\n",
    "librosa.display.specshow(X_train[0][0].numpy().T, sr=50000, x_axis='time')\n",
    "#batch: 32 / frame수: 400  /  feature수: 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a45b51bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valid :  torch.Size([30, 3, 400, 13]) type: torch.FloatTensor\n",
      "Y_valid :  torch.Size([30]) type: torch.LongTensor\n",
      "tensor(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x23b0fa07f40>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#valiation set 확인\n",
    "for (X_valid,Y_valid) in validation_loader:\n",
    "    print(\"X_valid : \",X_valid.size(),'type:',X_valid.type())\n",
    "    print(\"Y_valid : \",Y_valid.size(),'type:',Y_valid.type())\n",
    "    break\n",
    "\n",
    "print(Y_valid[0])\n",
    "librosa.display.specshow(X_valid[0][0].numpy().T, sr=50000, x_axis='time')\n",
    "#batch: 32 / 3채널 / frame수: 400  /  feature수: 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16debbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test set 확인\n",
    "for (test_data,test_label) in test_loader:\n",
    "    print(\"X_valid : \",test_data.size(),'type:',test_data.type())\n",
    "    print(\"Y_valid : \",test_label.size(),'type:',test_label.type())\n",
    "    break\n",
    "\n",
    "print(Y_valid[0])\n",
    "librosa.display.specshow(test_data[0][0].numpy().T, sr=50000, x_axis='time')\n",
    "#batch: 32 / 3채널 / frame수: 500  /  feature수: 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec40ea4",
   "metadata": {},
   "source": [
    "# RESNET18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e1d59a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 \n",
    "# pretrained\n",
    "\n",
    "\n",
    "def model_initialize():\n",
    "    model = models.resnet18(pretrained=True).cuda()\n",
    "    model.ftrs = model.fc.in_features # in_features : fully connected의 입력수.\n",
    "    num_ftrs = model.fc.in_features\n",
    "\n",
    "    model.fc = nn.Sequential(nn.Linear(num_ftrs, 256),\n",
    "                             nn.BatchNorm1d(256),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(256,128),\n",
    "                             nn.BatchNorm1d(128),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(128,64),\n",
    "                             nn.BatchNorm1d(64),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(64,50),\n",
    "                             nn.BatchNorm1d(50),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(50,2)\n",
    "                            )\n",
    "\n",
    "    model = model.cuda()\n",
    "    return model\n",
    "model=model_initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c26ff30a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.5, inplace=False)\n",
      "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.5, inplace=False)\n",
      "    (12): Linear(in_features=64, out_features=50, bias=True)\n",
      "    (13): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU()\n",
      "    (15): Dropout(p=0.5, inplace=False)\n",
      "    (16): Linear(in_features=50, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6097d312",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 200, 7]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 200, 7]             128\n",
      "              ReLU-3           [-1, 64, 200, 7]               0\n",
      "         MaxPool2d-4           [-1, 64, 100, 4]               0\n",
      "            Conv2d-5           [-1, 64, 100, 4]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 100, 4]             128\n",
      "              ReLU-7           [-1, 64, 100, 4]               0\n",
      "            Conv2d-8           [-1, 64, 100, 4]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 100, 4]             128\n",
      "             ReLU-10           [-1, 64, 100, 4]               0\n",
      "       BasicBlock-11           [-1, 64, 100, 4]               0\n",
      "           Conv2d-12           [-1, 64, 100, 4]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 100, 4]             128\n",
      "             ReLU-14           [-1, 64, 100, 4]               0\n",
      "           Conv2d-15           [-1, 64, 100, 4]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 100, 4]             128\n",
      "             ReLU-17           [-1, 64, 100, 4]               0\n",
      "       BasicBlock-18           [-1, 64, 100, 4]               0\n",
      "           Conv2d-19           [-1, 128, 50, 2]          73,728\n",
      "      BatchNorm2d-20           [-1, 128, 50, 2]             256\n",
      "             ReLU-21           [-1, 128, 50, 2]               0\n",
      "           Conv2d-22           [-1, 128, 50, 2]         147,456\n",
      "      BatchNorm2d-23           [-1, 128, 50, 2]             256\n",
      "           Conv2d-24           [-1, 128, 50, 2]           8,192\n",
      "      BatchNorm2d-25           [-1, 128, 50, 2]             256\n",
      "             ReLU-26           [-1, 128, 50, 2]               0\n",
      "       BasicBlock-27           [-1, 128, 50, 2]               0\n",
      "           Conv2d-28           [-1, 128, 50, 2]         147,456\n",
      "      BatchNorm2d-29           [-1, 128, 50, 2]             256\n",
      "             ReLU-30           [-1, 128, 50, 2]               0\n",
      "           Conv2d-31           [-1, 128, 50, 2]         147,456\n",
      "      BatchNorm2d-32           [-1, 128, 50, 2]             256\n",
      "             ReLU-33           [-1, 128, 50, 2]               0\n",
      "       BasicBlock-34           [-1, 128, 50, 2]               0\n",
      "           Conv2d-35           [-1, 256, 25, 1]         294,912\n",
      "      BatchNorm2d-36           [-1, 256, 25, 1]             512\n",
      "             ReLU-37           [-1, 256, 25, 1]               0\n",
      "           Conv2d-38           [-1, 256, 25, 1]         589,824\n",
      "      BatchNorm2d-39           [-1, 256, 25, 1]             512\n",
      "           Conv2d-40           [-1, 256, 25, 1]          32,768\n",
      "      BatchNorm2d-41           [-1, 256, 25, 1]             512\n",
      "             ReLU-42           [-1, 256, 25, 1]               0\n",
      "       BasicBlock-43           [-1, 256, 25, 1]               0\n",
      "           Conv2d-44           [-1, 256, 25, 1]         589,824\n",
      "      BatchNorm2d-45           [-1, 256, 25, 1]             512\n",
      "             ReLU-46           [-1, 256, 25, 1]               0\n",
      "           Conv2d-47           [-1, 256, 25, 1]         589,824\n",
      "      BatchNorm2d-48           [-1, 256, 25, 1]             512\n",
      "             ReLU-49           [-1, 256, 25, 1]               0\n",
      "       BasicBlock-50           [-1, 256, 25, 1]               0\n",
      "           Conv2d-51           [-1, 512, 13, 1]       1,179,648\n",
      "      BatchNorm2d-52           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-53           [-1, 512, 13, 1]               0\n",
      "           Conv2d-54           [-1, 512, 13, 1]       2,359,296\n",
      "      BatchNorm2d-55           [-1, 512, 13, 1]           1,024\n",
      "           Conv2d-56           [-1, 512, 13, 1]         131,072\n",
      "      BatchNorm2d-57           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-58           [-1, 512, 13, 1]               0\n",
      "       BasicBlock-59           [-1, 512, 13, 1]               0\n",
      "           Conv2d-60           [-1, 512, 13, 1]       2,359,296\n",
      "      BatchNorm2d-61           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-62           [-1, 512, 13, 1]               0\n",
      "           Conv2d-63           [-1, 512, 13, 1]       2,359,296\n",
      "      BatchNorm2d-64           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-65           [-1, 512, 13, 1]               0\n",
      "       BasicBlock-66           [-1, 512, 13, 1]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                  [-1, 256]         131,328\n",
      "      BatchNorm1d-69                  [-1, 256]             512\n",
      "             ReLU-70                  [-1, 256]               0\n",
      "          Dropout-71                  [-1, 256]               0\n",
      "           Linear-72                  [-1, 128]          32,896\n",
      "      BatchNorm1d-73                  [-1, 128]             256\n",
      "             ReLU-74                  [-1, 128]               0\n",
      "          Dropout-75                  [-1, 128]               0\n",
      "           Linear-76                   [-1, 64]           8,256\n",
      "      BatchNorm1d-77                   [-1, 64]             128\n",
      "             ReLU-78                   [-1, 64]               0\n",
      "          Dropout-79                   [-1, 64]               0\n",
      "           Linear-80                   [-1, 50]           3,250\n",
      "      BatchNorm1d-81                   [-1, 50]             100\n",
      "             ReLU-82                   [-1, 50]               0\n",
      "          Dropout-83                   [-1, 50]               0\n",
      "           Linear-84                    [-1, 2]             102\n",
      "================================================================\n",
      "Total params: 11,353,340\n",
      "Trainable params: 11,353,340\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 8.16\n",
      "Params size (MB): 43.31\n",
      "Estimated Total Size (MB): 51.52\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# get the model summary\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 400, 13), device=DEVICE.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f2ca15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. 학습\n",
    "def train(model,train_loader,optimizer, log_interval):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    train_loss = 0\n",
    "    for batch_idx,(image,label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        #데이터들 장비에 할당\n",
    "        optimizer.zero_grad() # device 에 저장된 gradient 제거\n",
    "        output = model(image) # model로 output을 계산\n",
    "        loss = criterion(output, label) #loss 계산\n",
    "        train_loss += loss.item()\n",
    "        prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "        correct += prediction.eq(label.view_as(prediction)).sum().item()# 아웃풋이 배치 사이즈 32개라서.\n",
    "        loss.backward() # loss 값을 이용해 gradient를 계산\n",
    "        optimizer.step() # Gradient 값을 이용해 파라미터 업데이트.\n",
    "    train_loss/=len(train_loader.dataset)\n",
    "    train_accuracy = 100. * correct / len(train_loader.dataset)\n",
    "    return train_loss,train_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b09341bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. 학습 진행하며, validation 데이터로 모델 성능확인\n",
    "def evaluate(model,valid_loader):\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    #no_grad : 그래디언트 값 계산 막기.\n",
    "    with torch.no_grad():\n",
    "        for image, label in valid_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            valid_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()# 아웃풋이 배치 사이즈 32개라서.\n",
    "            #true.false값을 sum해줌. item\n",
    "        valid_loss /= len(valid_loader.dataset)\n",
    "        valid_accuracy = 100. * correct / len(valid_loader.dataset)\n",
    "        return valid_loss,valid_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae179080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 로더 제작 함수\n",
    "\n",
    "def load_data(data_ind):\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_dataset(\n",
    "                                                   X_train_list,\n",
    "                                                   classes,\n",
    "                                                   transform = transforms.ToTensor(),#이걸 composed로 고쳐서 전처리 하도록 수정.\n",
    "                                                   data_num=data_ind,\n",
    "                                                   training=True\n",
    "                                               ),\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = True,\n",
    "                                               ) # 순서가 암기되는것을 막기위해.\n",
    "\n",
    "    validation_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_dataset(\n",
    "                                                   X_test_list,\n",
    "                                                   classes,\n",
    "                                                   transform = transforms.ToTensor(),\n",
    "                                                   data_num=data_ind,\n",
    "                                                   training=False\n",
    "                                               ),\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = True,) \n",
    "    return train_loader,validation_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7c8c86f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0239\t Train Acc:50.84 %  | \tValid Loss:0.0229 \tValid Acc: 53.35 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.022916).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0240\t Train Acc:50.16 %  | \tValid Loss:0.0227 \tValid Acc: 59.00 %\n",
      "\n",
      "Validation loss decreased (0.022916 --> 0.022652).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0234\t Train Acc:53.72 %  | \tValid Loss:0.0218 \tValid Acc: 60.88 %\n",
      "\n",
      "Validation loss decreased (0.022652 --> 0.021824).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0231\t Train Acc:55.29 %  | \tValid Loss:0.0217 \tValid Acc: 63.18 %\n",
      "\n",
      "Validation loss decreased (0.021824 --> 0.021728).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0226\t Train Acc:58.06 %  | \tValid Loss:0.0218 \tValid Acc: 61.30 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0224\t Train Acc:59.69 %  | \tValid Loss:0.0210 \tValid Acc: 63.18 %\n",
      "\n",
      "Validation loss decreased (0.021728 --> 0.020962).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0216\t Train Acc:63.25 %  | \tValid Loss:0.0210 \tValid Acc: 62.97 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0212\t Train Acc:64.35 %  | \tValid Loss:0.0211 \tValid Acc: 64.23 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0206\t Train Acc:66.34 %  | \tValid Loss:0.0206 \tValid Acc: 65.06 %\n",
      "\n",
      "Validation loss decreased (0.020962 --> 0.020568).  Saving model ...\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0201\t Train Acc:69.06 %  | \tValid Loss:0.0208 \tValid Acc: 63.39 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0194\t Train Acc:71.47 %  | \tValid Loss:0.0199 \tValid Acc: 67.57 %\n",
      "\n",
      "Validation loss decreased (0.020568 --> 0.019949).  Saving model ...\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0190\t Train Acc:72.20 %  | \tValid Loss:0.0197 \tValid Acc: 66.95 %\n",
      "\n",
      "Validation loss decreased (0.019949 --> 0.019668).  Saving model ...\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0185\t Train Acc:74.55 %  | \tValid Loss:0.0203 \tValid Acc: 65.48 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0172\t Train Acc:76.60 %  | \tValid Loss:0.0208 \tValid Acc: 61.51 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0163\t Train Acc:79.58 %  | \tValid Loss:0.0195 \tValid Acc: 67.15 %\n",
      "\n",
      "Validation loss decreased (0.019668 --> 0.019510).  Saving model ...\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0154\t Train Acc:80.79 %  | \tValid Loss:0.0191 \tValid Acc: 68.62 %\n",
      "\n",
      "Validation loss decreased (0.019510 --> 0.019077).  Saving model ...\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0145\t Train Acc:83.40 %  | \tValid Loss:0.0189 \tValid Acc: 70.50 %\n",
      "\n",
      "Validation loss decreased (0.019077 --> 0.018925).  Saving model ...\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0137\t Train Acc:84.61 %  | \tValid Loss:0.0189 \tValid Acc: 68.62 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0132\t Train Acc:85.39 %  | \tValid Loss:0.0177 \tValid Acc: 74.48 %\n",
      "\n",
      "Validation loss decreased (0.018925 --> 0.017675).  Saving model ...\n",
      "\n",
      "[EPOCH:20]\t Train Loss:0.0121\t Train Acc:87.59 %  | \tValid Loss:0.0184 \tValid Acc: 70.29 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:21]\t Train Loss:0.0109\t Train Acc:89.27 %  | \tValid Loss:0.0194 \tValid Acc: 71.76 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:22]\t Train Loss:0.0094\t Train Acc:91.31 %  | \tValid Loss:0.0204 \tValid Acc: 71.13 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:23]\t Train Loss:0.0097\t Train Acc:90.37 %  | \tValid Loss:0.0184 \tValid Acc: 73.64 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:24]\t Train Loss:0.0094\t Train Acc:90.42 %  | \tValid Loss:0.0192 \tValid Acc: 71.34 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[1 교차검증] Early stopping\n",
      "[2 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0248\t Train Acc:51.99 %  | \tValid Loss:0.0227 \tValid Acc: 58.37 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.022703).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0238\t Train Acc:53.30 %  | \tValid Loss:0.0218 \tValid Acc: 60.67 %\n",
      "\n",
      "Validation loss decreased (0.022703 --> 0.021834).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0227\t Train Acc:56.96 %  | \tValid Loss:0.0215 \tValid Acc: 61.72 %\n",
      "\n",
      "Validation loss decreased (0.021834 --> 0.021538).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0221\t Train Acc:59.74 %  | \tValid Loss:0.0213 \tValid Acc: 63.18 %\n",
      "\n",
      "Validation loss decreased (0.021538 --> 0.021318).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0213\t Train Acc:62.88 %  | \tValid Loss:0.0208 \tValid Acc: 64.44 %\n",
      "\n",
      "Validation loss decreased (0.021318 --> 0.020779).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0211\t Train Acc:64.61 %  | \tValid Loss:0.0202 \tValid Acc: 64.44 %\n",
      "\n",
      "Validation loss decreased (0.020779 --> 0.020223).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0205\t Train Acc:66.91 %  | \tValid Loss:0.0203 \tValid Acc: 64.44 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0196\t Train Acc:68.01 %  | \tValid Loss:0.0200 \tValid Acc: 68.62 %\n",
      "\n",
      "Validation loss decreased (0.020223 --> 0.019957).  Saving model ...\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0186\t Train Acc:72.88 %  | \tValid Loss:0.0193 \tValid Acc: 71.34 %\n",
      "\n",
      "Validation loss decreased (0.019957 --> 0.019304).  Saving model ...\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0182\t Train Acc:73.56 %  | \tValid Loss:0.0193 \tValid Acc: 68.62 %\n",
      "\n",
      "Validation loss decreased (0.019304 --> 0.019266).  Saving model ...\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0170\t Train Acc:77.33 %  | \tValid Loss:0.0190 \tValid Acc: 70.50 %\n",
      "\n",
      "Validation loss decreased (0.019266 --> 0.019031).  Saving model ...\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0164\t Train Acc:77.54 %  | \tValid Loss:0.0181 \tValid Acc: 72.38 %\n",
      "\n",
      "Validation loss decreased (0.019031 --> 0.018093).  Saving model ...\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0153\t Train Acc:80.21 %  | \tValid Loss:0.0181 \tValid Acc: 72.59 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0142\t Train Acc:82.67 %  | \tValid Loss:0.0183 \tValid Acc: 70.08 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0130\t Train Acc:86.39 %  | \tValid Loss:0.0182 \tValid Acc: 74.48 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0121\t Train Acc:88.95 %  | \tValid Loss:0.0177 \tValid Acc: 70.92 %\n",
      "\n",
      "Validation loss decreased (0.018093 --> 0.017681).  Saving model ...\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0107\t Train Acc:90.47 %  | \tValid Loss:0.0182 \tValid Acc: 72.80 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0094\t Train Acc:91.99 %  | \tValid Loss:0.0193 \tValid Acc: 70.29 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0089\t Train Acc:91.83 %  | \tValid Loss:0.0187 \tValid Acc: 72.18 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:20]\t Train Loss:0.0086\t Train Acc:92.62 %  | \tValid Loss:0.0208 \tValid Acc: 72.38 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:21]\t Train Loss:0.0080\t Train Acc:93.51 %  | \tValid Loss:0.0170 \tValid Acc: 76.57 %\n",
      "\n",
      "Validation loss decreased (0.017681 --> 0.017033).  Saving model ...\n",
      "\n",
      "[EPOCH:22]\t Train Loss:0.0072\t Train Acc:94.87 %  | \tValid Loss:0.0194 \tValid Acc: 73.22 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:23]\t Train Loss:0.0070\t Train Acc:94.55 %  | \tValid Loss:0.0179 \tValid Acc: 75.52 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:24]\t Train Loss:0.0064\t Train Acc:95.13 %  | \tValid Loss:0.0202 \tValid Acc: 74.69 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:25]\t Train Loss:0.0066\t Train Acc:94.45 %  | \tValid Loss:0.0241 \tValid Acc: 70.71 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:26]\t Train Loss:0.0070\t Train Acc:93.82 %  | \tValid Loss:0.0219 \tValid Acc: 74.27 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[2 교차검증] Early stopping\n",
      "[3 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0254\t Train Acc:52.09 %  | \tValid Loss:0.0228 \tValid Acc: 55.86 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.022761).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0251\t Train Acc:51.36 %  | \tValid Loss:0.0230 \tValid Acc: 56.07 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0241\t Train Acc:52.98 %  | \tValid Loss:0.0227 \tValid Acc: 55.65 %\n",
      "\n",
      "Validation loss decreased (0.022761 --> 0.022710).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0237\t Train Acc:56.44 %  | \tValid Loss:0.0226 \tValid Acc: 57.95 %\n",
      "\n",
      "Validation loss decreased (0.022710 --> 0.022619).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0229\t Train Acc:58.48 %  | \tValid Loss:0.0224 \tValid Acc: 59.83 %\n",
      "\n",
      "Validation loss decreased (0.022619 --> 0.022353).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0222\t Train Acc:60.99 %  | \tValid Loss:0.0223 \tValid Acc: 57.95 %\n",
      "\n",
      "Validation loss decreased (0.022353 --> 0.022260).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH:7]\t Train Loss:0.0222\t Train Acc:61.68 %  | \tValid Loss:0.0215 \tValid Acc: 63.81 %\n",
      "\n",
      "Validation loss decreased (0.022260 --> 0.021544).  Saving model ...\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0217\t Train Acc:63.46 %  | \tValid Loss:0.0217 \tValid Acc: 63.18 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0215\t Train Acc:63.51 %  | \tValid Loss:0.0216 \tValid Acc: 60.25 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0205\t Train Acc:66.70 %  | \tValid Loss:0.0218 \tValid Acc: 59.41 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0203\t Train Acc:68.38 %  | \tValid Loss:0.0215 \tValid Acc: 62.13 %\n",
      "\n",
      "Validation loss decreased (0.021544 --> 0.021482).  Saving model ...\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0197\t Train Acc:69.84 %  | \tValid Loss:0.0214 \tValid Acc: 57.53 %\n",
      "\n",
      "Validation loss decreased (0.021482 --> 0.021419).  Saving model ...\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0192\t Train Acc:72.15 %  | \tValid Loss:0.0207 \tValid Acc: 65.27 %\n",
      "\n",
      "Validation loss decreased (0.021419 --> 0.020734).  Saving model ...\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0185\t Train Acc:72.77 %  | \tValid Loss:0.0209 \tValid Acc: 63.18 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0182\t Train Acc:73.56 %  | \tValid Loss:0.0200 \tValid Acc: 66.95 %\n",
      "\n",
      "Validation loss decreased (0.020734 --> 0.019964).  Saving model ...\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0166\t Train Acc:76.65 %  | \tValid Loss:0.0205 \tValid Acc: 65.48 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0162\t Train Acc:77.33 %  | \tValid Loss:0.0202 \tValid Acc: 66.11 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0153\t Train Acc:80.99 %  | \tValid Loss:0.0211 \tValid Acc: 67.36 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0146\t Train Acc:81.36 %  | \tValid Loss:0.0202 \tValid Acc: 68.83 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:20]\t Train Loss:0.0138\t Train Acc:83.09 %  | \tValid Loss:0.0192 \tValid Acc: 68.20 %\n",
      "\n",
      "Validation loss decreased (0.019964 --> 0.019246).  Saving model ...\n",
      "\n",
      "[EPOCH:21]\t Train Loss:0.0128\t Train Acc:85.03 %  | \tValid Loss:0.0197 \tValid Acc: 70.71 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:22]\t Train Loss:0.0116\t Train Acc:86.60 %  | \tValid Loss:0.0188 \tValid Acc: 71.76 %\n",
      "\n",
      "Validation loss decreased (0.019246 --> 0.018787).  Saving model ...\n",
      "\n",
      "[EPOCH:23]\t Train Loss:0.0110\t Train Acc:89.27 %  | \tValid Loss:0.0193 \tValid Acc: 71.13 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:24]\t Train Loss:0.0109\t Train Acc:88.85 %  | \tValid Loss:0.0194 \tValid Acc: 71.76 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:25]\t Train Loss:0.0102\t Train Acc:89.06 %  | \tValid Loss:0.0199 \tValid Acc: 70.08 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:26]\t Train Loss:0.0087\t Train Acc:91.83 %  | \tValid Loss:0.0193 \tValid Acc: 72.59 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:27]\t Train Loss:0.0085\t Train Acc:92.15 %  | \tValid Loss:0.0210 \tValid Acc: 71.55 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[3 교차검증] Early stopping\n",
      "[4 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0247\t Train Acc:51.60 %  | \tValid Loss:0.0229 \tValid Acc: 54.51 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.022859).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0243\t Train Acc:51.91 %  | \tValid Loss:0.0221 \tValid Acc: 65.41 %\n",
      "\n",
      "Validation loss decreased (0.022859 --> 0.022084).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0232\t Train Acc:54.79 %  | \tValid Loss:0.0220 \tValid Acc: 65.20 %\n",
      "\n",
      "Validation loss decreased (0.022084 --> 0.022029).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0228\t Train Acc:57.09 %  | \tValid Loss:0.0216 \tValid Acc: 68.13 %\n",
      "\n",
      "Validation loss decreased (0.022029 --> 0.021644).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0228\t Train Acc:56.62 %  | \tValid Loss:0.0214 \tValid Acc: 67.30 %\n",
      "\n",
      "Validation loss decreased (0.021644 --> 0.021442).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0223\t Train Acc:57.82 %  | \tValid Loss:0.0207 \tValid Acc: 71.49 %\n",
      "\n",
      "Validation loss decreased (0.021442 --> 0.020660).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0217\t Train Acc:61.22 %  | \tValid Loss:0.0205 \tValid Acc: 68.55 %\n",
      "\n",
      "Validation loss decreased (0.020660 --> 0.020524).  Saving model ...\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0214\t Train Acc:60.28 %  | \tValid Loss:0.0205 \tValid Acc: 69.60 %\n",
      "\n",
      "Validation loss decreased (0.020524 --> 0.020471).  Saving model ...\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0208\t Train Acc:64.63 %  | \tValid Loss:0.0198 \tValid Acc: 70.86 %\n",
      "\n",
      "Validation loss decreased (0.020471 --> 0.019783).  Saving model ...\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0203\t Train Acc:65.52 %  | \tValid Loss:0.0196 \tValid Acc: 69.39 %\n",
      "\n",
      "Validation loss decreased (0.019783 --> 0.019641).  Saving model ...\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0199\t Train Acc:67.24 %  | \tValid Loss:0.0191 \tValid Acc: 71.28 %\n",
      "\n",
      "Validation loss decreased (0.019641 --> 0.019086).  Saving model ...\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0193\t Train Acc:68.55 %  | \tValid Loss:0.0186 \tValid Acc: 71.70 %\n",
      "\n",
      "Validation loss decreased (0.019086 --> 0.018559).  Saving model ...\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0187\t Train Acc:71.95 %  | \tValid Loss:0.0185 \tValid Acc: 71.28 %\n",
      "\n",
      "Validation loss decreased (0.018559 --> 0.018505).  Saving model ...\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0177\t Train Acc:73.63 %  | \tValid Loss:0.0180 \tValid Acc: 73.17 %\n",
      "\n",
      "Validation loss decreased (0.018505 --> 0.018019).  Saving model ...\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0179\t Train Acc:74.25 %  | \tValid Loss:0.0182 \tValid Acc: 72.12 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0167\t Train Acc:75.98 %  | \tValid Loss:0.0180 \tValid Acc: 74.21 %\n",
      "\n",
      "Validation loss decreased (0.018019 --> 0.017950).  Saving model ...\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0158\t Train Acc:78.96 %  | \tValid Loss:0.0180 \tValid Acc: 72.12 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0149\t Train Acc:80.32 %  | \tValid Loss:0.0161 \tValid Acc: 77.15 %\n",
      "\n",
      "Validation loss decreased (0.017950 --> 0.016056).  Saving model ...\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0140\t Train Acc:83.57 %  | \tValid Loss:0.0178 \tValid Acc: 72.54 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:20]\t Train Loss:0.0131\t Train Acc:85.40 %  | \tValid Loss:0.0144 \tValid Acc: 80.92 %\n",
      "\n",
      "Validation loss decreased (0.016056 --> 0.014431).  Saving model ...\n",
      "\n",
      "[EPOCH:21]\t Train Loss:0.0119\t Train Acc:86.97 %  | \tValid Loss:0.0139 \tValid Acc: 83.02 %\n",
      "\n",
      "Validation loss decreased (0.014431 --> 0.013919).  Saving model ...\n",
      "\n",
      "[EPOCH:22]\t Train Loss:0.0115\t Train Acc:87.86 %  | \tValid Loss:0.0143 \tValid Acc: 81.34 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:23]\t Train Loss:0.0107\t Train Acc:89.06 %  | \tValid Loss:0.0141 \tValid Acc: 80.92 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:24]\t Train Loss:0.0093\t Train Acc:91.26 %  | \tValid Loss:0.0138 \tValid Acc: 83.44 %\n",
      "\n",
      "Validation loss decreased (0.013919 --> 0.013799).  Saving model ...\n",
      "\n",
      "[EPOCH:25]\t Train Loss:0.0084\t Train Acc:92.52 %  | \tValid Loss:0.0113 \tValid Acc: 86.16 %\n",
      "\n",
      "Validation loss decreased (0.013799 --> 0.011277).  Saving model ...\n",
      "\n",
      "[EPOCH:26]\t Train Loss:0.0076\t Train Acc:93.14 %  | \tValid Loss:0.0174 \tValid Acc: 74.63 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:27]\t Train Loss:0.0080\t Train Acc:92.83 %  | \tValid Loss:0.0157 \tValid Acc: 77.99 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:28]\t Train Loss:0.0081\t Train Acc:92.36 %  | \tValid Loss:0.0160 \tValid Acc: 80.08 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:29]\t Train Loss:0.0071\t Train Acc:94.14 %  | \tValid Loss:0.0127 \tValid Acc: 84.28 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:30]\t Train Loss:0.0056\t Train Acc:95.66 %  | \tValid Loss:0.0159 \tValid Acc: 80.29 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[4 교차검증] Early stopping\n",
      "[5 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0255\t Train Acc:49.56 %  | \tValid Loss:0.0227 \tValid Acc: 61.22 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.022658).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0249\t Train Acc:51.96 %  | \tValid Loss:0.0220 \tValid Acc: 61.43 %\n",
      "\n",
      "Validation loss decreased (0.022658 --> 0.022007).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0241\t Train Acc:53.79 %  | \tValid Loss:0.0217 \tValid Acc: 64.15 %\n",
      "\n",
      "Validation loss decreased (0.022007 --> 0.021728).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0239\t Train Acc:54.79 %  | \tValid Loss:0.0218 \tValid Acc: 64.57 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0235\t Train Acc:54.84 %  | \tValid Loss:0.0210 \tValid Acc: 65.20 %\n",
      "\n",
      "Validation loss decreased (0.021728 --> 0.021026).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH:6]\t Train Loss:0.0236\t Train Acc:55.26 %  | \tValid Loss:0.0214 \tValid Acc: 60.38 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0230\t Train Acc:58.97 %  | \tValid Loss:0.0208 \tValid Acc: 64.57 %\n",
      "\n",
      "Validation loss decreased (0.021026 --> 0.020845).  Saving model ...\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0222\t Train Acc:60.54 %  | \tValid Loss:0.0207 \tValid Acc: 63.52 %\n",
      "\n",
      "Validation loss decreased (0.020845 --> 0.020748).  Saving model ...\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0227\t Train Acc:59.45 %  | \tValid Loss:0.0202 \tValid Acc: 66.04 %\n",
      "\n",
      "Validation loss decreased (0.020748 --> 0.020246).  Saving model ...\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0212\t Train Acc:63.63 %  | \tValid Loss:0.0199 \tValid Acc: 67.92 %\n",
      "\n",
      "Validation loss decreased (0.020246 --> 0.019873).  Saving model ...\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0216\t Train Acc:64.42 %  | \tValid Loss:0.0187 \tValid Acc: 72.12 %\n",
      "\n",
      "Validation loss decreased (0.019873 --> 0.018656).  Saving model ...\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0215\t Train Acc:64.94 %  | \tValid Loss:0.0184 \tValid Acc: 73.38 %\n",
      "\n",
      "Validation loss decreased (0.018656 --> 0.018353).  Saving model ...\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0203\t Train Acc:67.56 %  | \tValid Loss:0.0180 \tValid Acc: 75.05 %\n",
      "\n",
      "Validation loss decreased (0.018353 --> 0.018029).  Saving model ...\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0200\t Train Acc:66.51 %  | \tValid Loss:0.0184 \tValid Acc: 70.86 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0193\t Train Acc:70.02 %  | \tValid Loss:0.0185 \tValid Acc: 72.54 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0180\t Train Acc:73.78 %  | \tValid Loss:0.0174 \tValid Acc: 71.70 %\n",
      "\n",
      "Validation loss decreased (0.018029 --> 0.017439).  Saving model ...\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0177\t Train Acc:73.73 %  | \tValid Loss:0.0168 \tValid Acc: 79.25 %\n",
      "\n",
      "Validation loss decreased (0.017439 --> 0.016766).  Saving model ...\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0172\t Train Acc:76.24 %  | \tValid Loss:0.0173 \tValid Acc: 76.94 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0164\t Train Acc:77.66 %  | \tValid Loss:0.0171 \tValid Acc: 74.42 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:20]\t Train Loss:0.0149\t Train Acc:80.64 %  | \tValid Loss:0.0176 \tValid Acc: 79.04 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:21]\t Train Loss:0.0146\t Train Acc:82.10 %  | \tValid Loss:0.0153 \tValid Acc: 76.73 %\n",
      "\n",
      "Validation loss decreased (0.016766 --> 0.015263).  Saving model ...\n",
      "\n",
      "[EPOCH:22]\t Train Loss:0.0146\t Train Acc:81.27 %  | \tValid Loss:0.0146 \tValid Acc: 81.34 %\n",
      "\n",
      "Validation loss decreased (0.015263 --> 0.014647).  Saving model ...\n",
      "\n",
      "[EPOCH:23]\t Train Loss:0.0134\t Train Acc:84.09 %  | \tValid Loss:0.0156 \tValid Acc: 77.99 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:24]\t Train Loss:0.0119\t Train Acc:87.02 %  | \tValid Loss:0.0149 \tValid Acc: 79.66 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:25]\t Train Loss:0.0117\t Train Acc:87.28 %  | \tValid Loss:0.0142 \tValid Acc: 80.08 %\n",
      "\n",
      "Validation loss decreased (0.014647 --> 0.014216).  Saving model ...\n",
      "\n",
      "[EPOCH:26]\t Train Loss:0.0109\t Train Acc:89.17 %  | \tValid Loss:0.0168 \tValid Acc: 76.10 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:27]\t Train Loss:0.0103\t Train Acc:89.38 %  | \tValid Loss:0.0127 \tValid Acc: 82.60 %\n",
      "\n",
      "Validation loss decreased (0.014216 --> 0.012722).  Saving model ...\n",
      "\n",
      "[EPOCH:28]\t Train Loss:0.0086\t Train Acc:91.78 %  | \tValid Loss:0.0134 \tValid Acc: 84.28 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:29]\t Train Loss:0.0077\t Train Acc:93.72 %  | \tValid Loss:0.0121 \tValid Acc: 85.95 %\n",
      "\n",
      "Validation loss decreased (0.012722 --> 0.012099).  Saving model ...\n",
      "\n",
      "[EPOCH:30]\t Train Loss:0.0073\t Train Acc:94.09 %  | \tValid Loss:0.0142 \tValid Acc: 83.02 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:31]\t Train Loss:0.0069\t Train Acc:94.40 %  | \tValid Loss:0.0147 \tValid Acc: 80.50 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:32]\t Train Loss:0.0073\t Train Acc:93.41 %  | \tValid Loss:0.0148 \tValid Acc: 83.44 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:33]\t Train Loss:0.0061\t Train Acc:94.66 %  | \tValid Loss:0.0116 \tValid Acc: 86.37 %\n",
      "\n",
      "Validation loss decreased (0.012099 --> 0.011559).  Saving model ...\n",
      "\n",
      "[EPOCH:34]\t Train Loss:0.0063\t Train Acc:94.56 %  | \tValid Loss:0.0135 \tValid Acc: 84.07 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:35]\t Train Loss:0.0065\t Train Acc:94.03 %  | \tValid Loss:0.0158 \tValid Acc: 82.60 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:36]\t Train Loss:0.0068\t Train Acc:94.30 %  | \tValid Loss:0.0135 \tValid Acc: 85.74 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:37]\t Train Loss:0.0049\t Train Acc:96.28 %  | \tValid Loss:0.0122 \tValid Acc: 84.28 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:38]\t Train Loss:0.0052\t Train Acc:95.76 %  | \tValid Loss:0.0122 \tValid Acc: 86.16 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[5 교차검증] Early stopping\n"
     ]
    }
   ],
   "source": [
    "#10. 학습 및 평가.\n",
    "# resnet34 pretrained true\n",
    "# kfold 적용\n",
    "\n",
    "train_accs = []\n",
    "valid_accs = []\n",
    "\n",
    "for data_ind in range(1,6):\n",
    "\n",
    "    check_path = '../checkpoint/checkpoint_resnet18_true_'+str(data_ind)+'_a.pt'\n",
    "\n",
    "    early_stopping = EarlyStopping(patience = 5, verbose = True, path=check_path)\n",
    "    train_loader,validation_loader = load_data(data_ind-1)\n",
    "    \n",
    "    best_train_acc=0 # accuracy 기록용\n",
    "    best_valid_acc=0\n",
    "    \n",
    "    model=model_initialize()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "    \n",
    "    \n",
    "    print(\"[{} 교차검증] 학습 시작\\n ----- \".format(data_ind))\n",
    "    for Epoch in range(1,EPOCHS+1):\n",
    "        train_loss,train_accuracy=train(model,train_loader,optimizer,log_interval=31)\n",
    "        valid_loss,valid_accuracy = evaluate(model, validation_loader)\n",
    "\n",
    "\n",
    "        print(\"\\n[EPOCH:{}]\\t Train Loss:{:.4f}\\t Train Acc:{:.2f} %  | \\tValid Loss:{:.4f} \\tValid Acc: {:.2f} %\\n\".\n",
    "              format(Epoch,train_loss,train_accuracy,valid_loss,valid_accuracy))\n",
    "\n",
    "        early_stopping(valid_loss, model)\n",
    "        if -early_stopping.best_score == valid_loss:\n",
    "            best_train_acc, best_valid_acc = train_accuracy,valid_accuracy\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "                train_accs.append(best_train_acc)\n",
    "                valid_accs.append(best_valid_acc)\n",
    "                print(\"[{} 교차검증] Early stopping\".format(data_ind))\n",
    "                break\n",
    "\n",
    "        if Epoch==EPOCHS:\n",
    "            #만약 early stop 없이 40 epoch라서 중지 된 경우.\n",
    "            train_accs.append(best_train_acc)\n",
    "            valid_accs.append(best_valid_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6767ec8",
   "metadata": {},
   "source": [
    "# 모델 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6824ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 교차검증] train ACC : 85.3927 |\t valid ACC: 74.4770 \n",
      "[2 교차검증] train ACC : 93.5079 |\t valid ACC: 76.5690 \n",
      "[3 교차검증] train ACC : 86.5969 |\t valid ACC: 71.7573 \n",
      "[4 교차검증] train ACC : 92.5170 |\t valid ACC: 86.1635 \n",
      "[5 교차검증] train ACC : 94.6625 |\t valid ACC: 86.3732 \n",
      "평균 검증 정확도 79.0680069822724 %\n"
     ]
    }
   ],
   "source": [
    "sum_valid=0\n",
    "for data_ind in range(5):\n",
    "    print(\"[{} 교차검증] train ACC : {:.4f} |\\t valid ACC: {:.4f} \".format(data_ind+1,train_accs[data_ind],valid_accs[data_ind] ))\n",
    "    sum_valid+=valid_accs[data_ind]\n",
    "    \n",
    "print(\"평균 검증 정확도\",sum_valid/5,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0967cf",
   "metadata": {},
   "source": [
    "# Model Test\n",
    "\n",
    "- test set\n",
    "- confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a19235bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix 계산\n",
    "#test set 계산.\n",
    "def test_evaluate(model,test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    predictions = []\n",
    "    answers = []\n",
    "    #no_grad : 그래디언트 값 계산 막기.\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "            answers +=label\n",
    "            predictions +=prediction\n",
    "            \n",
    "        return predictions,answers,test_loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca2e1ed2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[187.  52.]\n",
      " [ 70. 169.]]\n",
      "[[357. 121.]\n",
      " [113. 365.]]\n",
      "[[538. 179.]\n",
      " [190. 527.]]\n",
      "[[751. 205.]\n",
      " [230. 725.]]\n",
      "[[927. 267.]\n",
      " [233. 961.]]\n",
      "Accuracy : 79.0620% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.7991\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.7764\n",
      "f score : 0.7876 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Confusion matrix (resnet18)\n",
    "# kfold의 confusion matrix는 계산 방법이 다르다.\n",
    "# 모델을 각각 불러와서 test set을 평가한다.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf = np.zeros((2,2))\n",
    "cf_list = []\n",
    "average_accuracy = 0\n",
    "\n",
    "for data_ind in range(1,6):\n",
    "\n",
    "    check_path = './checkpoint/checkpoint_resnet18_true_'+str(data_ind)+'_a.pt'\n",
    "    model.load_state_dict(torch.load(check_path))\n",
    "\n",
    "    predictions,answers,test_loss = test_evaluate(model, test_loader)\n",
    "    predictions=[ dat.cpu().numpy() for dat in predictions]\n",
    "    answers=[ dat.cpu().numpy() for dat in answers]\n",
    "\n",
    "    \n",
    "    cf = confusion_matrix(answers, predictions)\n",
    "    cf_list.append(cf)\n",
    "    \n",
    "    acc = (cf[0,0]+cf[1,1])/(cf[0,0]+cf[0,1]+cf[1,0]+cf[1,1])\n",
    "    average_accuracy+=acc\n",
    "    precision=cf[0,0]/(cf[0,0]+cf[1,0])\n",
    "    recall=cf[0,0]/(cf[0,0]+cf[0,1])\n",
    "    fscore=2*precision*recall/(precision+recall)\n",
    "    print('{}번 모델'.format(data_ind))\n",
    "    print(\"Accuracy : {:.4f}% \".format(acc*100))\n",
    "    print(\"Precision (pathology 예측한 것중 맞는 것) : {:.4f}\".format(precision))\n",
    "    print(\"recall (실제 pathology 중  예측이 맞는 것) : {:.4f}\".format(recall))\n",
    "    print(\"f score : {:.4f} \".format(fscore))\n",
    "    print(cf)\n",
    "    print(\"-----\")\n",
    "\n",
    "print(\"평균 acc : {:.4f}\".format(average_accuracy/5))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "455.111px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
