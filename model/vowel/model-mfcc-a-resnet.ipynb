{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37664ece",
   "metadata": {},
   "source": [
    "- http://keunwoochoi.blogspot.com/2016/03/2.html\n",
    "- http://www.rex-ai.info/docs/AI_Example_CNN_speech_recognize\n",
    "- https://www.youtube.com/watch?v=oltGIc4uo5c\n",
    "- https://youdaeng-com.tistory.com/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "275b8092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pytorch version :  1.10.0  Device :  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn # 인공 신경망 모델들 모아놓은 모듈\n",
    "import torch.nn.functional as F #그중 자주 쓰이는것들을 F로\n",
    "from torchvision import transforms, datasets\n",
    "import cv2\n",
    "from torchvision import transforms, datasets\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "p = os.path.abspath('..') # 상위 폴더를 사용하기 위해서.\n",
    "sys.path.insert(1, p)\n",
    "from pytorchtools.pytorchtools import EarlyStopping # 현재 폴더에 추가된 모듈.\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "#DEVICE = torch.device('cpu')\n",
    "print('Using Pytorch version : ',torch.__version__,' Device : ',DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ebea6",
   "metadata": {},
   "source": [
    "# SVD 문장 데이터에서 Feature 추출\n",
    "- mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "114a1b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa, librosa.display \n",
    "import matplotlib.pyplot as plt\n",
    "#window sizde : FFT를 할때 참조할 그래프 길이 ( 프레임 하나당 sample 수 )\n",
    "#자연어 처리에서는 25ms 사용. https://ahnjg.tistory.com/93\n",
    "#초당 50000hz 중 1250개씩 윈도우 사이즈로 사용.\n",
    "sr=50000\n",
    "win_length =  np.int64(50000/40) # 1250\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c72d82e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pathology data 수 :  1194\n",
      "healthy data 수 :  687\n",
      "가장 긴 path sample : 131655\n",
      "가장 긴 healthy sample : 219501\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa, librosa.display \n",
    "import matplotlib.pyplot as plt\n",
    "#window sizde : FFT를 할때 참조할 그래프 길이 ( 프레임 하나당 sample 수 )\n",
    "#자연어 처리에서는 25ms 사용. https://ahnjg.tistory.com/93\n",
    "#초당 50000hz 중 1250개씩 윈도우 사이즈로 사용.\n",
    "sr=50000\n",
    "win_length =  np.int64(50000/40) # 1250\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다.\n",
    "\n",
    "pathology_sig=[]\n",
    "healthy_sig=[]\n",
    "\n",
    "pathology=[]\n",
    "healthy=[]\n",
    "\n",
    "\n",
    "#PATHOLOGY DATA\n",
    "for audio_path in os.listdir('../../voice_data/pathology_new/a/export'):\n",
    "    sig, sr = librosa.load('../../voice_data/pathology_new/a/export/'+audio_path, sr=50000)# 논문에서 f_s = 50 000HZ\n",
    "    pathology_sig.append(sig)\n",
    "    MFCCs = librosa.feature.mfcc(sig, sr, win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "    pathology.append(MFCCs)\n",
    "    \n",
    "\n",
    "#Healthy data\n",
    "for audio_path in os.listdir('../../voice_data/healthy_new/a/export'):\n",
    "    sig, sr = librosa.load('../../voice_data/healthy_new/a/export/'+audio_path, sr=50000)# 논문에서 f_s = 50 000HZ\n",
    "    healthy_sig.append(sig)\n",
    "    MFCCs = librosa.feature.mfcc(sig, sr, win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "    healthy.append(MFCCs)\n",
    "    \n",
    "print(\"pathology data 수 : \",len(pathology))\n",
    "print(\"healthy data 수 : \",len(healthy))\n",
    "\n",
    "\n",
    "path_max=max([ len(samples) for samples in pathology_sig])\n",
    "healthy_max=max([ len(samples) for samples in healthy_sig])\n",
    "print(\"가장 긴 path sample :\" ,path_max)\n",
    "print(\"가장 긴 healthy sample :\" ,healthy_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "636bede8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6331 초\n",
      "4.39002 초\n"
     ]
    }
   ],
   "source": [
    "print(path_max/sr,\"초\")\n",
    "print(healthy_max/sr,\"초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5915f64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 :  1.2573740201005026\n",
      "평균 :  1.314699767103348\n"
     ]
    }
   ],
   "source": [
    "print('평균 : ',np.mean([ len(samples) for samples in pathology_sig])/sr)\n",
    "print('평균 : ',np.mean([ len(samples) for samples in healthy_sig])/sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91bd1989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.504"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "400*313/sr\n",
    "#400 frame은 약 2.5초 이상."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148ec668",
   "metadata": {},
   "source": [
    "# 결과 확인\n",
    "- 1 row당 1 frame으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a48f3297",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>mfcc5</th>\n",
       "      <th>mfcc6</th>\n",
       "      <th>mfcc7</th>\n",
       "      <th>mfcc8</th>\n",
       "      <th>mfcc9</th>\n",
       "      <th>mfcc10</th>\n",
       "      <th>mfcc11</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-214.176651</td>\n",
       "      <td>207.977264</td>\n",
       "      <td>1.462625</td>\n",
       "      <td>13.944162</td>\n",
       "      <td>-63.319916</td>\n",
       "      <td>-2.144712</td>\n",
       "      <td>-16.828245</td>\n",
       "      <td>-21.429878</td>\n",
       "      <td>7.964348</td>\n",
       "      <td>-0.085761</td>\n",
       "      <td>-1.125562</td>\n",
       "      <td>-21.268238</td>\n",
       "      <td>-16.084270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-222.949982</td>\n",
       "      <td>209.148163</td>\n",
       "      <td>2.133819</td>\n",
       "      <td>17.240515</td>\n",
       "      <td>-52.081551</td>\n",
       "      <td>2.385664</td>\n",
       "      <td>-18.650604</td>\n",
       "      <td>-24.606426</td>\n",
       "      <td>3.663574</td>\n",
       "      <td>-1.903811</td>\n",
       "      <td>-8.280209</td>\n",
       "      <td>-16.000689</td>\n",
       "      <td>-12.138484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-248.733551</td>\n",
       "      <td>195.559235</td>\n",
       "      <td>-2.844307</td>\n",
       "      <td>7.977224</td>\n",
       "      <td>-52.356590</td>\n",
       "      <td>-1.202414</td>\n",
       "      <td>-16.476841</td>\n",
       "      <td>-20.510300</td>\n",
       "      <td>5.527544</td>\n",
       "      <td>-0.318386</td>\n",
       "      <td>-15.725111</td>\n",
       "      <td>-8.803049</td>\n",
       "      <td>-4.176742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-246.802917</td>\n",
       "      <td>198.915344</td>\n",
       "      <td>-3.477466</td>\n",
       "      <td>8.681169</td>\n",
       "      <td>-53.547142</td>\n",
       "      <td>-5.144975</td>\n",
       "      <td>-17.089766</td>\n",
       "      <td>-22.173811</td>\n",
       "      <td>4.114779</td>\n",
       "      <td>-1.155015</td>\n",
       "      <td>-14.204550</td>\n",
       "      <td>-9.640966</td>\n",
       "      <td>-2.181946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-245.827591</td>\n",
       "      <td>200.687988</td>\n",
       "      <td>0.568132</td>\n",
       "      <td>6.174569</td>\n",
       "      <td>-51.041344</td>\n",
       "      <td>-1.792537</td>\n",
       "      <td>-17.918312</td>\n",
       "      <td>-18.034185</td>\n",
       "      <td>5.677939</td>\n",
       "      <td>-2.018642</td>\n",
       "      <td>-12.768702</td>\n",
       "      <td>-11.336535</td>\n",
       "      <td>-1.299195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>-242.007767</td>\n",
       "      <td>200.297760</td>\n",
       "      <td>3.961174</td>\n",
       "      <td>14.153851</td>\n",
       "      <td>-52.725536</td>\n",
       "      <td>7.545429</td>\n",
       "      <td>-5.822221</td>\n",
       "      <td>-22.547153</td>\n",
       "      <td>6.216630</td>\n",
       "      <td>7.461223</td>\n",
       "      <td>-12.434643</td>\n",
       "      <td>-15.016934</td>\n",
       "      <td>12.251122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>-245.131500</td>\n",
       "      <td>196.616119</td>\n",
       "      <td>2.222031</td>\n",
       "      <td>15.436684</td>\n",
       "      <td>-56.961128</td>\n",
       "      <td>6.723224</td>\n",
       "      <td>-5.488671</td>\n",
       "      <td>-19.845875</td>\n",
       "      <td>7.457106</td>\n",
       "      <td>2.931230</td>\n",
       "      <td>-13.481985</td>\n",
       "      <td>-15.816978</td>\n",
       "      <td>13.508206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>-247.851624</td>\n",
       "      <td>198.925278</td>\n",
       "      <td>2.341530</td>\n",
       "      <td>14.167100</td>\n",
       "      <td>-54.980747</td>\n",
       "      <td>11.598038</td>\n",
       "      <td>-2.436407</td>\n",
       "      <td>-18.352262</td>\n",
       "      <td>8.678156</td>\n",
       "      <td>8.914279</td>\n",
       "      <td>-9.958929</td>\n",
       "      <td>-16.050816</td>\n",
       "      <td>15.700717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>-232.978348</td>\n",
       "      <td>215.946442</td>\n",
       "      <td>14.133223</td>\n",
       "      <td>16.482494</td>\n",
       "      <td>-50.424297</td>\n",
       "      <td>13.806274</td>\n",
       "      <td>-4.241011</td>\n",
       "      <td>-16.475407</td>\n",
       "      <td>5.775840</td>\n",
       "      <td>7.153922</td>\n",
       "      <td>-11.623649</td>\n",
       "      <td>-19.136692</td>\n",
       "      <td>15.453394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>-218.726624</td>\n",
       "      <td>225.969635</td>\n",
       "      <td>17.963581</td>\n",
       "      <td>17.724133</td>\n",
       "      <td>-46.865860</td>\n",
       "      <td>8.419164</td>\n",
       "      <td>-2.978050</td>\n",
       "      <td>-13.858909</td>\n",
       "      <td>9.973724</td>\n",
       "      <td>11.311474</td>\n",
       "      <td>-11.353134</td>\n",
       "      <td>-16.323940</td>\n",
       "      <td>12.591789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mfcc1       mfcc2      mfcc3      mfcc4      mfcc5      mfcc6  \\\n",
       "0   -214.176651  207.977264   1.462625  13.944162 -63.319916  -2.144712   \n",
       "1   -222.949982  209.148163   2.133819  17.240515 -52.081551   2.385664   \n",
       "2   -248.733551  195.559235  -2.844307   7.977224 -52.356590  -1.202414   \n",
       "3   -246.802917  198.915344  -3.477466   8.681169 -53.547142  -5.144975   \n",
       "4   -245.827591  200.687988   0.568132   6.174569 -51.041344  -1.792537   \n",
       "..          ...         ...        ...        ...        ...        ...   \n",
       "333 -242.007767  200.297760   3.961174  14.153851 -52.725536   7.545429   \n",
       "334 -245.131500  196.616119   2.222031  15.436684 -56.961128   6.723224   \n",
       "335 -247.851624  198.925278   2.341530  14.167100 -54.980747  11.598038   \n",
       "336 -232.978348  215.946442  14.133223  16.482494 -50.424297  13.806274   \n",
       "337 -218.726624  225.969635  17.963581  17.724133 -46.865860   8.419164   \n",
       "\n",
       "         mfcc7      mfcc8     mfcc9     mfcc10     mfcc11     mfcc12  \\\n",
       "0   -16.828245 -21.429878  7.964348  -0.085761  -1.125562 -21.268238   \n",
       "1   -18.650604 -24.606426  3.663574  -1.903811  -8.280209 -16.000689   \n",
       "2   -16.476841 -20.510300  5.527544  -0.318386 -15.725111  -8.803049   \n",
       "3   -17.089766 -22.173811  4.114779  -1.155015 -14.204550  -9.640966   \n",
       "4   -17.918312 -18.034185  5.677939  -2.018642 -12.768702 -11.336535   \n",
       "..         ...        ...       ...        ...        ...        ...   \n",
       "333  -5.822221 -22.547153  6.216630   7.461223 -12.434643 -15.016934   \n",
       "334  -5.488671 -19.845875  7.457106   2.931230 -13.481985 -15.816978   \n",
       "335  -2.436407 -18.352262  8.678156   8.914279  -9.958929 -16.050816   \n",
       "336  -4.241011 -16.475407  5.775840   7.153922 -11.623649 -19.136692   \n",
       "337  -2.978050 -13.858909  9.973724  11.311474 -11.353134 -16.323940   \n",
       "\n",
       "        mfcc13  \n",
       "0   -16.084270  \n",
       "1   -12.138484  \n",
       "2    -4.176742  \n",
       "3    -2.181946  \n",
       "4    -1.299195  \n",
       "..         ...  \n",
       "333  12.251122  \n",
       "334  13.508206  \n",
       "335  15.700717  \n",
       "336  15.453394  \n",
       "337  12.591789  \n",
       "\n",
       "[338 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(healthy[0][2]) #1번 : 파일. 2번:mfcc\n",
    "headers = \"mfcc1 mfcc2 mfcc3 mfcc4 mfcc5 mfcc6 mfcc7 mfcc8 mfcc9 mfcc10 mfcc11 mfcc12 mfcc13\".split()\n",
    "pd.DataFrame(healthy[1].T,columns=headers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "186be135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthy[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73d328bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "del pathology\n",
    "del healthy\n",
    "del pathology_sig\n",
    "del healthy_sig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23a4c15",
   "metadata": {},
   "source": [
    "# 데이터 나누기 - Stratified KFold\n",
    "\n",
    "- pathology : 1194 / healthy : 687 / 총 1881\n",
    "- k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfb1c84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pathology :  1194\n",
      "Healthy:  687\n",
      "총 데이터수 :  1881\n",
      "교차 검증 : 1\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 549, 'pathology': 955}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 138, 'pathology': 239} \n",
      "\n",
      "교차 검증 : 2\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 550, 'pathology': 955}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 137, 'pathology': 239} \n",
      "\n",
      "교차 검증 : 3\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 550, 'pathology': 955}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 137, 'pathology': 239} \n",
      "\n",
      "교차 검증 : 4\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 550, 'pathology': 955}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 137, 'pathology': 239} \n",
      "\n",
      "교차 검증 : 5\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 549, 'pathology': 956}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 138, 'pathology': 238} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. train, test 나누기\n",
    "\n",
    "import os\n",
    "import random #데이터 shuffle 사용\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from collections import Counter\n",
    "\n",
    "pathology = glob('../../voice_data/pathology_new/a/export/*.wav')\n",
    "healthy = glob('../../voice_data/healthy_new/a/export/*.wav')\n",
    "print(\"Pathology : \",len(pathology))\n",
    "print(\"Healthy: \",len(healthy))\n",
    "\n",
    "X = pathology+healthy # path 데이터 합\n",
    "print(\"총 데이터수 : \",len(X))\n",
    "Y = [] # 라벨\n",
    "for idx,x in enumerate(X):\n",
    "    if idx<1194:\n",
    "        Y.append(\"pathology\")\n",
    "    else:\n",
    "        Y.append(\"healthy\")\n",
    "\n",
    "skf_iris = StratifiedKFold(n_splits=5)\n",
    "cnt_iter = 0\n",
    "\n",
    "X_train_list = [] #데이터 셋 보관\n",
    "Y_train_list = []\n",
    "\n",
    "X_test_list = []\n",
    "Y_test_list = []\n",
    "\n",
    "for train_idx, test_idx in skf_iris.split(X,Y):\n",
    "    \n",
    "    #split으로 반환된 인덱스를 이용하여, 학습 검증용 테스트 데이터 추출\n",
    "    cnt_iter += 1\n",
    "    X_train, X_test = [X[idx] for idx in train_idx.tolist() ], [X[idx] for idx in test_idx.tolist() ]\n",
    "    Y_train, Y_test = [Y[idx] for idx in train_idx.tolist() ], [Y[idx] for idx in test_idx.tolist() ]\n",
    "    \n",
    "    X_train_list.append(X_train)\n",
    "    X_test_list.append(X_test)\n",
    "    \n",
    "    Y_test_list.append(Y_test)\n",
    "    Y_train_list.append(Y_train)\n",
    "    \n",
    "    #학습 및 예측\n",
    "    \n",
    "    label_train = Y_train\n",
    "    label_test = Y_test\n",
    "    unique_train, train_counts = np.unique(label_train, return_counts = True)\n",
    "    unique_test, test_counts = np.unique(label_test, return_counts = True)\n",
    "    \n",
    "    uniq_cnt_train = dict(zip(unique_train, train_counts))\n",
    "    uniq_cnt_test = dict(zip(unique_test, test_counts))\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('교차 검증 : {}'.format(cnt_iter))\n",
    "    print('학습 레이블 데이터 분포 : \\n', uniq_cnt_train)\n",
    "    print('검증 레이블 데이터 분포 : \\n', uniq_cnt_test,'\\n')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a663f0",
   "metadata": {},
   "source": [
    "# 데이터 정의\n",
    "- 추가적으로 데이터의 크기를 맞춰주기 위해 3초로 padding 및 truncate 실시 https://sequencedata.tistory.com/25 FixAudioLength\n",
    "- 논문에서는 400frame으로 설정.\n",
    "- 전처리 방법 결정.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2febf8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "classes = [\"pathology\",\"healthy\"]\n",
    "sr=50000\n",
    "win_length =  np.int64(50000/40) # 1250\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다.\n",
    "\n",
    "class svd_dataset(Dataset):\n",
    "    def __init__(self,data_path_list,classes,data_num,training,transform=None):\n",
    "        #클래스에서 사용할 인자를 받아 인스턴스 변수로 저장하는 일을 한다.\n",
    "        #예를들면, 이미지의 경로 리스트를 저장하는 일을 하게 된다.\n",
    "        \n",
    "        #data_num : k 개 데이터 셋 중 어떤것을 쓸지\n",
    "        #test인지 아닌지.\n",
    "        \n",
    "        self.path_list = data_path_list[data_num]\n",
    "        self.data_num = data_num\n",
    "        self.training = training\n",
    "        self.label = svd_dataset.get_label(self.path_list,training,data_num)\n",
    "        self.classes=classes\n",
    "        self.transform=transform\n",
    "        \n",
    "    \n",
    "    @classmethod\n",
    "    def get_label(cls,data_path_list,training,data_num):\n",
    "        label_list=[]\n",
    "        \n",
    "        if training:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_train_list[data_num][idx])\n",
    "        else:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_test_list[data_num][idx])\n",
    "        #print(label_list)\n",
    "        return label_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "        #데이터 셋의 길이를 정수로 반환한다. \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        1. path를 받아서, 소리에서 mfcc를 추출\n",
    "        2. mfcc를 500프레임으로 패딩.\n",
    "        3. resnet에 사용되기 위해 3채널로 복사(rgb 처럼)\n",
    "        4. 0~1 정규화\n",
    "        \n",
    "        \"\"\"\n",
    "        sig, sr = librosa.load(self.path_list[idx], sr=50000)# 논문에서 f_s = 50 000HZ\n",
    "        \n",
    "        MFCCs = librosa.feature.mfcc(sig, sr, win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "        #mfcc 400 FRAME이 되도록 패딩.\n",
    "        length = 400\n",
    "        pad2d = lambda a, i: a[:, 0:i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0], i-a.shape[1]))))\n",
    "        MFCCs = pad2d(MFCCs, length)\n",
    "        MFCCs= MFCCs.T\n",
    "        \n",
    "        if self.transform:\n",
    "            #print('transform')\n",
    "            MFCCs=self.transform(MFCCs).type(torch.float32)# 데이터 0~1 정규화\n",
    "            MFCCs=torch.stack([MFCCs,MFCCs,MFCCs])# 3채널로 복사.\n",
    "            MFCCs = MFCCs.squeeze(dim=1)\n",
    "        else:\n",
    "            #print(\"else\")\n",
    "            MFCCs = torch.from_numpy(MFCCs).type(torch.float32)\n",
    "            MFCCs=MFCCs.unsqueeze(0) #cnn 사용위해서 추가\n",
    "            #MFCCs = MFCCs.permute(2, 0, 1)\n",
    "        return MFCCs, self.classes.index(self.label[idx])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d05129d",
   "metadata": {},
   "source": [
    "# 데이터 로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89052fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. 하이퍼 파라미터\n",
    "BATCH_SIZE =  30 #한 배치당 30개 음성데이터 # 32 배수시에, 1개만 남는 경우가 발생해서.\n",
    "EPOCHS = 40 # 전체 데이터 셋을 40번 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bba97b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA LOADER 함수가 BATCH_size 단위로 분리해 지정.\n",
    "\n",
    "#확인을 위해 데이터셋 하나만 확인\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                           svd_dataset(\n",
    "                                               X_train_list,\n",
    "                                               classes,\n",
    "                                               transform = transforms.ToTensor(),#이걸 composed로 고쳐서 전처리 하도록 수정.\n",
    "                                               data_num=0,\n",
    "                                               training=True\n",
    "                                           ),\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True,\n",
    "                                           ) # 순서가 암기되는것을 막기위해.\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                           svd_dataset(\n",
    "                                               X_test_list,\n",
    "                                               classes,\n",
    "                                               transform = transforms.ToTensor(),\n",
    "                                               data_num=0,\n",
    "                                               training=False\n",
    "                                           ),\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True,) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b15a86",
   "metadata": {},
   "source": [
    "# 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f866237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :  torch.Size([30, 3, 400, 13]) type: torch.FloatTensor\n",
      "Y_train :  torch.Size([30]) type: torch.LongTensor\n",
      "tensor(1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x1fedbd2b1f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. 데이터 확인하기\n",
    "for (X_train,Y_train) in train_loader:\n",
    "    print(\"X_train : \",X_train.size(),'type:',X_train.type())\n",
    "    print(\"Y_train : \",Y_train.size(),'type:',Y_train.type())\n",
    "    break\n",
    "    \n",
    "print(Y_train[0])\n",
    "librosa.display.specshow(X_train[0][0].numpy().T, sr=50000, x_axis='time')\n",
    "#batch: 32 / frame수: 400  /  feature수: 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a45b51bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valid :  torch.Size([30, 3, 400, 13]) type: torch.FloatTensor\n",
      "Y_valid :  torch.Size([30]) type: torch.LongTensor\n",
      "tensor(0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x1b47d62d820>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#valiation set 확인\n",
    "for (X_valid,Y_valid) in validation_loader:\n",
    "    print(\"X_valid : \",X_valid.size(),'type:',X_valid.type())\n",
    "    print(\"Y_valid : \",Y_valid.size(),'type:',Y_valid.type())\n",
    "    break\n",
    "\n",
    "print(Y_valid[0])\n",
    "librosa.display.specshow(X_valid[0][0].numpy().T, sr=50000, x_axis='time')\n",
    "#batch: 32 / 3채널 / frame수: 400  /  feature수: 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec40ea4",
   "metadata": {},
   "source": [
    "# RESNET18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e1d59a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 \n",
    "# pretrained\n",
    "\n",
    "\n",
    "def model_initialize():\n",
    "    model = models.resnet18(pretrained=True).cuda()\n",
    "    model.ftrs = model.fc.in_features # in_features : fully connected의 입력수.\n",
    "    num_ftrs = model.fc.in_features\n",
    "\n",
    "    model.fc = nn.Sequential(nn.Linear(num_ftrs, 256),\n",
    "                             nn.BatchNorm1d(256),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(256,128),\n",
    "                             nn.BatchNorm1d(128),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(128,64),\n",
    "                             nn.BatchNorm1d(64),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(64,50),\n",
    "                             nn.BatchNorm1d(50),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(50,2)\n",
    "                            )\n",
    "\n",
    "    model = model.cuda()\n",
    "    return model\n",
    "model=model_initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c26ff30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.5, inplace=False)\n",
      "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.5, inplace=False)\n",
      "    (12): Linear(in_features=64, out_features=50, bias=True)\n",
      "    (13): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU()\n",
      "    (15): Dropout(p=0.5, inplace=False)\n",
      "    (16): Linear(in_features=50, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6097d312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 200, 7]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 200, 7]             128\n",
      "              ReLU-3           [-1, 64, 200, 7]               0\n",
      "         MaxPool2d-4           [-1, 64, 100, 4]               0\n",
      "            Conv2d-5           [-1, 64, 100, 4]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 100, 4]             128\n",
      "              ReLU-7           [-1, 64, 100, 4]               0\n",
      "            Conv2d-8           [-1, 64, 100, 4]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 100, 4]             128\n",
      "             ReLU-10           [-1, 64, 100, 4]               0\n",
      "       BasicBlock-11           [-1, 64, 100, 4]               0\n",
      "           Conv2d-12           [-1, 64, 100, 4]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 100, 4]             128\n",
      "             ReLU-14           [-1, 64, 100, 4]               0\n",
      "           Conv2d-15           [-1, 64, 100, 4]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 100, 4]             128\n",
      "             ReLU-17           [-1, 64, 100, 4]               0\n",
      "       BasicBlock-18           [-1, 64, 100, 4]               0\n",
      "           Conv2d-19           [-1, 128, 50, 2]          73,728\n",
      "      BatchNorm2d-20           [-1, 128, 50, 2]             256\n",
      "             ReLU-21           [-1, 128, 50, 2]               0\n",
      "           Conv2d-22           [-1, 128, 50, 2]         147,456\n",
      "      BatchNorm2d-23           [-1, 128, 50, 2]             256\n",
      "           Conv2d-24           [-1, 128, 50, 2]           8,192\n",
      "      BatchNorm2d-25           [-1, 128, 50, 2]             256\n",
      "             ReLU-26           [-1, 128, 50, 2]               0\n",
      "       BasicBlock-27           [-1, 128, 50, 2]               0\n",
      "           Conv2d-28           [-1, 128, 50, 2]         147,456\n",
      "      BatchNorm2d-29           [-1, 128, 50, 2]             256\n",
      "             ReLU-30           [-1, 128, 50, 2]               0\n",
      "           Conv2d-31           [-1, 128, 50, 2]         147,456\n",
      "      BatchNorm2d-32           [-1, 128, 50, 2]             256\n",
      "             ReLU-33           [-1, 128, 50, 2]               0\n",
      "       BasicBlock-34           [-1, 128, 50, 2]               0\n",
      "           Conv2d-35           [-1, 256, 25, 1]         294,912\n",
      "      BatchNorm2d-36           [-1, 256, 25, 1]             512\n",
      "             ReLU-37           [-1, 256, 25, 1]               0\n",
      "           Conv2d-38           [-1, 256, 25, 1]         589,824\n",
      "      BatchNorm2d-39           [-1, 256, 25, 1]             512\n",
      "           Conv2d-40           [-1, 256, 25, 1]          32,768\n",
      "      BatchNorm2d-41           [-1, 256, 25, 1]             512\n",
      "             ReLU-42           [-1, 256, 25, 1]               0\n",
      "       BasicBlock-43           [-1, 256, 25, 1]               0\n",
      "           Conv2d-44           [-1, 256, 25, 1]         589,824\n",
      "      BatchNorm2d-45           [-1, 256, 25, 1]             512\n",
      "             ReLU-46           [-1, 256, 25, 1]               0\n",
      "           Conv2d-47           [-1, 256, 25, 1]         589,824\n",
      "      BatchNorm2d-48           [-1, 256, 25, 1]             512\n",
      "             ReLU-49           [-1, 256, 25, 1]               0\n",
      "       BasicBlock-50           [-1, 256, 25, 1]               0\n",
      "           Conv2d-51           [-1, 512, 13, 1]       1,179,648\n",
      "      BatchNorm2d-52           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-53           [-1, 512, 13, 1]               0\n",
      "           Conv2d-54           [-1, 512, 13, 1]       2,359,296\n",
      "      BatchNorm2d-55           [-1, 512, 13, 1]           1,024\n",
      "           Conv2d-56           [-1, 512, 13, 1]         131,072\n",
      "      BatchNorm2d-57           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-58           [-1, 512, 13, 1]               0\n",
      "       BasicBlock-59           [-1, 512, 13, 1]               0\n",
      "           Conv2d-60           [-1, 512, 13, 1]       2,359,296\n",
      "      BatchNorm2d-61           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-62           [-1, 512, 13, 1]               0\n",
      "           Conv2d-63           [-1, 512, 13, 1]       2,359,296\n",
      "      BatchNorm2d-64           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-65           [-1, 512, 13, 1]               0\n",
      "       BasicBlock-66           [-1, 512, 13, 1]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                  [-1, 256]         131,328\n",
      "      BatchNorm1d-69                  [-1, 256]             512\n",
      "             ReLU-70                  [-1, 256]               0\n",
      "          Dropout-71                  [-1, 256]               0\n",
      "           Linear-72                  [-1, 128]          32,896\n",
      "      BatchNorm1d-73                  [-1, 128]             256\n",
      "             ReLU-74                  [-1, 128]               0\n",
      "          Dropout-75                  [-1, 128]               0\n",
      "           Linear-76                   [-1, 64]           8,256\n",
      "      BatchNorm1d-77                   [-1, 64]             128\n",
      "             ReLU-78                   [-1, 64]               0\n",
      "          Dropout-79                   [-1, 64]               0\n",
      "           Linear-80                   [-1, 50]           3,250\n",
      "      BatchNorm1d-81                   [-1, 50]             100\n",
      "             ReLU-82                   [-1, 50]               0\n",
      "          Dropout-83                   [-1, 50]               0\n",
      "           Linear-84                    [-1, 2]             102\n",
      "================================================================\n",
      "Total params: 11,353,340\n",
      "Trainable params: 11,353,340\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 8.16\n",
      "Params size (MB): 43.31\n",
      "Estimated Total Size (MB): 51.52\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# get the model summary\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 400, 13), device=DEVICE.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f2ca15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. 학습\n",
    "def train(model,train_loader,optimizer, log_interval):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    train_loss = 0\n",
    "    for batch_idx,(image,label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        #데이터들 장비에 할당\n",
    "        optimizer.zero_grad() # device 에 저장된 gradient 제거\n",
    "        output = model(image) # model로 output을 계산\n",
    "        loss = criterion(output, label) #loss 계산\n",
    "        train_loss += loss.item()\n",
    "        prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "        correct += prediction.eq(label.view_as(prediction)).sum().item()# 아웃풋이 배치 사이즈 32개라서.\n",
    "        loss.backward() # loss 값을 이용해 gradient를 계산\n",
    "        optimizer.step() # Gradient 값을 이용해 파라미터 업데이트.\n",
    "    train_loss/=len(train_loader.dataset)\n",
    "    train_accuracy = 100. * correct / len(train_loader.dataset)\n",
    "    return train_loss,train_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b09341bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. 학습 진행하며, validation 데이터로 모델 성능확인\n",
    "def evaluate(model,valid_loader):\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    #no_grad : 그래디언트 값 계산 막기.\n",
    "    with torch.no_grad():\n",
    "        for image, label in valid_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            valid_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()# 아웃풋이 배치 사이즈 32개라서.\n",
    "            #true.false값을 sum해줌. item\n",
    "        valid_loss /= len(valid_loader.dataset)\n",
    "        valid_accuracy = 100. * correct / len(valid_loader.dataset)\n",
    "        return valid_loss,valid_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae179080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 로더 제작 함수\n",
    "\n",
    "def load_data(data_ind):\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_dataset(\n",
    "                                                   X_train_list,\n",
    "                                                   classes,\n",
    "                                                   transform = transforms.ToTensor(),#이걸 composed로 고쳐서 전처리 하도록 수정.\n",
    "                                                   data_num=data_ind,\n",
    "                                                   training=True\n",
    "                                               ),\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = True,\n",
    "                                               ) # 순서가 암기되는것을 막기위해.\n",
    "\n",
    "    validation_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_dataset(\n",
    "                                                   X_test_list,\n",
    "                                                   classes,\n",
    "                                                   transform = transforms.ToTensor(),\n",
    "                                                   data_num=data_ind,\n",
    "                                                   training=False\n",
    "                                               ),\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = True,) \n",
    "    return train_loader,validation_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c85d7e27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0240\t Train Acc:57.38 %  | \tValid Loss:0.0230 \tValid Acc: 62.60 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.023013).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0237\t Train Acc:56.91 %  | \tValid Loss:0.0228 \tValid Acc: 63.40 %\n",
      "\n",
      "Validation loss decreased (0.023013 --> 0.022794).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0237\t Train Acc:57.91 %  | \tValid Loss:0.0227 \tValid Acc: 63.66 %\n",
      "\n",
      "Validation loss decreased (0.022794 --> 0.022656).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0234\t Train Acc:57.98 %  | \tValid Loss:0.0227 \tValid Acc: 64.46 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0231\t Train Acc:59.24 %  | \tValid Loss:0.0225 \tValid Acc: 62.86 %\n",
      "\n",
      "Validation loss decreased (0.022656 --> 0.022469).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0232\t Train Acc:59.71 %  | \tValid Loss:0.0227 \tValid Acc: 64.19 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0222\t Train Acc:60.97 %  | \tValid Loss:0.0218 \tValid Acc: 62.86 %\n",
      "\n",
      "Validation loss decreased (0.022469 --> 0.021813).  Saving model ...\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0222\t Train Acc:61.37 %  | \tValid Loss:0.0216 \tValid Acc: 63.40 %\n",
      "\n",
      "Validation loss decreased (0.021813 --> 0.021565).  Saving model ...\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0221\t Train Acc:61.90 %  | \tValid Loss:0.0215 \tValid Acc: 65.25 %\n",
      "\n",
      "Validation loss decreased (0.021565 --> 0.021456).  Saving model ...\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0213\t Train Acc:63.10 %  | \tValid Loss:0.0212 \tValid Acc: 67.11 %\n",
      "\n",
      "Validation loss decreased (0.021456 --> 0.021234).  Saving model ...\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0213\t Train Acc:61.57 %  | \tValid Loss:0.0210 \tValid Acc: 70.03 %\n",
      "\n",
      "Validation loss decreased (0.021234 --> 0.020990).  Saving model ...\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0212\t Train Acc:63.83 %  | \tValid Loss:0.0213 \tValid Acc: 66.31 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0207\t Train Acc:63.30 %  | \tValid Loss:0.0205 \tValid Acc: 69.23 %\n",
      "\n",
      "Validation loss decreased (0.020990 --> 0.020527).  Saving model ...\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0206\t Train Acc:64.23 %  | \tValid Loss:0.0207 \tValid Acc: 67.37 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0202\t Train Acc:64.16 %  | \tValid Loss:0.0205 \tValid Acc: 70.82 %\n",
      "\n",
      "Validation loss decreased (0.020527 --> 0.020507).  Saving model ...\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0200\t Train Acc:63.63 %  | \tValid Loss:0.0208 \tValid Acc: 70.56 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0196\t Train Acc:65.03 %  | \tValid Loss:0.0207 \tValid Acc: 67.64 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0194\t Train Acc:64.16 %  | \tValid Loss:0.0207 \tValid Acc: 69.23 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0193\t Train Acc:65.69 %  | \tValid Loss:0.0205 \tValid Acc: 64.99 %\n",
      "\n",
      "Validation loss decreased (0.020507 --> 0.020463).  Saving model ...\n",
      "\n",
      "[EPOCH:20]\t Train Loss:0.0189\t Train Acc:66.76 %  | \tValid Loss:0.0198 \tValid Acc: 69.76 %\n",
      "\n",
      "Validation loss decreased (0.020463 --> 0.019829).  Saving model ...\n",
      "\n",
      "[EPOCH:21]\t Train Loss:0.0188\t Train Acc:65.76 %  | \tValid Loss:0.0198 \tValid Acc: 69.50 %\n",
      "\n",
      "Validation loss decreased (0.019829 --> 0.019815).  Saving model ...\n",
      "\n",
      "[EPOCH:22]\t Train Loss:0.0184\t Train Acc:66.82 %  | \tValid Loss:0.0204 \tValid Acc: 66.05 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:23]\t Train Loss:0.0182\t Train Acc:69.28 %  | \tValid Loss:0.0201 \tValid Acc: 67.11 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:24]\t Train Loss:0.0178\t Train Acc:70.01 %  | \tValid Loss:0.0195 \tValid Acc: 68.97 %\n",
      "\n",
      "Validation loss decreased (0.019815 --> 0.019477).  Saving model ...\n",
      "\n",
      "[EPOCH:25]\t Train Loss:0.0174\t Train Acc:70.35 %  | \tValid Loss:0.0194 \tValid Acc: 70.56 %\n",
      "\n",
      "Validation loss decreased (0.019477 --> 0.019404).  Saving model ...\n",
      "\n",
      "[EPOCH:26]\t Train Loss:0.0174\t Train Acc:73.07 %  | \tValid Loss:0.0198 \tValid Acc: 68.70 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:27]\t Train Loss:0.0171\t Train Acc:73.54 %  | \tValid Loss:0.0195 \tValid Acc: 67.37 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:28]\t Train Loss:0.0166\t Train Acc:72.81 %  | \tValid Loss:0.0200 \tValid Acc: 66.84 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:29]\t Train Loss:0.0168\t Train Acc:75.00 %  | \tValid Loss:0.0197 \tValid Acc: 66.05 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:30]\t Train Loss:0.0160\t Train Acc:77.99 %  | \tValid Loss:0.0200 \tValid Acc: 64.19 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[1 교차검증] Early stopping\n",
      "[2 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0242\t Train Acc:52.89 %  | \tValid Loss:0.0238 \tValid Acc: 51.60 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.023761).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0236\t Train Acc:54.35 %  | \tValid Loss:0.0232 \tValid Acc: 61.70 %\n",
      "\n",
      "Validation loss decreased (0.023761 --> 0.023235).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0235\t Train Acc:57.74 %  | \tValid Loss:0.0229 \tValid Acc: 67.29 %\n",
      "\n",
      "Validation loss decreased (0.023235 --> 0.022887).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0227\t Train Acc:58.14 %  | \tValid Loss:0.0226 \tValid Acc: 64.63 %\n",
      "\n",
      "Validation loss decreased (0.022887 --> 0.022563).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0222\t Train Acc:60.93 %  | \tValid Loss:0.0229 \tValid Acc: 63.30 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0220\t Train Acc:59.34 %  | \tValid Loss:0.0219 \tValid Acc: 71.01 %\n",
      "\n",
      "Validation loss decreased (0.022563 --> 0.021912).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0218\t Train Acc:61.00 %  | \tValid Loss:0.0226 \tValid Acc: 67.82 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0213\t Train Acc:62.39 %  | \tValid Loss:0.0228 \tValid Acc: 58.78 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0205\t Train Acc:64.25 %  | \tValid Loss:0.0218 \tValid Acc: 63.56 %\n",
      "\n",
      "Validation loss decreased (0.021912 --> 0.021791).  Saving model ...\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0204\t Train Acc:63.39 %  | \tValid Loss:0.0215 \tValid Acc: 63.56 %\n",
      "\n",
      "Validation loss decreased (0.021791 --> 0.021516).  Saving model ...\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0202\t Train Acc:65.12 %  | \tValid Loss:0.0215 \tValid Acc: 64.10 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0198\t Train Acc:66.45 %  | \tValid Loss:0.0220 \tValid Acc: 63.30 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0195\t Train Acc:66.45 %  | \tValid Loss:0.0219 \tValid Acc: 61.17 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0190\t Train Acc:67.57 %  | \tValid Loss:0.0219 \tValid Acc: 60.64 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0192\t Train Acc:66.64 %  | \tValid Loss:0.0214 \tValid Acc: 63.03 %\n",
      "\n",
      "Validation loss decreased (0.021516 --> 0.021360).  Saving model ...\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0188\t Train Acc:67.91 %  | \tValid Loss:0.0218 \tValid Acc: 61.17 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0183\t Train Acc:68.50 %  | \tValid Loss:0.0214 \tValid Acc: 61.70 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0178\t Train Acc:70.90 %  | \tValid Loss:0.0217 \tValid Acc: 61.17 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0176\t Train Acc:71.30 %  | \tValid Loss:0.0212 \tValid Acc: 63.83 %\n",
      "\n",
      "Validation loss decreased (0.021360 --> 0.021181).  Saving model ...\n",
      "\n",
      "[EPOCH:20]\t Train Loss:0.0175\t Train Acc:73.55 %  | \tValid Loss:0.0218 \tValid Acc: 58.51 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:21]\t Train Loss:0.0169\t Train Acc:73.02 %  | \tValid Loss:0.0215 \tValid Acc: 57.71 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:22]\t Train Loss:0.0174\t Train Acc:74.82 %  | \tValid Loss:0.0219 \tValid Acc: 60.37 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:23]\t Train Loss:0.0176\t Train Acc:69.70 %  | \tValid Loss:0.0213 \tValid Acc: 60.11 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:24]\t Train Loss:0.0173\t Train Acc:71.03 %  | \tValid Loss:0.0216 \tValid Acc: 61.97 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[2 교차검증] Early stopping\n",
      "[3 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0246\t Train Acc:54.02 %  | \tValid Loss:0.0226 \tValid Acc: 65.16 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.022588).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0236\t Train Acc:56.94 %  | \tValid Loss:0.0217 \tValid Acc: 67.55 %\n",
      "\n",
      "Validation loss decreased (0.022588 --> 0.021685).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0235\t Train Acc:57.21 %  | \tValid Loss:0.0224 \tValid Acc: 66.22 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH:4]\t Train Loss:0.0233\t Train Acc:59.07 %  | \tValid Loss:0.0220 \tValid Acc: 65.96 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0229\t Train Acc:59.47 %  | \tValid Loss:0.0218 \tValid Acc: 66.76 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0224\t Train Acc:61.06 %  | \tValid Loss:0.0217 \tValid Acc: 64.63 %\n",
      "\n",
      "Validation loss decreased (0.021685 --> 0.021684).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0216\t Train Acc:60.60 %  | \tValid Loss:0.0210 \tValid Acc: 69.41 %\n",
      "\n",
      "Validation loss decreased (0.021684 --> 0.021002).  Saving model ...\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0216\t Train Acc:60.86 %  | \tValid Loss:0.0210 \tValid Acc: 68.88 %\n",
      "\n",
      "Validation loss decreased (0.021002 --> 0.020985).  Saving model ...\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0214\t Train Acc:62.19 %  | \tValid Loss:0.0209 \tValid Acc: 71.54 %\n",
      "\n",
      "Validation loss decreased (0.020985 --> 0.020877).  Saving model ...\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0215\t Train Acc:63.39 %  | \tValid Loss:0.0200 \tValid Acc: 71.54 %\n",
      "\n",
      "Validation loss decreased (0.020877 --> 0.020038).  Saving model ...\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0207\t Train Acc:63.99 %  | \tValid Loss:0.0205 \tValid Acc: 68.35 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0203\t Train Acc:64.58 %  | \tValid Loss:0.0207 \tValid Acc: 68.35 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0197\t Train Acc:66.98 %  | \tValid Loss:0.0202 \tValid Acc: 70.21 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0190\t Train Acc:68.17 %  | \tValid Loss:0.0202 \tValid Acc: 68.88 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0192\t Train Acc:66.31 %  | \tValid Loss:0.0198 \tValid Acc: 70.21 %\n",
      "\n",
      "Validation loss decreased (0.020038 --> 0.019841).  Saving model ...\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0189\t Train Acc:66.98 %  | \tValid Loss:0.0209 \tValid Acc: 64.89 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0186\t Train Acc:70.37 %  | \tValid Loss:0.0211 \tValid Acc: 63.56 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0186\t Train Acc:70.43 %  | \tValid Loss:0.0203 \tValid Acc: 69.15 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0172\t Train Acc:74.02 %  | \tValid Loss:0.0202 \tValid Acc: 68.09 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:20]\t Train Loss:0.0174\t Train Acc:71.23 %  | \tValid Loss:0.0203 \tValid Acc: 66.49 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[3 교차검증] Early stopping\n",
      "[4 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0247\t Train Acc:53.62 %  | \tValid Loss:0.0224 \tValid Acc: 67.02 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.022408).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0243\t Train Acc:55.22 %  | \tValid Loss:0.0219 \tValid Acc: 68.62 %\n",
      "\n",
      "Validation loss decreased (0.022408 --> 0.021893).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0230\t Train Acc:59.53 %  | \tValid Loss:0.0216 \tValid Acc: 69.41 %\n",
      "\n",
      "Validation loss decreased (0.021893 --> 0.021645).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0237\t Train Acc:57.28 %  | \tValid Loss:0.0215 \tValid Acc: 68.88 %\n",
      "\n",
      "Validation loss decreased (0.021645 --> 0.021504).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0228\t Train Acc:62.13 %  | \tValid Loss:0.0211 \tValid Acc: 71.01 %\n",
      "\n",
      "Validation loss decreased (0.021504 --> 0.021136).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0224\t Train Acc:63.59 %  | \tValid Loss:0.0211 \tValid Acc: 69.15 %\n",
      "\n",
      "Validation loss decreased (0.021136 --> 0.021134).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0221\t Train Acc:65.71 %  | \tValid Loss:0.0214 \tValid Acc: 66.49 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0224\t Train Acc:64.58 %  | \tValid Loss:0.0216 \tValid Acc: 67.55 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0222\t Train Acc:64.72 %  | \tValid Loss:0.0212 \tValid Acc: 68.62 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0219\t Train Acc:65.78 %  | \tValid Loss:0.0211 \tValid Acc: 68.62 %\n",
      "\n",
      "Validation loss decreased (0.021134 --> 0.021057).  Saving model ...\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0217\t Train Acc:66.05 %  | \tValid Loss:0.0216 \tValid Acc: 65.69 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0216\t Train Acc:66.51 %  | \tValid Loss:0.0215 \tValid Acc: 64.89 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0204\t Train Acc:68.11 %  | \tValid Loss:0.0213 \tValid Acc: 68.09 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0207\t Train Acc:68.17 %  | \tValid Loss:0.0220 \tValid Acc: 64.63 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0202\t Train Acc:68.84 %  | \tValid Loss:0.0211 \tValid Acc: 67.55 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[4 교차검증] Early stopping\n",
      "[5 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0247\t Train Acc:52.96 %  | \tValid Loss:0.0234 \tValid Acc: 61.70 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.023397).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0238\t Train Acc:54.62 %  | \tValid Loss:0.0227 \tValid Acc: 64.36 %\n",
      "\n",
      "Validation loss decreased (0.023397 --> 0.022687).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0228\t Train Acc:57.94 %  | \tValid Loss:0.0226 \tValid Acc: 65.16 %\n",
      "\n",
      "Validation loss decreased (0.022687 --> 0.022645).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0227\t Train Acc:57.28 %  | \tValid Loss:0.0225 \tValid Acc: 63.03 %\n",
      "\n",
      "Validation loss decreased (0.022645 --> 0.022543).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0227\t Train Acc:61.59 %  | \tValid Loss:0.0221 \tValid Acc: 64.10 %\n",
      "\n",
      "Validation loss decreased (0.022543 --> 0.022069).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0224\t Train Acc:59.27 %  | \tValid Loss:0.0215 \tValid Acc: 67.02 %\n",
      "\n",
      "Validation loss decreased (0.022069 --> 0.021479).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0212\t Train Acc:63.65 %  | \tValid Loss:0.0216 \tValid Acc: 69.95 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0211\t Train Acc:61.33 %  | \tValid Loss:0.0208 \tValid Acc: 69.41 %\n",
      "\n",
      "Validation loss decreased (0.021479 --> 0.020810).  Saving model ...\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0208\t Train Acc:63.46 %  | \tValid Loss:0.0215 \tValid Acc: 67.02 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0209\t Train Acc:63.32 %  | \tValid Loss:0.0214 \tValid Acc: 64.10 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0202\t Train Acc:64.72 %  | \tValid Loss:0.0210 \tValid Acc: 65.16 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0198\t Train Acc:67.38 %  | \tValid Loss:0.0212 \tValid Acc: 67.02 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0196\t Train Acc:67.31 %  | \tValid Loss:0.0210 \tValid Acc: 64.89 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[5 교차검증] Early stopping\n"
     ]
    }
   ],
   "source": [
    "### 10. 학습 및 평가.\n",
    "# resnet18 pretrained true\n",
    "# kfold 적용\n",
    "\n",
    "train_accs = []\n",
    "valid_accs = []\n",
    "\n",
    "for data_ind in range(1,6):\n",
    "\n",
    "    check_path = '../checkpoint/checkpoint_resnet18_true_noros'+str(data_ind)+'_a.pt'\n",
    "\n",
    "    early_stopping = EarlyStopping(patience = 5, verbose = True, path=check_path)\n",
    "    train_loader,validation_loader = load_data(data_ind-1)\n",
    "    \n",
    "    best_train_acc=0 # accuracy 기록용\n",
    "    best_valid_acc=0\n",
    "    \n",
    "    model=model_initialize()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "    \n",
    "    \n",
    "    print(\"[{} 교차검증] 학습 시작\\n ----- \".format(data_ind))\n",
    "    for Epoch in range(1,EPOCHS+1):\n",
    "        train_loss,train_accuracy=train(model,train_loader,optimizer,log_interval=31)\n",
    "        valid_loss,valid_accuracy = evaluate(model, validation_loader)\n",
    "\n",
    "\n",
    "        print(\"\\n[EPOCH:{}]\\t Train Loss:{:.4f}\\t Train Acc:{:.2f} %  | \\tValid Loss:{:.4f} \\tValid Acc: {:.2f} %\\n\".\n",
    "              format(Epoch,train_loss,train_accuracy,valid_loss,valid_accuracy))\n",
    "\n",
    "        early_stopping(valid_loss, model)\n",
    "        if -early_stopping.best_score == valid_loss:\n",
    "            best_train_acc, best_valid_acc = train_accuracy,valid_accuracy\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "                train_accs.append(best_train_acc)\n",
    "                valid_accs.append(best_valid_acc)\n",
    "                print(\"[{} 교차검증] Early stopping\".format(data_ind))\n",
    "                break\n",
    "\n",
    "        if Epoch==EPOCHS:\n",
    "            #만약 early stop 없이 40 epoch라서 중지 된 경우.\n",
    "            train_accs.append(best_train_acc)\n",
    "            valid_accs.append(best_valid_acc)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6767ec8",
   "metadata": {},
   "source": [
    "# 모델 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6824ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 교차검증] train ACC : 70.3457 |\t valid ACC: 70.5570 \n",
      "[2 교차검증] train ACC : 71.2957 |\t valid ACC: 63.8298 \n",
      "[3 교차검증] train ACC : 66.3123 |\t valid ACC: 70.2128 \n",
      "[4 교차검증] train ACC : 65.7807 |\t valid ACC: 68.6170 \n",
      "[5 교차검증] train ACC : 61.3289 |\t valid ACC: 69.4149 \n",
      "평균 검증 정확도 68.52629945256504 %\n"
     ]
    }
   ],
   "source": [
    "sum_valid=0\n",
    "for data_ind in range(5):\n",
    "    print(\"[{} 교차검증] train ACC : {:.4f} |\\t valid ACC: {:.4f} \".format(data_ind+1,train_accs[data_ind],valid_accs[data_ind] ))\n",
    "    sum_valid+=valid_accs[data_ind]\n",
    "    \n",
    "print(\"평균 검증 정확도\",sum_valid/5,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0967cf",
   "metadata": {},
   "source": [
    "# Model Test\n",
    "\n",
    "- test set\n",
    "- confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a19235bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix 계산\n",
    "#test set 계산.\n",
    "def test_evaluate(model,test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    predictions = []\n",
    "    answers = []\n",
    "    #no_grad : 그래디언트 값 계산 막기.\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "            answers +=label\n",
    "            predictions +=prediction\n",
    "            \n",
    "        return predictions,answers,test_loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca2e1ed2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[148  91]\n",
      " [ 20 118]]\n",
      "[[270 208]\n",
      " [ 39 236]]\n",
      "[[430 287]\n",
      " [ 72 340]]\n",
      "[[655 301]\n",
      " [176 373]]\n",
      "[[842 352]\n",
      " [240 447]]\n",
      "Accuracy : 68.5274% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.7782\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.7052\n",
      "f score : 0.6708 \n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix (resnet18)\n",
    "# kfold의 confusion matrix는 계산 방법이 다르다.\n",
    "# 모델을 각각 불러와서 결과를 모두 합쳐줘야한다.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "cf = np.zeros((2,2))\n",
    "\n",
    "predictions=[]\n",
    "answers=[]\n",
    "\n",
    "for data_ind in range(1,6):\n",
    "\n",
    "    check_path = '../checkpoint/checkpoint_resnet18_true_noros'+str(data_ind)+'_a.pt'\n",
    "    model.load_state_dict(torch.load(check_path))\n",
    "    _,validation_loader = load_data(data_ind-1)\n",
    "\n",
    "    prediction,answer,test_loss = test_evaluate(model, validation_loader)\n",
    "    predictions+=[ dat.cpu().numpy() for dat in prediction]\n",
    "    answers+=[ dat.cpu().numpy() for dat in answer]\n",
    "\n",
    "\n",
    "    print(confusion_matrix(answers, predictions))\n",
    "\n",
    "    \n",
    "cf = confusion_matrix(answers, predictions)\n",
    "acc = (cf[0,0]+cf[1,1])/(cf[0,0]+cf[0,1]+cf[1,0]+cf[1,1])\n",
    "precision=cf[0,0]/(cf[0,0]+cf[1,0])\n",
    "recall=cf[0,0]/(cf[0,0]+cf[0,1])\n",
    "#fscore=2*precision*recall/(precision+recall)\n",
    "\n",
    "fscore = f1_score(answers,predictions,average='macro')\n",
    "\n",
    "print(\"Accuracy : {:.4f}% \".format(acc*100))\n",
    "print(\"Precision (pathology 예측한 것중 맞는 것) : {:.4f}\".format(precision))\n",
    "print(\"recall (실제 pathology 중  예측이 맞는 것) : {:.4f}\".format(recall))\n",
    "print(\"f score : {:.4f} \".format(fscore))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "496.083px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
