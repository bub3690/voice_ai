{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37664ece",
   "metadata": {},
   "source": [
    "- http://keunwoochoi.blogspot.com/2016/03/2.html\n",
    "- http://www.rex-ai.info/docs/AI_Example_CNN_speech_recognize\n",
    "- https://www.youtube.com/watch?v=oltGIc4uo5c\n",
    "- https://youdaeng-com.tistory.com/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "275b8092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pytorch version :  1.10.0  Device :  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn # 인공 신경망 모델들 모아놓은 모듈\n",
    "import torch.nn.functional as F #그중 자주 쓰이는것들을 F로\n",
    "from torchvision import transforms, datasets\n",
    "import cv2\n",
    "from torchvision import transforms, datasets\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "p = os.path.abspath('..') # 상위 폴더를 사용하기 위해서.\n",
    "sys.path.insert(1, p)\n",
    "from pytorchtools.pytorchtools import EarlyStopping # 현재 폴더에 추가된 모듈.\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "#DEVICE = torch.device('cpu')\n",
    "print('Using Pytorch version : ',torch.__version__,' Device : ',DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ebea6",
   "metadata": {},
   "source": [
    "# SVD 문장 데이터에서 Feature 추출\n",
    "- mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "114a1b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa, librosa.display \n",
    "import matplotlib.pyplot as plt\n",
    "#window sizde : FFT를 할때 참조할 그래프 길이 ( 프레임 하나당 sample 수 )\n",
    "#자연어 처리에서는 25ms 사용. https://ahnjg.tistory.com/93\n",
    "#초당 50000hz 중 1250개씩 윈도우 사이즈로 사용.\n",
    "sr=50000\n",
    "win_length =  np.int64(50000/40) # 1250\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c72d82e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pathology data 수 :  1194\n",
      "healthy data 수 :  687\n",
      "가장 긴 path sample : 126051\n",
      "가장 긴 healthy sample : 226236\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa, librosa.display \n",
    "import matplotlib.pyplot as plt\n",
    "#window sizde : FFT를 할때 참조할 그래프 길이 ( 프레임 하나당 sample 수 )\n",
    "#자연어 처리에서는 25ms 사용. https://ahnjg.tistory.com/93\n",
    "#초당 50000hz 중 1250개씩 윈도우 사이즈로 사용.\n",
    "sr=50000\n",
    "win_length =  np.int64(50000/40) # 1250\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다.\n",
    "\n",
    "pathology_sig=[]\n",
    "healthy_sig=[]\n",
    "\n",
    "pathology=[]\n",
    "healthy=[]\n",
    "\n",
    "\n",
    "#PATHOLOGY DATA\n",
    "for audio_path in os.listdir('../../voice_data/pathology_new/i/export'):\n",
    "    sig, sr = librosa.load('../../voice_data/pathology_new/i/export/'+audio_path, sr=50000)# 논문에서 f_s = 50 000HZ\n",
    "    pathology_sig.append(sig)\n",
    "    MFCCs = librosa.feature.mfcc(sig, sr, win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "    pathology.append(MFCCs)\n",
    "    \n",
    "\n",
    "#Healthy data\n",
    "for audio_path in os.listdir('../../voice_data/healthy_new/i/export'):\n",
    "    sig, sr = librosa.load('../../voice_data/healthy_new/i/export/'+audio_path, sr=50000)# 논문에서 f_s = 50 000HZ\n",
    "    healthy_sig.append(sig)\n",
    "    MFCCs = librosa.feature.mfcc(sig, sr, win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "    healthy.append(MFCCs)\n",
    "    \n",
    "print(\"pathology data 수 : \",len(pathology))\n",
    "print(\"healthy data 수 : \",len(healthy))\n",
    "\n",
    "\n",
    "path_max=max([ len(samples) for samples in pathology_sig])\n",
    "healthy_max=max([ len(samples) for samples in healthy_sig])\n",
    "print(\"가장 긴 path sample :\" ,path_max)\n",
    "print(\"가장 긴 healthy sample :\" ,healthy_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "636bede8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.52102 초\n",
      "4.52472 초\n"
     ]
    }
   ],
   "source": [
    "print(path_max/sr,\"초\")\n",
    "print(healthy_max/sr,\"초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5915f64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 :  1.3066967504187605\n",
      "평균 :  1.4290190684133917\n"
     ]
    }
   ],
   "source": [
    "print('평균 : ',np.mean([ len(samples) for samples in pathology_sig])/sr)\n",
    "print('평균 : ',np.mean([ len(samples) for samples in healthy_sig])/sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91bd1989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.504"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "400*313/sr\n",
    "#400 frame은 약 2.5초 이상."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148ec668",
   "metadata": {},
   "source": [
    "# 결과 확인\n",
    "- 1 row당 1 frame으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a48f3297",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>mfcc2</th>\n",
       "      <th>mfcc3</th>\n",
       "      <th>mfcc4</th>\n",
       "      <th>mfcc5</th>\n",
       "      <th>mfcc6</th>\n",
       "      <th>mfcc7</th>\n",
       "      <th>mfcc8</th>\n",
       "      <th>mfcc9</th>\n",
       "      <th>mfcc10</th>\n",
       "      <th>mfcc11</th>\n",
       "      <th>mfcc12</th>\n",
       "      <th>mfcc13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-257.624054</td>\n",
       "      <td>101.441605</td>\n",
       "      <td>11.431145</td>\n",
       "      <td>104.284782</td>\n",
       "      <td>12.844074</td>\n",
       "      <td>30.858997</td>\n",
       "      <td>-23.006546</td>\n",
       "      <td>2.733066</td>\n",
       "      <td>9.088483</td>\n",
       "      <td>7.039111</td>\n",
       "      <td>-10.334429</td>\n",
       "      <td>-11.233789</td>\n",
       "      <td>8.435503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-257.419067</td>\n",
       "      <td>105.031265</td>\n",
       "      <td>5.871933</td>\n",
       "      <td>103.881897</td>\n",
       "      <td>9.893070</td>\n",
       "      <td>31.431822</td>\n",
       "      <td>-28.251961</td>\n",
       "      <td>2.587878</td>\n",
       "      <td>9.513090</td>\n",
       "      <td>6.644758</td>\n",
       "      <td>-10.730095</td>\n",
       "      <td>-7.525294</td>\n",
       "      <td>8.861940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-268.067444</td>\n",
       "      <td>97.532532</td>\n",
       "      <td>-0.844803</td>\n",
       "      <td>97.117706</td>\n",
       "      <td>4.381507</td>\n",
       "      <td>32.494549</td>\n",
       "      <td>-30.492897</td>\n",
       "      <td>8.963182</td>\n",
       "      <td>12.760096</td>\n",
       "      <td>2.586401</td>\n",
       "      <td>-17.708195</td>\n",
       "      <td>-13.206583</td>\n",
       "      <td>5.997622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-265.217255</td>\n",
       "      <td>103.015350</td>\n",
       "      <td>0.299210</td>\n",
       "      <td>96.632637</td>\n",
       "      <td>5.642620</td>\n",
       "      <td>31.900784</td>\n",
       "      <td>-27.334534</td>\n",
       "      <td>13.026344</td>\n",
       "      <td>13.372935</td>\n",
       "      <td>1.548650</td>\n",
       "      <td>-19.601070</td>\n",
       "      <td>-20.358650</td>\n",
       "      <td>6.491438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-273.240997</td>\n",
       "      <td>99.064453</td>\n",
       "      <td>-0.932297</td>\n",
       "      <td>102.358727</td>\n",
       "      <td>9.351763</td>\n",
       "      <td>33.117325</td>\n",
       "      <td>-21.290325</td>\n",
       "      <td>6.766669</td>\n",
       "      <td>11.293850</td>\n",
       "      <td>6.161934</td>\n",
       "      <td>-13.658633</td>\n",
       "      <td>-20.147438</td>\n",
       "      <td>8.825264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>-319.358826</td>\n",
       "      <td>99.801743</td>\n",
       "      <td>11.737771</td>\n",
       "      <td>106.282928</td>\n",
       "      <td>22.124329</td>\n",
       "      <td>35.677372</td>\n",
       "      <td>-23.567856</td>\n",
       "      <td>-9.952773</td>\n",
       "      <td>-5.157382</td>\n",
       "      <td>-4.717806</td>\n",
       "      <td>-5.968917</td>\n",
       "      <td>-0.529867</td>\n",
       "      <td>14.742380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>-319.462280</td>\n",
       "      <td>101.881531</td>\n",
       "      <td>11.020847</td>\n",
       "      <td>107.795593</td>\n",
       "      <td>23.923904</td>\n",
       "      <td>35.095200</td>\n",
       "      <td>-23.819321</td>\n",
       "      <td>-12.773374</td>\n",
       "      <td>-1.936720</td>\n",
       "      <td>-5.520776</td>\n",
       "      <td>-8.793245</td>\n",
       "      <td>-6.701656</td>\n",
       "      <td>9.741186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>-314.436890</td>\n",
       "      <td>101.790909</td>\n",
       "      <td>5.311404</td>\n",
       "      <td>105.077950</td>\n",
       "      <td>24.844336</td>\n",
       "      <td>38.300655</td>\n",
       "      <td>-15.776247</td>\n",
       "      <td>-10.611283</td>\n",
       "      <td>5.813788</td>\n",
       "      <td>-5.038822</td>\n",
       "      <td>-7.109626</td>\n",
       "      <td>-9.563528</td>\n",
       "      <td>6.402265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>-313.523163</td>\n",
       "      <td>99.951782</td>\n",
       "      <td>8.047307</td>\n",
       "      <td>111.989151</td>\n",
       "      <td>17.960836</td>\n",
       "      <td>30.798668</td>\n",
       "      <td>-22.714546</td>\n",
       "      <td>-15.894030</td>\n",
       "      <td>7.621811</td>\n",
       "      <td>0.363993</td>\n",
       "      <td>-1.509025</td>\n",
       "      <td>-10.327892</td>\n",
       "      <td>2.256658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>-305.809143</td>\n",
       "      <td>114.312828</td>\n",
       "      <td>20.389521</td>\n",
       "      <td>119.027878</td>\n",
       "      <td>24.773117</td>\n",
       "      <td>35.625900</td>\n",
       "      <td>-25.438438</td>\n",
       "      <td>-16.555592</td>\n",
       "      <td>-0.157074</td>\n",
       "      <td>-2.125565</td>\n",
       "      <td>-3.486874</td>\n",
       "      <td>-14.503933</td>\n",
       "      <td>-7.731712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>331 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          mfcc1       mfcc2      mfcc3       mfcc4      mfcc5      mfcc6  \\\n",
       "0   -257.624054  101.441605  11.431145  104.284782  12.844074  30.858997   \n",
       "1   -257.419067  105.031265   5.871933  103.881897   9.893070  31.431822   \n",
       "2   -268.067444   97.532532  -0.844803   97.117706   4.381507  32.494549   \n",
       "3   -265.217255  103.015350   0.299210   96.632637   5.642620  31.900784   \n",
       "4   -273.240997   99.064453  -0.932297  102.358727   9.351763  33.117325   \n",
       "..          ...         ...        ...         ...        ...        ...   \n",
       "326 -319.358826   99.801743  11.737771  106.282928  22.124329  35.677372   \n",
       "327 -319.462280  101.881531  11.020847  107.795593  23.923904  35.095200   \n",
       "328 -314.436890  101.790909   5.311404  105.077950  24.844336  38.300655   \n",
       "329 -313.523163   99.951782   8.047307  111.989151  17.960836  30.798668   \n",
       "330 -305.809143  114.312828  20.389521  119.027878  24.773117  35.625900   \n",
       "\n",
       "         mfcc7      mfcc8      mfcc9    mfcc10     mfcc11     mfcc12  \\\n",
       "0   -23.006546   2.733066   9.088483  7.039111 -10.334429 -11.233789   \n",
       "1   -28.251961   2.587878   9.513090  6.644758 -10.730095  -7.525294   \n",
       "2   -30.492897   8.963182  12.760096  2.586401 -17.708195 -13.206583   \n",
       "3   -27.334534  13.026344  13.372935  1.548650 -19.601070 -20.358650   \n",
       "4   -21.290325   6.766669  11.293850  6.161934 -13.658633 -20.147438   \n",
       "..         ...        ...        ...       ...        ...        ...   \n",
       "326 -23.567856  -9.952773  -5.157382 -4.717806  -5.968917  -0.529867   \n",
       "327 -23.819321 -12.773374  -1.936720 -5.520776  -8.793245  -6.701656   \n",
       "328 -15.776247 -10.611283   5.813788 -5.038822  -7.109626  -9.563528   \n",
       "329 -22.714546 -15.894030   7.621811  0.363993  -1.509025 -10.327892   \n",
       "330 -25.438438 -16.555592  -0.157074 -2.125565  -3.486874 -14.503933   \n",
       "\n",
       "        mfcc13  \n",
       "0     8.435503  \n",
       "1     8.861940  \n",
       "2     5.997622  \n",
       "3     6.491438  \n",
       "4     8.825264  \n",
       "..         ...  \n",
       "326  14.742380  \n",
       "327   9.741186  \n",
       "328   6.402265  \n",
       "329   2.256658  \n",
       "330  -7.731712  \n",
       "\n",
       "[331 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(healthy[0][2]) #1번 : 파일. 2번:mfcc\n",
    "headers = \"mfcc1 mfcc2 mfcc3 mfcc4 mfcc5 mfcc6 mfcc7 mfcc8 mfcc9 mfcc10 mfcc11 mfcc12 mfcc13\".split()\n",
    "pd.DataFrame(healthy[1].T,columns=headers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "186be135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthy[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73d328bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "del pathology\n",
    "del healthy\n",
    "del pathology_sig\n",
    "del healthy_sig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23a4c15",
   "metadata": {},
   "source": [
    "# 데이터 나누기 - Stratified KFold\n",
    "\n",
    "- pathology : 1194 / healthy : 687 / 총 1881\n",
    "- k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfb1c84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pathology :  1194\n",
      "Healthy:  687\n",
      "총 데이터수 :  1881\n",
      "교차 검증 : 1\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 549, 'pathology': 955}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 138, 'pathology': 239} \n",
      "\n",
      "교차 검증 : 2\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 550, 'pathology': 955}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 137, 'pathology': 239} \n",
      "\n",
      "교차 검증 : 3\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 550, 'pathology': 955}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 137, 'pathology': 239} \n",
      "\n",
      "교차 검증 : 4\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 550, 'pathology': 955}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 137, 'pathology': 239} \n",
      "\n",
      "교차 검증 : 5\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 549, 'pathology': 956}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 138, 'pathology': 238} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. train, test 나누기\n",
    "\n",
    "import os\n",
    "import random #데이터 shuffle 사용\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from collections import Counter\n",
    "\n",
    "pathology = glob('../../voice_data/pathology_new/i/export/*.wav')\n",
    "healthy = glob('../../voice_data/healthy_new/i/export/*.wav')\n",
    "print(\"Pathology : \",len(pathology))\n",
    "print(\"Healthy: \",len(healthy))\n",
    "\n",
    "X = pathology+healthy # path 데이터 합\n",
    "print(\"총 데이터수 : \",len(X))\n",
    "Y = [] # 라벨\n",
    "for idx,x in enumerate(X):\n",
    "    if idx<1194:\n",
    "        Y.append(\"pathology\")\n",
    "    else:\n",
    "        Y.append(\"healthy\")\n",
    "\n",
    "skf_iris = StratifiedKFold(n_splits=5)\n",
    "cnt_iter = 0\n",
    "\n",
    "X_train_list = [] #데이터 셋 보관\n",
    "Y_train_list = []\n",
    "\n",
    "X_test_list = []\n",
    "Y_test_list = []\n",
    "\n",
    "for train_idx, test_idx in skf_iris.split(X,Y):\n",
    "    \n",
    "    #split으로 반환된 인덱스를 이용하여, 학습 검증용 테스트 데이터 추출\n",
    "    cnt_iter += 1\n",
    "    X_train, X_test = [X[idx] for idx in train_idx.tolist() ], [X[idx] for idx in test_idx.tolist() ]\n",
    "    Y_train, Y_test = [Y[idx] for idx in train_idx.tolist() ], [Y[idx] for idx in test_idx.tolist() ]\n",
    "    \n",
    "    X_train_list.append(X_train)\n",
    "    X_test_list.append(X_test)\n",
    "    \n",
    "    Y_test_list.append(Y_test)\n",
    "    Y_train_list.append(Y_train)\n",
    "    \n",
    "    #학습 및 예측\n",
    "    \n",
    "    label_train = Y_train\n",
    "    label_test = Y_test\n",
    "    unique_train, train_counts = np.unique(label_train, return_counts = True)\n",
    "    unique_test, test_counts = np.unique(label_test, return_counts = True)\n",
    "    \n",
    "    uniq_cnt_train = dict(zip(unique_train, train_counts))\n",
    "    uniq_cnt_test = dict(zip(unique_test, test_counts))\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('교차 검증 : {}'.format(cnt_iter))\n",
    "    print('학습 레이블 데이터 분포 : \\n', uniq_cnt_train)\n",
    "    print('검증 레이블 데이터 분포 : \\n', uniq_cnt_test,'\\n')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a663f0",
   "metadata": {},
   "source": [
    "# 데이터 정의\n",
    "- 추가적으로 데이터의 크기를 맞춰주기 위해 3초로 padding 및 truncate 실시 https://sequencedata.tistory.com/25 FixAudioLength\n",
    "- 논문에서는 400frame으로 설정.\n",
    "- 전처리 방법 결정.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2febf8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "classes = [\"pathology\",\"healthy\"]\n",
    "sr=50000\n",
    "win_length =  np.int64(50000/40) # 1250\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다.\n",
    "\n",
    "class svd_dataset(Dataset):\n",
    "    def __init__(self,data_path_list,classes,data_num,training,transform=None):\n",
    "        #클래스에서 사용할 인자를 받아 인스턴스 변수로 저장하는 일을 한다.\n",
    "        #예를들면, 이미지의 경로 리스트를 저장하는 일을 하게 된다.\n",
    "        \n",
    "        #data_num : k 개 데이터 셋 중 어떤것을 쓸지\n",
    "        #test인지 아닌지.\n",
    "        \n",
    "        self.path_list = data_path_list[data_num]\n",
    "        self.data_num = data_num\n",
    "        self.training = training\n",
    "        self.label = svd_dataset.get_label(self.path_list,training,data_num)\n",
    "        self.classes=classes\n",
    "        self.transform=transform\n",
    "        \n",
    "    \n",
    "    @classmethod\n",
    "    def get_label(cls,data_path_list,training,data_num):\n",
    "        label_list=[]\n",
    "        \n",
    "        if training:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_train_list[data_num][idx])\n",
    "        else:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_test_list[data_num][idx])\n",
    "        #print(label_list)\n",
    "        return label_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "        #데이터 셋의 길이를 정수로 반환한다. \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        1. path를 받아서, 소리에서 mfcc를 추출\n",
    "        2. mfcc를 500프레임으로 패딩.\n",
    "        3. resnet에 사용되기 위해 3채널로 복사(rgb 처럼)\n",
    "        4. 0~1 정규화\n",
    "        \n",
    "        \"\"\"\n",
    "        sig, sr = librosa.load(self.path_list[idx], sr=50000)# 논문에서 f_s = 50 000HZ\n",
    "        \n",
    "        MFCCs = librosa.feature.mfcc(sig, sr, win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=13)\n",
    "        #mfcc 400 FRAME이 되도록 패딩.\n",
    "        length = 400\n",
    "        pad2d = lambda a, i: a[:, 0:i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0], i-a.shape[1]))))\n",
    "        MFCCs = pad2d(MFCCs, length)\n",
    "        MFCCs= MFCCs.T\n",
    "        \n",
    "        if self.transform:\n",
    "            #print('transform')\n",
    "            MFCCs=self.transform(MFCCs).type(torch.float32)# 데이터 0~1 정규화\n",
    "            MFCCs=torch.stack([MFCCs,MFCCs,MFCCs])# 3채널로 복사.\n",
    "            MFCCs = MFCCs.squeeze(dim=1)\n",
    "        else:\n",
    "            #print(\"else\")\n",
    "            MFCCs = torch.from_numpy(MFCCs).type(torch.float32)\n",
    "            MFCCs=MFCCs.unsqueeze(0) #cnn 사용위해서 추가\n",
    "            #MFCCs = MFCCs.permute(2, 0, 1)\n",
    "        return MFCCs, self.classes.index(self.label[idx])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d05129d",
   "metadata": {},
   "source": [
    "# 데이터 로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89052fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. 하이퍼 파라미터\n",
    "BATCH_SIZE =  30 #한 배치당 30개 음성데이터 # 32 배수시에, 1개만 남는 경우가 발생해서.\n",
    "EPOCHS = 40 # 전체 데이터 셋을 40번 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bba97b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA LOADER 함수가 BATCH_size 단위로 분리해 지정.\n",
    "\n",
    "#확인을 위해 데이터셋 하나만 확인\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                           svd_dataset(\n",
    "                                               X_train_list,\n",
    "                                               classes,\n",
    "                                               transform = transforms.ToTensor(),#이걸 composed로 고쳐서 전처리 하도록 수정.\n",
    "                                               data_num=0,\n",
    "                                               training=True\n",
    "                                           ),\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True,\n",
    "                                           ) # 순서가 암기되는것을 막기위해.\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                           svd_dataset(\n",
    "                                               X_test_list,\n",
    "                                               classes,\n",
    "                                               transform = transforms.ToTensor(),\n",
    "                                               data_num=0,\n",
    "                                               training=False\n",
    "                                           ),\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True,) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b15a86",
   "metadata": {},
   "source": [
    "# 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f866237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :  torch.Size([30, 3, 400, 13]) type: torch.FloatTensor\n",
      "Y_train :  torch.Size([30]) type: torch.LongTensor\n",
      "tensor(1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x24a8fd66460>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. 데이터 확인하기\n",
    "for (X_train,Y_train) in train_loader:\n",
    "    print(\"X_train : \",X_train.size(),'type:',X_train.type())\n",
    "    print(\"Y_train : \",Y_train.size(),'type:',Y_train.type())\n",
    "    break\n",
    "    \n",
    "print(Y_train[0])\n",
    "librosa.display.specshow(X_train[0][0].numpy().T, sr=50000, x_axis='time')\n",
    "#batch: 32 / frame수: 400  /  feature수: 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a45b51bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valid :  torch.Size([30, 3, 400, 13]) type: torch.FloatTensor\n",
      "Y_valid :  torch.Size([30]) type: torch.LongTensor\n",
      "tensor(1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x24a8fe140d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#valiation set 확인\n",
    "for (X_valid,Y_valid) in validation_loader:\n",
    "    print(\"X_valid : \",X_valid.size(),'type:',X_valid.type())\n",
    "    print(\"Y_valid : \",Y_valid.size(),'type:',Y_valid.type())\n",
    "    break\n",
    "\n",
    "print(Y_valid[0])\n",
    "librosa.display.specshow(X_valid[0][0].numpy().T, sr=50000, x_axis='time')\n",
    "#batch: 32 / 3채널 / frame수: 400  /  feature수: 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec40ea4",
   "metadata": {},
   "source": [
    "# RESNET18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e1d59a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 \n",
    "# pretrained\n",
    "\n",
    "\n",
    "def model_initialize():\n",
    "    model = models.resnet18(pretrained=True).cuda()\n",
    "    model.ftrs = model.fc.in_features # in_features : fully connected의 입력수.\n",
    "    num_ftrs = model.fc.in_features\n",
    "\n",
    "    model.fc = nn.Sequential(nn.Linear(num_ftrs, 256),\n",
    "                             nn.BatchNorm1d(256),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(256,128),\n",
    "                             nn.BatchNorm1d(128),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(128,64),\n",
    "                             nn.BatchNorm1d(64),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(64,50),\n",
    "                             nn.BatchNorm1d(50),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(50,2)\n",
    "                            )\n",
    "\n",
    "    model = model.cuda()\n",
    "    return model\n",
    "model=model_initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c26ff30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.5, inplace=False)\n",
      "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.5, inplace=False)\n",
      "    (12): Linear(in_features=64, out_features=50, bias=True)\n",
      "    (13): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU()\n",
      "    (15): Dropout(p=0.5, inplace=False)\n",
      "    (16): Linear(in_features=50, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6097d312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 200, 7]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 200, 7]             128\n",
      "              ReLU-3           [-1, 64, 200, 7]               0\n",
      "         MaxPool2d-4           [-1, 64, 100, 4]               0\n",
      "            Conv2d-5           [-1, 64, 100, 4]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 100, 4]             128\n",
      "              ReLU-7           [-1, 64, 100, 4]               0\n",
      "            Conv2d-8           [-1, 64, 100, 4]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 100, 4]             128\n",
      "             ReLU-10           [-1, 64, 100, 4]               0\n",
      "       BasicBlock-11           [-1, 64, 100, 4]               0\n",
      "           Conv2d-12           [-1, 64, 100, 4]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 100, 4]             128\n",
      "             ReLU-14           [-1, 64, 100, 4]               0\n",
      "           Conv2d-15           [-1, 64, 100, 4]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 100, 4]             128\n",
      "             ReLU-17           [-1, 64, 100, 4]               0\n",
      "       BasicBlock-18           [-1, 64, 100, 4]               0\n",
      "           Conv2d-19           [-1, 128, 50, 2]          73,728\n",
      "      BatchNorm2d-20           [-1, 128, 50, 2]             256\n",
      "             ReLU-21           [-1, 128, 50, 2]               0\n",
      "           Conv2d-22           [-1, 128, 50, 2]         147,456\n",
      "      BatchNorm2d-23           [-1, 128, 50, 2]             256\n",
      "           Conv2d-24           [-1, 128, 50, 2]           8,192\n",
      "      BatchNorm2d-25           [-1, 128, 50, 2]             256\n",
      "             ReLU-26           [-1, 128, 50, 2]               0\n",
      "       BasicBlock-27           [-1, 128, 50, 2]               0\n",
      "           Conv2d-28           [-1, 128, 50, 2]         147,456\n",
      "      BatchNorm2d-29           [-1, 128, 50, 2]             256\n",
      "             ReLU-30           [-1, 128, 50, 2]               0\n",
      "           Conv2d-31           [-1, 128, 50, 2]         147,456\n",
      "      BatchNorm2d-32           [-1, 128, 50, 2]             256\n",
      "             ReLU-33           [-1, 128, 50, 2]               0\n",
      "       BasicBlock-34           [-1, 128, 50, 2]               0\n",
      "           Conv2d-35           [-1, 256, 25, 1]         294,912\n",
      "      BatchNorm2d-36           [-1, 256, 25, 1]             512\n",
      "             ReLU-37           [-1, 256, 25, 1]               0\n",
      "           Conv2d-38           [-1, 256, 25, 1]         589,824\n",
      "      BatchNorm2d-39           [-1, 256, 25, 1]             512\n",
      "           Conv2d-40           [-1, 256, 25, 1]          32,768\n",
      "      BatchNorm2d-41           [-1, 256, 25, 1]             512\n",
      "             ReLU-42           [-1, 256, 25, 1]               0\n",
      "       BasicBlock-43           [-1, 256, 25, 1]               0\n",
      "           Conv2d-44           [-1, 256, 25, 1]         589,824\n",
      "      BatchNorm2d-45           [-1, 256, 25, 1]             512\n",
      "             ReLU-46           [-1, 256, 25, 1]               0\n",
      "           Conv2d-47           [-1, 256, 25, 1]         589,824\n",
      "      BatchNorm2d-48           [-1, 256, 25, 1]             512\n",
      "             ReLU-49           [-1, 256, 25, 1]               0\n",
      "       BasicBlock-50           [-1, 256, 25, 1]               0\n",
      "           Conv2d-51           [-1, 512, 13, 1]       1,179,648\n",
      "      BatchNorm2d-52           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-53           [-1, 512, 13, 1]               0\n",
      "           Conv2d-54           [-1, 512, 13, 1]       2,359,296\n",
      "      BatchNorm2d-55           [-1, 512, 13, 1]           1,024\n",
      "           Conv2d-56           [-1, 512, 13, 1]         131,072\n",
      "      BatchNorm2d-57           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-58           [-1, 512, 13, 1]               0\n",
      "       BasicBlock-59           [-1, 512, 13, 1]               0\n",
      "           Conv2d-60           [-1, 512, 13, 1]       2,359,296\n",
      "      BatchNorm2d-61           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-62           [-1, 512, 13, 1]               0\n",
      "           Conv2d-63           [-1, 512, 13, 1]       2,359,296\n",
      "      BatchNorm2d-64           [-1, 512, 13, 1]           1,024\n",
      "             ReLU-65           [-1, 512, 13, 1]               0\n",
      "       BasicBlock-66           [-1, 512, 13, 1]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                  [-1, 256]         131,328\n",
      "      BatchNorm1d-69                  [-1, 256]             512\n",
      "             ReLU-70                  [-1, 256]               0\n",
      "          Dropout-71                  [-1, 256]               0\n",
      "           Linear-72                  [-1, 128]          32,896\n",
      "      BatchNorm1d-73                  [-1, 128]             256\n",
      "             ReLU-74                  [-1, 128]               0\n",
      "          Dropout-75                  [-1, 128]               0\n",
      "           Linear-76                   [-1, 64]           8,256\n",
      "      BatchNorm1d-77                   [-1, 64]             128\n",
      "             ReLU-78                   [-1, 64]               0\n",
      "          Dropout-79                   [-1, 64]               0\n",
      "           Linear-80                   [-1, 50]           3,250\n",
      "      BatchNorm1d-81                   [-1, 50]             100\n",
      "             ReLU-82                   [-1, 50]               0\n",
      "          Dropout-83                   [-1, 50]               0\n",
      "           Linear-84                    [-1, 2]             102\n",
      "================================================================\n",
      "Total params: 11,353,340\n",
      "Trainable params: 11,353,340\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 8.16\n",
      "Params size (MB): 43.31\n",
      "Estimated Total Size (MB): 51.52\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# get the model summary\n",
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 400, 13), device=DEVICE.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f2ca15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. 학습\n",
    "def train(model,train_loader,optimizer, log_interval):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    train_loss = 0\n",
    "    for batch_idx,(image,label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        #데이터들 장비에 할당\n",
    "        optimizer.zero_grad() # device 에 저장된 gradient 제거\n",
    "        output = model(image) # model로 output을 계산\n",
    "        loss = criterion(output, label) #loss 계산\n",
    "        train_loss += loss.item()\n",
    "        prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "        correct += prediction.eq(label.view_as(prediction)).sum().item()# 아웃풋이 배치 사이즈 32개라서.\n",
    "        loss.backward() # loss 값을 이용해 gradient를 계산\n",
    "        optimizer.step() # Gradient 값을 이용해 파라미터 업데이트.\n",
    "    train_loss/=len(train_loader.dataset)\n",
    "    train_accuracy = 100. * correct / len(train_loader.dataset)\n",
    "    return train_loss,train_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b09341bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. 학습 진행하며, validation 데이터로 모델 성능확인\n",
    "def evaluate(model,valid_loader):\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    #no_grad : 그래디언트 값 계산 막기.\n",
    "    with torch.no_grad():\n",
    "        for image, label in valid_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            valid_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()# 아웃풋이 배치 사이즈 32개라서.\n",
    "            #true.false값을 sum해줌. item\n",
    "        valid_loss /= len(valid_loader.dataset)\n",
    "        valid_accuracy = 100. * correct / len(valid_loader.dataset)\n",
    "        return valid_loss,valid_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae179080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 로더 제작 함수\n",
    "\n",
    "def load_data(data_ind):\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_dataset(\n",
    "                                                   X_train_list,\n",
    "                                                   classes,\n",
    "                                                   transform = transforms.ToTensor(),#이걸 composed로 고쳐서 전처리 하도록 수정.\n",
    "                                                   data_num=data_ind,\n",
    "                                                   training=True\n",
    "                                               ),\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = True,\n",
    "                                               ) # 순서가 암기되는것을 막기위해.\n",
    "\n",
    "    validation_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_dataset(\n",
    "                                                   X_test_list,\n",
    "                                                   classes,\n",
    "                                                   transform = transforms.ToTensor(),\n",
    "                                                   data_num=data_ind,\n",
    "                                                   training=False\n",
    "                                               ),\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = True,) \n",
    "    return train_loader,validation_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c85d7e27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0303\t Train Acc:37.37 %  | \tValid Loss:0.0251 \tValid Acc: 37.93 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.025120).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0274\t Train Acc:43.62 %  | \tValid Loss:0.0251 \tValid Acc: 34.48 %\n",
      "\n",
      "Validation loss decreased (0.025120 --> 0.025070).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0263\t Train Acc:44.68 %  | \tValid Loss:0.0245 \tValid Acc: 42.18 %\n",
      "\n",
      "Validation loss decreased (0.025070 --> 0.024545).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0247\t Train Acc:51.33 %  | \tValid Loss:0.0244 \tValid Acc: 62.33 %\n",
      "\n",
      "Validation loss decreased (0.024545 --> 0.024393).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0241\t Train Acc:52.66 %  | \tValid Loss:0.0247 \tValid Acc: 63.13 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0236\t Train Acc:56.38 %  | \tValid Loss:0.0238 \tValid Acc: 63.93 %\n",
      "\n",
      "Validation loss decreased (0.024393 --> 0.023794).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0229\t Train Acc:60.51 %  | \tValid Loss:0.0236 \tValid Acc: 65.52 %\n",
      "\n",
      "Validation loss decreased (0.023794 --> 0.023563).  Saving model ...\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0224\t Train Acc:61.97 %  | \tValid Loss:0.0230 \tValid Acc: 65.52 %\n",
      "\n",
      "Validation loss decreased (0.023563 --> 0.022999).  Saving model ...\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0223\t Train Acc:63.63 %  | \tValid Loss:0.0233 \tValid Acc: 64.72 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0214\t Train Acc:67.55 %  | \tValid Loss:0.0230 \tValid Acc: 65.78 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0212\t Train Acc:68.62 %  | \tValid Loss:0.0221 \tValid Acc: 64.72 %\n",
      "\n",
      "Validation loss decreased (0.022999 --> 0.022061).  Saving model ...\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0212\t Train Acc:68.15 %  | \tValid Loss:0.0232 \tValid Acc: 62.86 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0212\t Train Acc:68.42 %  | \tValid Loss:0.0224 \tValid Acc: 62.60 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0205\t Train Acc:70.88 %  | \tValid Loss:0.0230 \tValid Acc: 63.93 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0203\t Train Acc:71.41 %  | \tValid Loss:0.0222 \tValid Acc: 63.66 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0198\t Train Acc:72.81 %  | \tValid Loss:0.0219 \tValid Acc: 65.52 %\n",
      "\n",
      "Validation loss decreased (0.022061 --> 0.021902).  Saving model ...\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0198\t Train Acc:71.08 %  | \tValid Loss:0.0227 \tValid Acc: 65.78 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0195\t Train Acc:72.47 %  | \tValid Loss:0.0218 \tValid Acc: 66.84 %\n",
      "\n",
      "Validation loss decreased (0.021902 --> 0.021782).  Saving model ...\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0195\t Train Acc:72.01 %  | \tValid Loss:0.0217 \tValid Acc: 66.05 %\n",
      "\n",
      "Validation loss decreased (0.021782 --> 0.021704).  Saving model ...\n",
      "\n",
      "[EPOCH:20]\t Train Loss:0.0197\t Train Acc:73.34 %  | \tValid Loss:0.0235 \tValid Acc: 63.66 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:21]\t Train Loss:0.0188\t Train Acc:74.27 %  | \tValid Loss:0.0213 \tValid Acc: 64.46 %\n",
      "\n",
      "Validation loss decreased (0.021704 --> 0.021283).  Saving model ...\n",
      "\n",
      "[EPOCH:22]\t Train Loss:0.0186\t Train Acc:74.20 %  | \tValid Loss:0.0214 \tValid Acc: 66.58 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:23]\t Train Loss:0.0197\t Train Acc:70.68 %  | \tValid Loss:0.0232 \tValid Acc: 63.40 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:24]\t Train Loss:0.0191\t Train Acc:72.74 %  | \tValid Loss:0.0213 \tValid Acc: 63.66 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:25]\t Train Loss:0.0181\t Train Acc:75.27 %  | \tValid Loss:0.0220 \tValid Acc: 64.46 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:26]\t Train Loss:0.0187\t Train Acc:72.81 %  | \tValid Loss:0.0236 \tValid Acc: 61.54 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[1 교차검증] Early stopping\n",
      "[2 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0244\t Train Acc:59.40 %  | \tValid Loss:0.0225 \tValid Acc: 63.30 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.022460).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0241\t Train Acc:58.74 %  | \tValid Loss:0.0220 \tValid Acc: 61.44 %\n",
      "\n",
      "Validation loss decreased (0.022460 --> 0.021989).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0241\t Train Acc:60.00 %  | \tValid Loss:0.0221 \tValid Acc: 63.56 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0237\t Train Acc:59.34 %  | \tValid Loss:0.0217 \tValid Acc: 63.30 %\n",
      "\n",
      "Validation loss decreased (0.021989 --> 0.021687).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0239\t Train Acc:59.34 %  | \tValid Loss:0.0217 \tValid Acc: 65.16 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0228\t Train Acc:61.20 %  | \tValid Loss:0.0210 \tValid Acc: 65.96 %\n",
      "\n",
      "Validation loss decreased (0.021687 --> 0.020983).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0226\t Train Acc:61.86 %  | \tValid Loss:0.0212 \tValid Acc: 66.22 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0222\t Train Acc:61.33 %  | \tValid Loss:0.0214 \tValid Acc: 66.49 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0214\t Train Acc:63.52 %  | \tValid Loss:0.0209 \tValid Acc: 65.69 %\n",
      "\n",
      "Validation loss decreased (0.020983 --> 0.020894).  Saving model ...\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0212\t Train Acc:64.98 %  | \tValid Loss:0.0212 \tValid Acc: 64.10 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0219\t Train Acc:62.39 %  | \tValid Loss:0.0198 \tValid Acc: 70.74 %\n",
      "\n",
      "Validation loss decreased (0.020894 --> 0.019830).  Saving model ...\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0210\t Train Acc:63.99 %  | \tValid Loss:0.0218 \tValid Acc: 60.11 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0205\t Train Acc:64.65 %  | \tValid Loss:0.0211 \tValid Acc: 69.95 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0201\t Train Acc:65.85 %  | \tValid Loss:0.0207 \tValid Acc: 64.63 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0198\t Train Acc:66.05 %  | \tValid Loss:0.0214 \tValid Acc: 63.83 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0194\t Train Acc:68.04 %  | \tValid Loss:0.0213 \tValid Acc: 66.49 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[2 교차검증] Early stopping\n",
      "[3 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0248\t Train Acc:56.35 %  | \tValid Loss:0.0230 \tValid Acc: 67.02 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.023035).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0245\t Train Acc:54.95 %  | \tValid Loss:0.0229 \tValid Acc: 65.69 %\n",
      "\n",
      "Validation loss decreased (0.023035 --> 0.022910).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0243\t Train Acc:56.41 %  | \tValid Loss:0.0223 \tValid Acc: 64.89 %\n",
      "\n",
      "Validation loss decreased (0.022910 --> 0.022294).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0241\t Train Acc:57.08 %  | \tValid Loss:0.0221 \tValid Acc: 65.43 %\n",
      "\n",
      "Validation loss decreased (0.022294 --> 0.022093).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0235\t Train Acc:58.41 %  | \tValid Loss:0.0218 \tValid Acc: 65.96 %\n",
      "\n",
      "Validation loss decreased (0.022093 --> 0.021843).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0234\t Train Acc:58.74 %  | \tValid Loss:0.0218 \tValid Acc: 64.89 %\n",
      "\n",
      "Validation loss decreased (0.021843 --> 0.021796).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0224\t Train Acc:62.66 %  | \tValid Loss:0.0211 \tValid Acc: 70.21 %\n",
      "\n",
      "Validation loss decreased (0.021796 --> 0.021096).  Saving model ...\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0222\t Train Acc:62.26 %  | \tValid Loss:0.0209 \tValid Acc: 68.35 %\n",
      "\n",
      "Validation loss decreased (0.021096 --> 0.020899).  Saving model ...\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0224\t Train Acc:61.59 %  | \tValid Loss:0.0210 \tValid Acc: 67.82 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0227\t Train Acc:62.99 %  | \tValid Loss:0.0207 \tValid Acc: 68.88 %\n",
      "\n",
      "Validation loss decreased (0.020899 --> 0.020705).  Saving model ...\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0223\t Train Acc:62.19 %  | \tValid Loss:0.0204 \tValid Acc: 68.88 %\n",
      "\n",
      "Validation loss decreased (0.020705 --> 0.020443).  Saving model ...\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0222\t Train Acc:63.85 %  | \tValid Loss:0.0202 \tValid Acc: 69.15 %\n",
      "\n",
      "Validation loss decreased (0.020443 --> 0.020228).  Saving model ...\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0214\t Train Acc:65.25 %  | \tValid Loss:0.0200 \tValid Acc: 68.88 %\n",
      "\n",
      "Validation loss decreased (0.020228 --> 0.020047).  Saving model ...\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0220\t Train Acc:62.06 %  | \tValid Loss:0.0200 \tValid Acc: 70.74 %\n",
      "\n",
      "Validation loss decreased (0.020047 --> 0.019998).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH:15]\t Train Loss:0.0207\t Train Acc:64.65 %  | \tValid Loss:0.0200 \tValid Acc: 73.40 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0209\t Train Acc:66.05 %  | \tValid Loss:0.0191 \tValid Acc: 72.87 %\n",
      "\n",
      "Validation loss decreased (0.019998 --> 0.019112).  Saving model ...\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0209\t Train Acc:65.32 %  | \tValid Loss:0.0188 \tValid Acc: 74.20 %\n",
      "\n",
      "Validation loss decreased (0.019112 --> 0.018769).  Saving model ...\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0200\t Train Acc:67.84 %  | \tValid Loss:0.0197 \tValid Acc: 72.34 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0200\t Train Acc:68.90 %  | \tValid Loss:0.0193 \tValid Acc: 70.21 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:20]\t Train Loss:0.0198\t Train Acc:67.31 %  | \tValid Loss:0.0185 \tValid Acc: 73.94 %\n",
      "\n",
      "Validation loss decreased (0.018769 --> 0.018509).  Saving model ...\n",
      "\n",
      "[EPOCH:21]\t Train Loss:0.0191\t Train Acc:68.97 %  | \tValid Loss:0.0188 \tValid Acc: 74.73 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:22]\t Train Loss:0.0192\t Train Acc:68.64 %  | \tValid Loss:0.0185 \tValid Acc: 71.54 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:23]\t Train Loss:0.0190\t Train Acc:71.43 %  | \tValid Loss:0.0184 \tValid Acc: 75.53 %\n",
      "\n",
      "Validation loss decreased (0.018509 --> 0.018396).  Saving model ...\n",
      "\n",
      "[EPOCH:24]\t Train Loss:0.0197\t Train Acc:70.43 %  | \tValid Loss:0.0183 \tValid Acc: 74.73 %\n",
      "\n",
      "Validation loss decreased (0.018396 --> 0.018269).  Saving model ...\n",
      "\n",
      "[EPOCH:25]\t Train Loss:0.0187\t Train Acc:71.83 %  | \tValid Loss:0.0184 \tValid Acc: 73.94 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:26]\t Train Loss:0.0182\t Train Acc:71.96 %  | \tValid Loss:0.0189 \tValid Acc: 73.67 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:27]\t Train Loss:0.0176\t Train Acc:73.82 %  | \tValid Loss:0.0187 \tValid Acc: 72.34 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:28]\t Train Loss:0.0175\t Train Acc:74.75 %  | \tValid Loss:0.0202 \tValid Acc: 71.01 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:29]\t Train Loss:0.0202\t Train Acc:68.17 %  | \tValid Loss:0.0182 \tValid Acc: 73.94 %\n",
      "\n",
      "Validation loss decreased (0.018269 --> 0.018191).  Saving model ...\n",
      "\n",
      "[EPOCH:30]\t Train Loss:0.0183\t Train Acc:72.69 %  | \tValid Loss:0.0181 \tValid Acc: 76.60 %\n",
      "\n",
      "Validation loss decreased (0.018191 --> 0.018065).  Saving model ...\n",
      "\n",
      "[EPOCH:31]\t Train Loss:0.0172\t Train Acc:72.36 %  | \tValid Loss:0.0193 \tValid Acc: 72.87 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:32]\t Train Loss:0.0167\t Train Acc:75.61 %  | \tValid Loss:0.0194 \tValid Acc: 72.34 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:33]\t Train Loss:0.0165\t Train Acc:76.88 %  | \tValid Loss:0.0191 \tValid Acc: 74.47 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:34]\t Train Loss:0.0159\t Train Acc:77.61 %  | \tValid Loss:0.0214 \tValid Acc: 68.62 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:35]\t Train Loss:0.0156\t Train Acc:79.00 %  | \tValid Loss:0.0194 \tValid Acc: 72.87 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[3 교차검증] Early stopping\n",
      "[4 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0259\t Train Acc:45.58 %  | \tValid Loss:0.0251 \tValid Acc: 38.30 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.025113).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0257\t Train Acc:47.71 %  | \tValid Loss:0.0241 \tValid Acc: 44.68 %\n",
      "\n",
      "Validation loss decreased (0.025113 --> 0.024103).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0246\t Train Acc:50.83 %  | \tValid Loss:0.0235 \tValid Acc: 53.46 %\n",
      "\n",
      "Validation loss decreased (0.024103 --> 0.023498).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0236\t Train Acc:52.89 %  | \tValid Loss:0.0227 \tValid Acc: 65.16 %\n",
      "\n",
      "Validation loss decreased (0.023498 --> 0.022724).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0236\t Train Acc:55.81 %  | \tValid Loss:0.0226 \tValid Acc: 68.88 %\n",
      "\n",
      "Validation loss decreased (0.022724 --> 0.022567).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0235\t Train Acc:55.02 %  | \tValid Loss:0.0223 \tValid Acc: 66.76 %\n",
      "\n",
      "Validation loss decreased (0.022567 --> 0.022278).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0225\t Train Acc:59.07 %  | \tValid Loss:0.0224 \tValid Acc: 60.37 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0221\t Train Acc:59.34 %  | \tValid Loss:0.0219 \tValid Acc: 59.57 %\n",
      "\n",
      "Validation loss decreased (0.022278 --> 0.021944).  Saving model ...\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0215\t Train Acc:61.06 %  | \tValid Loss:0.0219 \tValid Acc: 63.83 %\n",
      "\n",
      "Validation loss decreased (0.021944 --> 0.021858).  Saving model ...\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0214\t Train Acc:62.92 %  | \tValid Loss:0.0211 \tValid Acc: 69.68 %\n",
      "\n",
      "Validation loss decreased (0.021858 --> 0.021078).  Saving model ...\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0211\t Train Acc:63.19 %  | \tValid Loss:0.0210 \tValid Acc: 69.68 %\n",
      "\n",
      "Validation loss decreased (0.021078 --> 0.020958).  Saving model ...\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0202\t Train Acc:65.85 %  | \tValid Loss:0.0207 \tValid Acc: 68.09 %\n",
      "\n",
      "Validation loss decreased (0.020958 --> 0.020688).  Saving model ...\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0204\t Train Acc:65.85 %  | \tValid Loss:0.0201 \tValid Acc: 67.02 %\n",
      "\n",
      "Validation loss decreased (0.020688 --> 0.020099).  Saving model ...\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0197\t Train Acc:67.91 %  | \tValid Loss:0.0199 \tValid Acc: 69.41 %\n",
      "\n",
      "Validation loss decreased (0.020099 --> 0.019921).  Saving model ...\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0202\t Train Acc:65.32 %  | \tValid Loss:0.0205 \tValid Acc: 67.82 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0195\t Train Acc:67.51 %  | \tValid Loss:0.0200 \tValid Acc: 66.49 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0195\t Train Acc:68.31 %  | \tValid Loss:0.0196 \tValid Acc: 68.09 %\n",
      "\n",
      "Validation loss decreased (0.019921 --> 0.019587).  Saving model ...\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0189\t Train Acc:67.91 %  | \tValid Loss:0.0201 \tValid Acc: 67.29 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0187\t Train Acc:68.64 %  | \tValid Loss:0.0193 \tValid Acc: 69.15 %\n",
      "\n",
      "Validation loss decreased (0.019587 --> 0.019349).  Saving model ...\n",
      "\n",
      "[EPOCH:20]\t Train Loss:0.0188\t Train Acc:69.04 %  | \tValid Loss:0.0193 \tValid Acc: 69.15 %\n",
      "\n",
      "Validation loss decreased (0.019349 --> 0.019339).  Saving model ...\n",
      "\n",
      "[EPOCH:21]\t Train Loss:0.0183\t Train Acc:70.83 %  | \tValid Loss:0.0203 \tValid Acc: 65.96 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:22]\t Train Loss:0.0184\t Train Acc:69.04 %  | \tValid Loss:0.0191 \tValid Acc: 72.34 %\n",
      "\n",
      "Validation loss decreased (0.019339 --> 0.019110).  Saving model ...\n",
      "\n",
      "[EPOCH:23]\t Train Loss:0.0182\t Train Acc:69.24 %  | \tValid Loss:0.0201 \tValid Acc: 67.82 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:24]\t Train Loss:0.0179\t Train Acc:72.16 %  | \tValid Loss:0.0195 \tValid Acc: 67.02 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:25]\t Train Loss:0.0181\t Train Acc:71.43 %  | \tValid Loss:0.0180 \tValid Acc: 69.68 %\n",
      "\n",
      "Validation loss decreased (0.019110 --> 0.018048).  Saving model ...\n",
      "\n",
      "[EPOCH:26]\t Train Loss:0.0173\t Train Acc:73.75 %  | \tValid Loss:0.0193 \tValid Acc: 72.87 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:27]\t Train Loss:0.0163\t Train Acc:75.15 %  | \tValid Loss:0.0191 \tValid Acc: 72.34 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:28]\t Train Loss:0.0163\t Train Acc:75.08 %  | \tValid Loss:0.0207 \tValid Acc: 65.16 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:29]\t Train Loss:0.0163\t Train Acc:76.21 %  | \tValid Loss:0.0208 \tValid Acc: 71.28 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:30]\t Train Loss:0.0166\t Train Acc:74.95 %  | \tValid Loss:0.0204 \tValid Acc: 66.22 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[4 교차검증] Early stopping\n",
      "[5 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0237\t Train Acc:56.08 %  | \tValid Loss:0.0229 \tValid Acc: 62.77 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.022866).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0242\t Train Acc:56.48 %  | \tValid Loss:0.0227 \tValid Acc: 62.50 %\n",
      "\n",
      "Validation loss decreased (0.022866 --> 0.022741).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0237\t Train Acc:57.54 %  | \tValid Loss:0.0224 \tValid Acc: 63.56 %\n",
      "\n",
      "Validation loss decreased (0.022741 --> 0.022362).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0233\t Train Acc:59.34 %  | \tValid Loss:0.0223 \tValid Acc: 65.16 %\n",
      "\n",
      "Validation loss decreased (0.022362 --> 0.022334).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0231\t Train Acc:59.20 %  | \tValid Loss:0.0222 \tValid Acc: 62.77 %\n",
      "\n",
      "Validation loss decreased (0.022334 --> 0.022250).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH:6]\t Train Loss:0.0225\t Train Acc:60.33 %  | \tValid Loss:0.0221 \tValid Acc: 65.96 %\n",
      "\n",
      "Validation loss decreased (0.022250 --> 0.022112).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0223\t Train Acc:61.93 %  | \tValid Loss:0.0219 \tValid Acc: 62.50 %\n",
      "\n",
      "Validation loss decreased (0.022112 --> 0.021903).  Saving model ...\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0226\t Train Acc:60.80 %  | \tValid Loss:0.0216 \tValid Acc: 65.16 %\n",
      "\n",
      "Validation loss decreased (0.021903 --> 0.021592).  Saving model ...\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0221\t Train Acc:62.33 %  | \tValid Loss:0.0215 \tValid Acc: 65.43 %\n",
      "\n",
      "Validation loss decreased (0.021592 --> 0.021477).  Saving model ...\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0214\t Train Acc:65.25 %  | \tValid Loss:0.0211 \tValid Acc: 66.22 %\n",
      "\n",
      "Validation loss decreased (0.021477 --> 0.021139).  Saving model ...\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0209\t Train Acc:63.46 %  | \tValid Loss:0.0207 \tValid Acc: 66.49 %\n",
      "\n",
      "Validation loss decreased (0.021139 --> 0.020745).  Saving model ...\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0207\t Train Acc:65.65 %  | \tValid Loss:0.0205 \tValid Acc: 67.29 %\n",
      "\n",
      "Validation loss decreased (0.020745 --> 0.020514).  Saving model ...\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0208\t Train Acc:67.18 %  | \tValid Loss:0.0204 \tValid Acc: 66.22 %\n",
      "\n",
      "Validation loss decreased (0.020514 --> 0.020360).  Saving model ...\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0205\t Train Acc:66.58 %  | \tValid Loss:0.0205 \tValid Acc: 68.35 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0200\t Train Acc:67.04 %  | \tValid Loss:0.0202 \tValid Acc: 67.02 %\n",
      "\n",
      "Validation loss decreased (0.020360 --> 0.020164).  Saving model ...\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0200\t Train Acc:67.24 %  | \tValid Loss:0.0199 \tValid Acc: 67.29 %\n",
      "\n",
      "Validation loss decreased (0.020164 --> 0.019924).  Saving model ...\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0194\t Train Acc:67.64 %  | \tValid Loss:0.0205 \tValid Acc: 66.76 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0193\t Train Acc:69.63 %  | \tValid Loss:0.0201 \tValid Acc: 67.55 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0190\t Train Acc:70.23 %  | \tValid Loss:0.0202 \tValid Acc: 66.49 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:20]\t Train Loss:0.0187\t Train Acc:70.83 %  | \tValid Loss:0.0198 \tValid Acc: 65.96 %\n",
      "\n",
      "Validation loss decreased (0.019924 --> 0.019830).  Saving model ...\n",
      "\n",
      "[EPOCH:21]\t Train Loss:0.0184\t Train Acc:71.76 %  | \tValid Loss:0.0194 \tValid Acc: 67.55 %\n",
      "\n",
      "Validation loss decreased (0.019830 --> 0.019359).  Saving model ...\n",
      "\n",
      "[EPOCH:22]\t Train Loss:0.0180\t Train Acc:72.56 %  | \tValid Loss:0.0201 \tValid Acc: 66.22 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:23]\t Train Loss:0.0179\t Train Acc:73.22 %  | \tValid Loss:0.0200 \tValid Acc: 66.76 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:24]\t Train Loss:0.0175\t Train Acc:73.82 %  | \tValid Loss:0.0204 \tValid Acc: 66.76 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:25]\t Train Loss:0.0180\t Train Acc:72.69 %  | \tValid Loss:0.0223 \tValid Acc: 64.10 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:26]\t Train Loss:0.0182\t Train Acc:71.96 %  | \tValid Loss:0.0215 \tValid Acc: 65.43 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[5 교차검증] Early stopping\n"
     ]
    }
   ],
   "source": [
    "### 10. 학습 및 평가.\n",
    "# resnet18 pretrained true\n",
    "# kfold 적용\n",
    "\n",
    "train_accs = []\n",
    "valid_accs = []\n",
    "\n",
    "for data_ind in range(1,6):\n",
    "\n",
    "    check_path = '../checkpoint/checkpoint_resnet18_true_noros'+str(data_ind)+'_i.pt'\n",
    "\n",
    "    early_stopping = EarlyStopping(patience = 5, verbose = True, path=check_path)\n",
    "    train_loader,validation_loader = load_data(data_ind-1)\n",
    "    \n",
    "    best_train_acc=0 # accuracy 기록용\n",
    "    best_valid_acc=0\n",
    "    \n",
    "    model=model_initialize()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "    \n",
    "    \n",
    "    print(\"[{} 교차검증] 학습 시작\\n ----- \".format(data_ind))\n",
    "    for Epoch in range(1,EPOCHS+1):\n",
    "        train_loss,train_accuracy=train(model,train_loader,optimizer,log_interval=31)\n",
    "        valid_loss,valid_accuracy = evaluate(model, validation_loader)\n",
    "\n",
    "\n",
    "        print(\"\\n[EPOCH:{}]\\t Train Loss:{:.4f}\\t Train Acc:{:.2f} %  | \\tValid Loss:{:.4f} \\tValid Acc: {:.2f} %\\n\".\n",
    "              format(Epoch,train_loss,train_accuracy,valid_loss,valid_accuracy))\n",
    "\n",
    "        early_stopping(valid_loss, model)\n",
    "        if -early_stopping.best_score == valid_loss:\n",
    "            best_train_acc, best_valid_acc = train_accuracy,valid_accuracy\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "                train_accs.append(best_train_acc)\n",
    "                valid_accs.append(best_valid_acc)\n",
    "                print(\"[{} 교차검증] Early stopping\".format(data_ind))\n",
    "                break\n",
    "\n",
    "        if Epoch==EPOCHS:\n",
    "            #만약 early stop 없이 40 epoch라서 중지 된 경우.\n",
    "            train_accs.append(best_train_acc)\n",
    "            valid_accs.append(best_valid_acc)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6767ec8",
   "metadata": {},
   "source": [
    "# 모델 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6824ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 교차검증] train ACC : 74.2686 |\t valid ACC: 64.4562 \n",
      "[2 교차검증] train ACC : 62.3920 |\t valid ACC: 70.7447 \n",
      "[3 교차검증] train ACC : 72.6910 |\t valid ACC: 76.5957 \n",
      "[4 교차검증] train ACC : 71.4286 |\t valid ACC: 69.6809 \n",
      "[5 교차검증] train ACC : 71.7608 |\t valid ACC: 67.5532 \n",
      "평균 검증 정확도 69.80614030137141 %\n"
     ]
    }
   ],
   "source": [
    "sum_valid=0\n",
    "for data_ind in range(5):\n",
    "    print(\"[{} 교차검증] train ACC : {:.4f} |\\t valid ACC: {:.4f} \".format(data_ind+1,train_accs[data_ind],valid_accs[data_ind] ))\n",
    "    sum_valid+=valid_accs[data_ind]\n",
    "    \n",
    "print(\"평균 검증 정확도\",sum_valid/5,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0967cf",
   "metadata": {},
   "source": [
    "# Model Test\n",
    "\n",
    "- test set\n",
    "- confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a19235bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix 계산\n",
    "#test set 계산.\n",
    "def test_evaluate(model,test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    predictions = []\n",
    "    answers = []\n",
    "    #no_grad : 그래디언트 값 계산 막기.\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "            answers +=label\n",
    "            predictions +=prediction\n",
    "            \n",
    "        return predictions,answers,test_loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2e1ed2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[211  28]\n",
      " [106  32]]\n",
      "[[404  74]\n",
      " [170 105]]\n",
      "[[604 113]\n",
      " [219 193]]\n",
      "[[765 191]\n",
      " [255 294]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix (resnet18)\n",
    "# kfold의 confusion matrix는 계산 방법이 다르다.\n",
    "# 모델을 각각 불러와서 결과를 모두 합쳐줘야한다.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "cf = np.zeros((2,2))\n",
    "\n",
    "predictions=[]\n",
    "answers=[]\n",
    "\n",
    "for data_ind in range(1,6):\n",
    "\n",
    "    check_path = '../checkpoint/checkpoint_resnet18_true_noros'+str(data_ind)+'_i.pt'\n",
    "    model.load_state_dict(torch.load(check_path))\n",
    "    _,validation_loader = load_data(data_ind-1)\n",
    "\n",
    "    prediction,answer,test_loss = test_evaluate(model, validation_loader)\n",
    "    predictions+=[ dat.cpu().numpy() for dat in prediction]\n",
    "    answers+=[ dat.cpu().numpy() for dat in answer]\n",
    "\n",
    "\n",
    "    print(confusion_matrix(answers, predictions))\n",
    "\n",
    "    \n",
    "cf = confusion_matrix(answers, predictions)\n",
    "acc = (cf[0,0]+cf[1,1])/(cf[0,0]+cf[0,1]+cf[1,0]+cf[1,1])\n",
    "precision=cf[0,0]/(cf[0,0]+cf[1,0])\n",
    "recall=cf[0,0]/(cf[0,0]+cf[0,1])\n",
    "#fscore=2*precision*recall/(precision+recall)\n",
    "\n",
    "fscore = f1_score(answers,predictions,average='macro')\n",
    "\n",
    "print(\"Accuracy : {:.4f}% \".format(acc*100))\n",
    "print(\"Precision (pathology 예측한 것중 맞는 것) : {:.4f}\".format(precision))\n",
    "print(\"recall (실제 pathology 중  예측이 맞는 것) : {:.4f}\".format(recall))\n",
    "print(\"f score : {:.4f} \".format(fscore))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "496.069px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
