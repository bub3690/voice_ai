{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e2d0f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pytorch version :  1.10.2  Device :  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn # 인공 신경망 모델들 모아놓은 모듈\n",
    "import torch.nn.functional as F #그중 자주 쓰이는것들을 F로\n",
    "from torchvision import transforms, datasets\n",
    "import cv2\n",
    "from torchvision import transforms, datasets\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "p = os.path.abspath('../') # 상위 폴더를 사용하기 위해서.\n",
    "sys.path.insert(1, p)\n",
    "from pytorchtools.pytorchtools import EarlyStopping # 상위 폴더에 추가된 모듈.\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "#DEVICE = torch.device('cpu')\n",
    "print('Using Pytorch version : ',torch.__version__,' Device : ',DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9e7fc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa, librosa.display \n",
    "import matplotlib.pyplot as plt\n",
    "#window sizde : FFT를 할때 참조할 그래프 길이 ( 프레임 하나당 sample 수 )\n",
    "#자연어 처리에서는 25ms 사용. https://ahnjg.tistory.com/93\n",
    "#초당 50000hz 중 1250개씩 윈도우 사이즈로 사용.\n",
    "sr=50000\n",
    "win_length =  np.int64(50000/40) # 1250\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e56223a",
   "metadata": {},
   "source": [
    "# data 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8e6b4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pathology :  1193\n",
      "Healthy:  634\n",
      "총 데이터수 :  1827\n",
      "---\n",
      "훈련 셋 :  1461 Counter({'pathology': 954, 'healthy': 507})\n",
      "테스트 셋 :  366 Counter({'pathology': 239, 'healthy': 127})\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "#1. train, test 나누기\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split # train , test 분리에 사용.\n",
    "\n",
    "\n",
    "pathology = glob('../../voice_data/fusion/pathology/phrase/*.wav')\n",
    "healthy = glob('../../voice_data/fusion/healthy/phrase/*.wav')\n",
    "print(\"Pathology : \",len(pathology))\n",
    "print(\"Healthy: \",len(healthy))\n",
    "\n",
    "\n",
    "pathology= [ path.split(\"\\\\\")[-1] for path in pathology] # path 데이터 변환.\n",
    "healthy= [ path.split(\"\\\\\")[-1] for path in healthy] # path 데이터 변환.\n",
    " # path 데이터 변환\n",
    "\n",
    "\n",
    "X = pathology+healthy # path 데이터 합\n",
    "print(\"총 데이터수 : \",len(X))\n",
    "Y = [] # 라벨\n",
    "for idx,x in enumerate(X):\n",
    "    if idx<1193:\n",
    "        Y.append(\"pathology\")\n",
    "    else:\n",
    "        Y.append(\"healthy\")\n",
    "\n",
    "X, X_test, Y, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True, stratify=Y, random_state=456)\n",
    "#stratify를 넣어서, test에도 라벨별 잘 분류되게 한다.\n",
    "\n",
    "print(\"---\")\n",
    "print(\"훈련 셋 : \",len(Y),Counter(Y))\n",
    "print(\"테스트 셋 : \",len(Y_test),Counter(Y_test))\n",
    "print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94fd1651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 : 1\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 405, 'pathology': 763}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 102, 'pathology': 191} \n",
      "\n",
      "교차 검증 : 2\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 406, 'pathology': 763}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 101, 'pathology': 191} \n",
      "\n",
      "교차 검증 : 3\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 406, 'pathology': 763}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 101, 'pathology': 191} \n",
      "\n",
      "교차 검증 : 4\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 406, 'pathology': 763}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 101, 'pathology': 191} \n",
      "\n",
      "교차 검증 : 5\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 405, 'pathology': 764}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 102, 'pathology': 190} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. train, test 나누기\n",
    "#stratified kfold\n",
    "import os\n",
    "import random #데이터 shuffle 사용\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "skf_iris = StratifiedKFold(n_splits=5,shuffle=True,random_state=456)\n",
    "cnt_iter = 0\n",
    "\n",
    "X_train_list = [] #데이터 셋 보관\n",
    "Y_train_list = []\n",
    "\n",
    "X_valid_list = []\n",
    "Y_valid_list = []\n",
    "\n",
    "for train_idx, test_idx in skf_iris.split(X,Y):\n",
    "    \n",
    "    #split으로 반환된 인덱스를 이용하여, 학습 검증용 테스트 데이터 추출\n",
    "    cnt_iter += 1\n",
    "    X_train, X_valid = [X[idx] for idx in train_idx.tolist() ], [X[idx] for idx in test_idx.tolist() ]\n",
    "    Y_train, Y_valid = [Y[idx] for idx in train_idx.tolist() ], [Y[idx] for idx in test_idx.tolist() ]\n",
    "    \n",
    "    X_train_list.append(X_train)\n",
    "    X_valid_list.append(X_valid)\n",
    "    \n",
    "    Y_train_list.append(Y_train)\n",
    "    Y_valid_list.append(Y_valid)\n",
    "    \n",
    "    \n",
    "    #학습 및 예측\n",
    "    \n",
    "    label_train = Y_train\n",
    "    label_test = Y_valid\n",
    "    unique_train, train_counts = np.unique(label_train, return_counts = True)\n",
    "    unique_test, test_counts = np.unique(label_test, return_counts = True)\n",
    "    \n",
    "    uniq_cnt_train = dict(zip(unique_train, train_counts))\n",
    "    uniq_cnt_test = dict(zip(unique_test, test_counts))\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('교차 검증 : {}'.format(cnt_iter))\n",
    "    print('학습 레이블 데이터 분포 : \\n', uniq_cnt_train)\n",
    "    print('검증 레이블 데이터 분포 : \\n', uniq_cnt_test,'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38bd50b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " fold0 \n",
      "before dataset shape Counter({'pathology': 763, 'healthy': 405})\n",
      "Resampled dataset shape Counter({'pathology': 763, 'healthy': 763})\n",
      "\n",
      " fold1 \n",
      "before dataset shape Counter({'pathology': 763, 'healthy': 406})\n",
      "Resampled dataset shape Counter({'pathology': 763, 'healthy': 763})\n",
      "\n",
      " fold2 \n",
      "before dataset shape Counter({'pathology': 763, 'healthy': 406})\n",
      "Resampled dataset shape Counter({'pathology': 763, 'healthy': 763})\n",
      "\n",
      " fold3 \n",
      "before dataset shape Counter({'pathology': 763, 'healthy': 406})\n",
      "Resampled dataset shape Counter({'pathology': 763, 'healthy': 763})\n",
      "\n",
      " fold4 \n",
      "before dataset shape Counter({'pathology': 764, 'healthy': 405})\n",
      "Resampled dataset shape Counter({'pathology': 764, 'healthy': 764})\n"
     ]
    }
   ],
   "source": [
    "#2. random over sampling\n",
    "for i in range(5):\n",
    "    X_temp = np.array(X_train_list[i]).reshape(-1,1)#각 데이터를 다 행으로 넣음. (1194,1)\n",
    "    #Y = np.array(Y)\n",
    "    ros = RandomOverSampler(random_state = 123)\n",
    "    X_res,Y_res = ros.fit_resample(X_temp,Y_train_list[i])\n",
    "    \n",
    "    print(\"\\n fold{} \".format(i))\n",
    "    print('before dataset shape {}'.format(Counter(Y_train_list[i])) )\n",
    "    print('Resampled dataset shape {}'.format(Counter(Y_res)) )\n",
    "    \n",
    "    #원래대로 돌리기\n",
    "    X_res=X_res.reshape(1, -1)\n",
    "    X_train_list[i]=X_res[0].tolist()\n",
    "    Y_train_list[i]=Y_res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "565ad33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    " \n",
    "#load\n",
    "with open(\"../../voice_data/fusion/phrase_sig_dict.pickle\",\"rb\") as fr:\n",
    "    phrase_dict = pickle.load(fr)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7081577c",
   "metadata": {},
   "source": [
    "# data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bccf7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "classes = [\"pathology\",\"healthy\"]\n",
    "sr=16000\n",
    "win_length =  np.int64(sr/40) # 1250\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다.\n",
    "\n",
    "\n",
    "\n",
    "class svd_dataset(Dataset):\n",
    "    def __init__(self,data_path_list,classes,data_num,training):\n",
    "        #클래스에서 사용할 인자를 받아 인스턴스 변수로 저장하는 일을 한다.\n",
    "        #예를들면, 이미지의 경로 리스트를 저장하는 일을 하게 된다.\n",
    "        \n",
    "        #data_num : k 개 데이터 셋 중 어떤것을 쓸지\n",
    "        #test인지 아닌지.\n",
    "        \n",
    "        self.path_list = data_path_list[data_num]\n",
    "        self.data_num = data_num\n",
    "        self.training = training\n",
    "        self.label = svd_dataset.get_label(self.path_list,training,data_num)\n",
    "        self.classes=classes\n",
    "        \n",
    "    \n",
    "    @classmethod\n",
    "    def get_label(cls,data_path_list,training,data_num):\n",
    "        label_list=[]\n",
    "        \n",
    "        if training:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_train_list[data_num][idx])\n",
    "        else:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_valid_list[data_num][idx])\n",
    "        #print(label_list)\n",
    "        return label_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "        #데이터 셋의 길이를 정수로 반환한다.     \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        1. path를 받아서, signal 변환\n",
    "        2. raw 데이터 바로 출력.\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        sig = phrase_dict[self.path_list[idx]]\n",
    "        pad1d=lambda a, i: a[0:i] if a.shape[0] > i else np.hstack((a, np.zeros((i-a.shape[0]))))\n",
    "        length = 101951\n",
    "        sig=pad1d(sig,length)\n",
    "        sig=torch.from_numpy(sig).type(torch.float32)# 타입 변화\n",
    "        \n",
    "        return sig, self.classes.index(self.label[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59189e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set 제작을 위한 class\n",
    "class svd_test_set(Dataset):\n",
    "    def __init__(self,data_path_list,classes):\n",
    "        #클래스에서 사용할 인자를 받아 인스턴스 변수로 저장하는 일을 한다.\n",
    "        #예를들면, 이미지의 경로 리스트를 저장하는 일을 하게 된다.\n",
    "        \n",
    "        #data_num : k 개 데이터 셋 중 어떤것을 쓸지\n",
    "        #test인지 아닌지.\n",
    "        \n",
    "        self.path_list = data_path_list\n",
    "        self.label = svd_test_set.get_label(self.path_list)\n",
    "        self.classes=classes\n",
    "\n",
    "        \n",
    "    \n",
    "    @classmethod\n",
    "    def get_label(cls,data_path_list):\n",
    "        label_list=[]\n",
    "        \n",
    "        for idx,x in enumerate(data_path_list):\n",
    "            label_list.append(Y_test[idx])\n",
    "        #print(label_list)\n",
    "        return label_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "        #데이터 셋의 길이를 정수로 반환한다. \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        1. path를 받아서, signal 변환\n",
    "        2. raw 데이터 바로 출력.\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        sig = phrase_dict[self.path_list[idx]]\n",
    "        pad1d=lambda a, i: a[0:i] if a.shape[0] > i else np.hstack((a, np.zeros((i-a.shape[0]))))\n",
    "        length = 101951\n",
    "        sig=pad1d(sig,length)\n",
    "        sig=torch.from_numpy(sig).type(torch.float32)# 타입 변화\n",
    "        \n",
    "        return sig, self.classes.index(self.label[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb513028",
   "metadata": {},
   "source": [
    "# data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84c84cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. 하이퍼 파라미터\n",
    "BATCH_SIZE =  32 #한 배치당 32개 음성데이터\n",
    "EPOCHS = 50 # 전체 데이터 셋을 50번 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f77017a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA LOADER 함수가 BATCH_size 단위로 분리해 지정.\n",
    "\n",
    "#확인을 위해 데이터셋 하나만 확인\n",
    "\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                           svd_dataset(\n",
    "                                               X_train_list,\n",
    "                                                   classes,\n",
    "                                               data_num=0,\n",
    "                                               training=True\n",
    "                                           ),\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True,\n",
    "                                           ) # 순서가 암기되는것을 막기위해.\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                           svd_dataset(\n",
    "                                               X_valid_list,\n",
    "                                               classes,\n",
    "                                               data_num=0,\n",
    "                                               training=False\n",
    "                                           ),\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True,) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2426f51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 로더.\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_test_set(\n",
    "                                                   X_test,\n",
    "                                                   classes,\n",
    "                                               ),\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = True,) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80c3e99",
   "metadata": {},
   "source": [
    "# model\n",
    "\n",
    "https://pytorch.org/audio/main/tutorials/speech_recognition_pipeline_tutorial.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3b28b5",
   "metadata": {},
   "source": [
    "dat1=torch.randn((32,12,318,768))\n",
    "model1=nn.Conv2d(12,3,(3,3))\n",
    "dat2=model1(dat1)\n",
    "print(dat2.size())\n",
    "#torch.Size([32, 3, 316, 766])\n",
    "res_18_sample = models.resnet18(pretrained=True)\n",
    "dat3=res_18_sample(dat2)\n",
    "print(dat3.size())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c8179fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/torchaudio/models/wav2vec2_fairseq_large_lv60k_asr_ls960.pth\" to C:\\Users\\USER/.cache\\torch\\hub\\checkpoints\\wav2vec2_fairseq_large_lv60k_asr_ls960.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da629f5aed84bcba90d6e37dd7ba86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/1.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 318, 1024])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x_train,_ in train_loader:\n",
    "    break\n",
    "\n",
    "bundle = torchaudio.pipelines.WAV2VEC2_ASR_LARGE_LV60K_960H\n",
    "model_wav2vec = bundle.get_model().to(DEVICE)\n",
    "with torch.inference_mode():\n",
    "    x,_ = model_wav2vec.extract_features(x_train.cuda())\n",
    "    \n",
    "x[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d48f2583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d8c6486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1024])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[3].mean(axis=1).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130ecb04",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0053952",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "sr=16000\n",
    "win_length =  np.int64(sr/40) #\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다.\n",
    "\n",
    "\n",
    "        \n",
    "class wav_path_Net(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(wav_path_Net,self).__init__()\n",
    "        \n",
    "        bundle = torchaudio.pipelines.WAV2VEC2_BASE\n",
    "        self.model_wav2vec = bundle.get_model().to(DEVICE)\n",
    "        \n",
    "        \n",
    "        input_dim =101951\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.Linear(24*1024,1024),\n",
    "                                nn.BatchNorm1d(1024),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(p=0.7),\n",
    "                                nn.Linear(1024,256),\n",
    "                                nn.BatchNorm1d(256),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(p=0.7),\n",
    "                                nn.Linear(256,2),)\n",
    "        \n",
    "        \n",
    "    def merge(self,hidden_feature):\n",
    "        hidden_feature=[ feat.mean(axis=1) for feat  in  hidden_feature]\n",
    "        return hidden_feature\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        with torch.inference_mode():\n",
    "            x,_ = self.model_wav2vec.extract_features(x)\n",
    "        x = self.merge(x)\n",
    "        x = torch.stack(x,dim=1)\n",
    "        x = x.view(-1,24*1024)\n",
    "        x= self.fc(x)\n",
    "    \n",
    "        return x \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "996212fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "sr=16000\n",
    "win_length =  np.int64(sr/40) #\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다.\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "class wav_path_Net(nn.Module):\n",
    "    def __init__(self,num):\n",
    "        super(wav_path_Net,self).__init__()\n",
    "        \n",
    "        bundle = torchaudio.pipelines.WAV2VEC2_ASR_LARGE_LV60K_960H\n",
    "        self.model_wav2vec = bundle.get_model().to(DEVICE)\n",
    "        self.num = num\n",
    "        \n",
    "        #input_dim =101951\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "                                nn.Linear(1024,256),\n",
    "                                nn.BatchNorm1d(256),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(p=0.7),\n",
    "                                nn.Linear(256,2),)\n",
    "        \n",
    "        \n",
    "    def merge(self,hidden_feature):\n",
    "        hidden_feature=hidden_feature.mean(axis=1)\n",
    "        return hidden_feature\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        with torch.inference_mode():\n",
    "            x,_ = self.model_wav2vec.extract_features(x)\n",
    "        x = x[self.num]\n",
    "        x = self.merge(x)\n",
    "        #x = torch.stack(x,dim=1)\n",
    "        #x = x.view(-1,1024)\n",
    "        x= self.fc(x)\n",
    "    \n",
    "        return x \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf78e2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "sr=16000\n",
    "win_length =  np.int64(sr/40) #\n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다.\n",
    "\n",
    "\n",
    "bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H\n",
    "model_wav2vec = bundle.get_model().to(DEVICE)\n",
    "\n",
    "print(model_wav2vec.__class__)\n",
    "\n",
    "        \n",
    "class wav_path_Net(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(wav_path_Net,self).__init__()\n",
    "        \n",
    "        bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H\n",
    "        self.model_wav2vec = bundle.get_model().to(DEVICE)\n",
    "        self.res_18 = models.resnet18(pretrained=True)\n",
    "        self.conv_model1=nn.Conv2d(12,3,(3,3))\n",
    "        \n",
    "        #input_dim =101951\n",
    "        \n",
    "        self.fc = nn.Sequential(nn.Linear(1000,512),\n",
    "                                nn.BatchNorm1d(512),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(512,256),\n",
    "                                nn.BatchNorm1d(256),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(256,50),\n",
    "                                nn.Linear(50,2),)\n",
    "        \n",
    "        \n",
    "    def merge(self,hidden_feature):\n",
    "        hidden_feature=[ feat.mean(axis=1) for feat  in  hidden_feature]\n",
    "        return hidden_feature\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        with torch.inference_mode():\n",
    "            x,_ = self.model_wav2vec.extract_features(x)\n",
    "        x = torch.stack(x,axis=1)\n",
    "        x = self.conv_model1(x)\n",
    "        x = self.res_18(x)\n",
    "        x= self.fc(x)\n",
    "    \n",
    "        return x \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51eac24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Optimizer, Objective Function\n",
    "def model_initialize(num):\n",
    "    model = wav_path_Net(num).to(DEVICE)\n",
    "    #원핫 인코딩값의 loss는 crossEntropyLoss로 비교\n",
    "    #print(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b33fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. 학습\n",
    "def train(model,train_loader,optimizer, log_interval):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    train_loss = 0\n",
    "    for batch_idx,(image,label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        #데이터들 장비에 할당\n",
    "        optimizer.zero_grad() # device 에 저장된 gradient 제거\n",
    "        output = model(image) # model로 output을 계산\n",
    "        loss = criterion(output, label) #loss 계산\n",
    "        train_loss += loss.item()\n",
    "        prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "        correct += prediction.eq(label.view_as(prediction)).sum().item()# 아웃풋이 배치 사이즈 32개라서.\n",
    "        loss.backward() # loss 값을 이용해 gradient를 계산\n",
    "        optimizer.step() # Gradient 값을 이용해 파라미터 업데이트.\n",
    "    train_loss/=len(train_loader.dataset)\n",
    "    train_accuracy = 100. * correct / len(train_loader.dataset)\n",
    "    return train_loss,train_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "953a0f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. 학습 진행하며, validation 데이터로 모델 성능확인\n",
    "def evaluate(model,valid_loader):\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    #no_grad : 그래디언트 값 계산 막기.\n",
    "    with torch.no_grad():\n",
    "        for image, label in valid_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            valid_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()# 아웃풋이 배치 사이즈 32개라서.\n",
    "            \n",
    "            #true.false값을 sum해줌. item\n",
    "        valid_loss /= len(valid_loader.dataset)\n",
    "        valid_accuracy = 100. * correct / len(valid_loader.dataset)\n",
    "        return valid_loss,valid_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "632b6d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 로더 제작 함수\n",
    "\n",
    "def load_data(data_ind):\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_dataset(\n",
    "                                                   X_train_list,\n",
    "                                                   classes,\n",
    "                                                   data_num=data_ind,\n",
    "                                                   training=True\n",
    "                                               ),\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = True,\n",
    "                                               ) # 순서가 암기되는것을 막기위해.\n",
    "\n",
    "    validation_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_dataset(\n",
    "                                                   X_valid_list,\n",
    "                                                   classes,\n",
    "                                                   data_num=data_ind,\n",
    "                                                   training=False\n",
    "                                               ),\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = True,) \n",
    "    return train_loader,validation_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16463699",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. 학습 진행하며, validation 데이터로 모델 성능확인\n",
    "def test_evaluate(model,test_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    answers = []\n",
    "    #no_grad : 그래디언트 값 계산 막기.\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            output = F.softmax(output, dim=1).data.squeeze() # softmax 적용 (모델을 통과는 했지만, criterion는 안통과함.)\n",
    "            prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "            answers +=label\n",
    "            predictions +=prediction\n",
    "        return predictions,answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3b54cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix (resnet18)\n",
    "# kfold의 confusion matrix는 계산 방법이 다르다.\n",
    "# 모델을 각각 불러와서 test set을 평가한다.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "\n",
    "def test_grid():\n",
    "    cf = np.zeros((2,2))\n",
    "    cf_list = []\n",
    "    average_accuracy = 0\n",
    "    average_fscore = 0\n",
    "    \n",
    "    \n",
    "    for grid_num in range(0,24):\n",
    "        for data_ind in range(1,2):\n",
    "            model=model_initialize(grid_num)\n",
    "            check_path = '../checkpoint/checkpoint_w2v_large_960ft_'+str(grid_num)+'-'+str(data_ind)+'.pt'\n",
    "            model.load_state_dict(torch.load(check_path))\n",
    "\n",
    "            predictions,answers = test_evaluate(model, test_loader)\n",
    "            predictions=[ dat.cpu().numpy() for dat in predictions]\n",
    "            answers=[ dat.cpu().numpy() for dat in answers]\n",
    "\n",
    "\n",
    "            cf = confusion_matrix(answers, predictions)\n",
    "            cf_list.append(cf)\n",
    "\n",
    "            acc = (cf[0,0]+cf[1,1])/(cf[0,0]+cf[0,1]+cf[1,0]+cf[1,1])\n",
    "            average_accuracy+=acc\n",
    "            precision=cf[0,0]/(cf[0,0]+cf[1,0])\n",
    "            recall=cf[0,0]/(cf[0,0]+cf[0,1])\n",
    "            #fscore=2*precision*recall/(precision+recall)\n",
    "\n",
    "            #fscroe macro추가\n",
    "            fscore = f1_score(answers,predictions,average='macro')\n",
    "            average_fscore+=fscore\n",
    "\n",
    "            print('{}번 모델'.format(grid_num+1))\n",
    "            print(\"Accuracy : {:.4f}% \".format(acc*100))\n",
    "            print(\"Precision (pathology 예측한 것중 맞는 것) : {:.4f}\".format(precision))\n",
    "            print(\"recall (실제 pathology 중  예측이 맞는 것) : {:.4f}\".format(recall))\n",
    "            print(\"f score : {:.4f} \".format(fscore))\n",
    "            print(cf)\n",
    "            print(\"-----\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ef3b7d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-번 레이어\n",
      "../checkpoint/checkpoint_w2v_large_960ft_0-1.pt\n",
      "[1 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0179\t Train Acc:69.86 %  | \tValid Loss:0.0164 \tValid Acc: 74.06 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.016445).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0142\t Train Acc:78.11 %  | \tValid Loss:0.0158 \tValid Acc: 77.47 %\n",
      "\n",
      "Validation loss decreased (0.016445 --> 0.015773).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0132\t Train Acc:81.00 %  | \tValid Loss:0.0139 \tValid Acc: 81.57 %\n",
      "\n",
      "Validation loss decreased (0.015773 --> 0.013875).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0125\t Train Acc:81.78 %  | \tValid Loss:0.0158 \tValid Acc: 74.40 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0115\t Train Acc:83.49 %  | \tValid Loss:0.0151 \tValid Acc: 77.47 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0109\t Train Acc:84.40 %  | \tValid Loss:0.0121 \tValid Acc: 83.62 %\n",
      "\n",
      "Validation loss decreased (0.013875 --> 0.012132).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0107\t Train Acc:85.52 %  | \tValid Loss:0.0123 \tValid Acc: 85.67 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0106\t Train Acc:85.98 %  | \tValid Loss:0.0146 \tValid Acc: 79.18 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0099\t Train Acc:86.96 %  | \tValid Loss:0.0123 \tValid Acc: 86.35 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0093\t Train Acc:88.01 %  | \tValid Loss:0.0137 \tValid Acc: 79.86 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0093\t Train Acc:88.01 %  | \tValid Loss:0.0153 \tValid Acc: 77.47 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[1 교차검증] Early stopping\n",
      "1-번 레이어\n",
      "../checkpoint/checkpoint_w2v_large_960ft_1-1.pt\n",
      "[1 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0182\t Train Acc:70.31 %  | \tValid Loss:0.0141 \tValid Acc: 80.20 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.014086).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0144\t Train Acc:78.31 %  | \tValid Loss:0.0128 \tValid Acc: 84.30 %\n",
      "\n",
      "Validation loss decreased (0.014086 --> 0.012795).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0129\t Train Acc:80.54 %  | \tValid Loss:0.0128 \tValid Acc: 83.62 %\n",
      "\n",
      "Validation loss decreased (0.012795 --> 0.012762).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0123\t Train Acc:82.18 %  | \tValid Loss:0.0120 \tValid Acc: 84.64 %\n",
      "\n",
      "Validation loss decreased (0.012762 --> 0.011981).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0112\t Train Acc:84.47 %  | \tValid Loss:0.0126 \tValid Acc: 82.25 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0106\t Train Acc:85.32 %  | \tValid Loss:0.0143 \tValid Acc: 81.57 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0102\t Train Acc:86.44 %  | \tValid Loss:0.0129 \tValid Acc: 80.89 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0105\t Train Acc:86.17 %  | \tValid Loss:0.0114 \tValid Acc: 83.96 %\n",
      "\n",
      "Validation loss decreased (0.011981 --> 0.011395).  Saving model ...\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0096\t Train Acc:86.89 %  | \tValid Loss:0.0105 \tValid Acc: 87.03 %\n",
      "\n",
      "Validation loss decreased (0.011395 --> 0.010517).  Saving model ...\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0090\t Train Acc:88.73 %  | \tValid Loss:0.0115 \tValid Acc: 87.03 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0087\t Train Acc:89.06 %  | \tValid Loss:0.0119 \tValid Acc: 83.62 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0088\t Train Acc:88.53 %  | \tValid Loss:0.0140 \tValid Acc: 82.25 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0079\t Train Acc:90.10 %  | \tValid Loss:0.0108 \tValid Acc: 87.03 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0079\t Train Acc:91.02 %  | \tValid Loss:0.0112 \tValid Acc: 86.35 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[1 교차검증] Early stopping\n",
      "2-번 레이어\n",
      "../checkpoint/checkpoint_w2v_large_960ft_2-1.pt\n",
      "[1 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0180\t Train Acc:69.99 %  | \tValid Loss:0.0172 \tValid Acc: 75.09 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.017202).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0144\t Train Acc:79.03 %  | \tValid Loss:0.0144 \tValid Acc: 80.20 %\n",
      "\n",
      "Validation loss decreased (0.017202 --> 0.014392).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0128\t Train Acc:81.85 %  | \tValid Loss:0.0128 \tValid Acc: 86.69 %\n",
      "\n",
      "Validation loss decreased (0.014392 --> 0.012838).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0122\t Train Acc:83.81 %  | \tValid Loss:0.0120 \tValid Acc: 85.67 %\n",
      "\n",
      "Validation loss decreased (0.012838 --> 0.011957).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0112\t Train Acc:84.34 %  | \tValid Loss:0.0146 \tValid Acc: 83.62 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0107\t Train Acc:84.80 %  | \tValid Loss:0.0118 \tValid Acc: 87.03 %\n",
      "\n",
      "Validation loss decreased (0.011957 --> 0.011837).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0100\t Train Acc:86.57 %  | \tValid Loss:0.0132 \tValid Acc: 82.94 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0097\t Train Acc:88.34 %  | \tValid Loss:0.0123 \tValid Acc: 86.35 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0091\t Train Acc:88.27 %  | \tValid Loss:0.0103 \tValid Acc: 86.01 %\n",
      "\n",
      "Validation loss decreased (0.011837 --> 0.010280).  Saving model ...\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0088\t Train Acc:88.07 %  | \tValid Loss:0.0114 \tValid Acc: 84.64 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0086\t Train Acc:88.86 %  | \tValid Loss:0.0106 \tValid Acc: 87.71 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0080\t Train Acc:90.24 %  | \tValid Loss:0.0103 \tValid Acc: 87.03 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0081\t Train Acc:90.10 %  | \tValid Loss:0.0120 \tValid Acc: 83.96 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0073\t Train Acc:91.74 %  | \tValid Loss:0.0109 \tValid Acc: 85.67 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[1 교차검증] Early stopping\n",
      "3-번 레이어\n",
      "../checkpoint/checkpoint_w2v_large_960ft_3-1.pt\n",
      "[1 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0184\t Train Acc:70.05 %  | \tValid Loss:0.0168 \tValid Acc: 73.04 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.016836).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0139\t Train Acc:80.34 %  | \tValid Loss:0.0128 \tValid Acc: 82.59 %\n",
      "\n",
      "Validation loss decreased (0.016836 --> 0.012804).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0123\t Train Acc:82.44 %  | \tValid Loss:0.0140 \tValid Acc: 82.59 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0116\t Train Acc:84.67 %  | \tValid Loss:0.0142 \tValid Acc: 78.84 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0113\t Train Acc:84.08 %  | \tValid Loss:0.0131 \tValid Acc: 84.98 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0106\t Train Acc:85.32 %  | \tValid Loss:0.0155 \tValid Acc: 78.50 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0098\t Train Acc:86.70 %  | \tValid Loss:0.0132 \tValid Acc: 84.98 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[1 교차검증] Early stopping\n",
      "4-번 레이어\n",
      "../checkpoint/checkpoint_w2v_large_960ft_4-1.pt\n",
      "[1 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0190\t Train Acc:68.55 %  | \tValid Loss:0.0292 \tValid Acc: 60.41 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.029231).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0143\t Train Acc:79.36 %  | \tValid Loss:0.0132 \tValid Acc: 81.91 %\n",
      "\n",
      "Validation loss decreased (0.029231 --> 0.013221).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0130\t Train Acc:81.19 %  | \tValid Loss:0.0159 \tValid Acc: 80.20 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0119\t Train Acc:84.34 %  | \tValid Loss:0.0164 \tValid Acc: 77.13 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0116\t Train Acc:83.88 %  | \tValid Loss:0.0128 \tValid Acc: 82.94 %\n",
      "\n",
      "Validation loss decreased (0.013221 --> 0.012752).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0110\t Train Acc:84.80 %  | \tValid Loss:0.0171 \tValid Acc: 75.43 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0102\t Train Acc:85.85 %  | \tValid Loss:0.0134 \tValid Acc: 81.57 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0097\t Train Acc:87.02 %  | \tValid Loss:0.0130 \tValid Acc: 82.25 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0095\t Train Acc:87.55 %  | \tValid Loss:0.0128 \tValid Acc: 82.94 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0084\t Train Acc:89.84 %  | \tValid Loss:0.0143 \tValid Acc: 81.23 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[1 교차검증] Early stopping\n",
      "5-번 레이어\n",
      "../checkpoint/checkpoint_w2v_large_960ft_5-1.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0191\t Train Acc:68.28 %  | \tValid Loss:0.0151 \tValid Acc: 77.13 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.015084).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0142\t Train Acc:79.03 %  | \tValid Loss:0.0130 \tValid Acc: 81.91 %\n",
      "\n",
      "Validation loss decreased (0.015084 --> 0.012952).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0130\t Train Acc:81.59 %  | \tValid Loss:0.0120 \tValid Acc: 84.30 %\n",
      "\n",
      "Validation loss decreased (0.012952 --> 0.011996).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0116\t Train Acc:84.01 %  | \tValid Loss:0.0151 \tValid Acc: 78.16 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0112\t Train Acc:84.80 %  | \tValid Loss:0.0113 \tValid Acc: 86.35 %\n",
      "\n",
      "Validation loss decreased (0.011996 --> 0.011344).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0102\t Train Acc:87.02 %  | \tValid Loss:0.0117 \tValid Acc: 88.05 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0102\t Train Acc:86.24 %  | \tValid Loss:0.0124 \tValid Acc: 84.30 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0095\t Train Acc:87.42 %  | \tValid Loss:0.0110 \tValid Acc: 86.01 %\n",
      "\n",
      "Validation loss decreased (0.011344 --> 0.010959).  Saving model ...\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0092\t Train Acc:87.61 %  | \tValid Loss:0.0141 \tValid Acc: 84.64 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0091\t Train Acc:88.27 %  | \tValid Loss:0.0110 \tValid Acc: 86.01 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0089\t Train Acc:88.60 %  | \tValid Loss:0.0118 \tValid Acc: 84.98 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0078\t Train Acc:90.04 %  | \tValid Loss:0.0104 \tValid Acc: 86.01 %\n",
      "\n",
      "Validation loss decreased (0.010959 --> 0.010436).  Saving model ...\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0082\t Train Acc:89.32 %  | \tValid Loss:0.0119 \tValid Acc: 86.35 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0076\t Train Acc:91.09 %  | \tValid Loss:0.0133 \tValid Acc: 82.94 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0068\t Train Acc:92.20 %  | \tValid Loss:0.0111 \tValid Acc: 86.69 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0067\t Train Acc:91.94 %  | \tValid Loss:0.0188 \tValid Acc: 81.91 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0064\t Train Acc:91.55 %  | \tValid Loss:0.0104 \tValid Acc: 87.03 %\n",
      "\n",
      "Validation loss decreased (0.010436 --> 0.010397).  Saving model ...\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0065\t Train Acc:92.14 %  | \tValid Loss:0.0139 \tValid Acc: 83.62 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0062\t Train Acc:92.79 %  | \tValid Loss:0.0105 \tValid Acc: 85.67 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:20]\t Train Loss:0.0060\t Train Acc:93.64 %  | \tValid Loss:0.0138 \tValid Acc: 81.91 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:21]\t Train Loss:0.0058\t Train Acc:92.66 %  | \tValid Loss:0.0111 \tValid Acc: 86.35 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:22]\t Train Loss:0.0054\t Train Acc:94.50 %  | \tValid Loss:0.0111 \tValid Acc: 83.28 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[1 교차검증] Early stopping\n",
      "6-번 레이어\n",
      "../checkpoint/checkpoint_w2v_large_960ft_6-1.pt\n",
      "[1 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0181\t Train Acc:70.97 %  | \tValid Loss:0.0176 \tValid Acc: 77.82 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.017594).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0140\t Train Acc:79.88 %  | \tValid Loss:0.0134 \tValid Acc: 83.28 %\n",
      "\n",
      "Validation loss decreased (0.017594 --> 0.013410).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0129\t Train Acc:81.26 %  | \tValid Loss:0.0118 \tValid Acc: 84.98 %\n",
      "\n",
      "Validation loss decreased (0.013410 --> 0.011838).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0115\t Train Acc:83.88 %  | \tValid Loss:0.0132 \tValid Acc: 84.30 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0111\t Train Acc:84.67 %  | \tValid Loss:0.0118 \tValid Acc: 84.98 %\n",
      "\n",
      "Validation loss decreased (0.011838 --> 0.011796).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0103\t Train Acc:85.91 %  | \tValid Loss:0.0149 \tValid Acc: 81.57 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0104\t Train Acc:85.85 %  | \tValid Loss:0.0134 \tValid Acc: 80.55 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0094\t Train Acc:87.88 %  | \tValid Loss:0.0113 \tValid Acc: 86.01 %\n",
      "\n",
      "Validation loss decreased (0.011796 --> 0.011317).  Saving model ...\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0095\t Train Acc:87.16 %  | \tValid Loss:0.0127 \tValid Acc: 86.35 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0091\t Train Acc:88.34 %  | \tValid Loss:0.0115 \tValid Acc: 83.62 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0089\t Train Acc:88.53 %  | \tValid Loss:0.0114 \tValid Acc: 86.69 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0084\t Train Acc:88.34 %  | \tValid Loss:0.0120 \tValid Acc: 85.32 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0075\t Train Acc:90.76 %  | \tValid Loss:0.0124 \tValid Acc: 84.30 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[1 교차검증] Early stopping\n",
      "7-번 레이어\n",
      "../checkpoint/checkpoint_w2v_large_960ft_7-1.pt\n",
      "[1 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0185\t Train Acc:67.96 %  | \tValid Loss:0.0168 \tValid Acc: 72.35 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.016787).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0142\t Train Acc:78.83 %  | \tValid Loss:0.0136 \tValid Acc: 83.96 %\n",
      "\n",
      "Validation loss decreased (0.016787 --> 0.013577).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0132\t Train Acc:80.28 %  | \tValid Loss:0.0130 \tValid Acc: 83.62 %\n",
      "\n",
      "Validation loss decreased (0.013577 --> 0.013015).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0123\t Train Acc:83.16 %  | \tValid Loss:0.0124 \tValid Acc: 83.96 %\n",
      "\n",
      "Validation loss decreased (0.013015 --> 0.012415).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0112\t Train Acc:85.12 %  | \tValid Loss:0.0143 \tValid Acc: 81.91 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0112\t Train Acc:85.32 %  | \tValid Loss:0.0147 \tValid Acc: 83.96 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0107\t Train Acc:85.91 %  | \tValid Loss:0.0139 \tValid Acc: 83.62 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0098\t Train Acc:86.44 %  | \tValid Loss:0.0180 \tValid Acc: 72.70 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0091\t Train Acc:89.19 %  | \tValid Loss:0.0143 \tValid Acc: 79.86 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[1 교차검증] Early stopping\n",
      "8-번 레이어\n",
      "../checkpoint/checkpoint_w2v_large_960ft_8-1.pt\n",
      "[1 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0178\t Train Acc:70.38 %  | \tValid Loss:0.0166 \tValid Acc: 79.52 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.016619).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0146\t Train Acc:78.11 %  | \tValid Loss:0.0135 \tValid Acc: 82.94 %\n",
      "\n",
      "Validation loss decreased (0.016619 --> 0.013514).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0127\t Train Acc:81.45 %  | \tValid Loss:0.0127 \tValid Acc: 84.64 %\n",
      "\n",
      "Validation loss decreased (0.013514 --> 0.012730).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0122\t Train Acc:82.90 %  | \tValid Loss:0.0143 \tValid Acc: 82.59 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0117\t Train Acc:83.94 %  | \tValid Loss:0.0134 \tValid Acc: 81.57 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0114\t Train Acc:84.80 %  | \tValid Loss:0.0135 \tValid Acc: 86.01 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0105\t Train Acc:86.30 %  | \tValid Loss:0.0112 \tValid Acc: 86.69 %\n",
      "\n",
      "Validation loss decreased (0.012730 --> 0.011210).  Saving model ...\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0097\t Train Acc:87.55 %  | \tValid Loss:0.0137 \tValid Acc: 82.59 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0097\t Train Acc:86.57 %  | \tValid Loss:0.0129 \tValid Acc: 85.67 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0095\t Train Acc:87.55 %  | \tValid Loss:0.0117 \tValid Acc: 86.69 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0092\t Train Acc:88.34 %  | \tValid Loss:0.0147 \tValid Acc: 81.23 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0081\t Train Acc:89.52 %  | \tValid Loss:0.0132 \tValid Acc: 86.35 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[1 교차검증] Early stopping\n",
      "9-번 레이어\n",
      "../checkpoint/checkpoint_w2v_large_960ft_9-1.pt\n",
      "[1 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0188\t Train Acc:69.07 %  | \tValid Loss:0.0145 \tValid Acc: 82.25 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.014487).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH:2]\t Train Loss:0.0148\t Train Acc:77.39 %  | \tValid Loss:0.0145 \tValid Acc: 82.94 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0131\t Train Acc:81.00 %  | \tValid Loss:0.0121 \tValid Acc: 85.32 %\n",
      "\n",
      "Validation loss decreased (0.014487 --> 0.012095).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0127\t Train Acc:82.18 %  | \tValid Loss:0.0143 \tValid Acc: 86.01 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0121\t Train Acc:83.62 %  | \tValid Loss:0.0136 \tValid Acc: 84.98 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0111\t Train Acc:84.53 %  | \tValid Loss:0.0111 \tValid Acc: 87.03 %\n",
      "\n",
      "Validation loss decreased (0.012095 --> 0.011064).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0113\t Train Acc:84.60 %  | \tValid Loss:0.0135 \tValid Acc: 83.62 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0110\t Train Acc:85.71 %  | \tValid Loss:0.0122 \tValid Acc: 85.32 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0103\t Train Acc:86.50 %  | \tValid Loss:0.0124 \tValid Acc: 82.94 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0093\t Train Acc:87.94 %  | \tValid Loss:0.0140 \tValid Acc: 76.45 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0089\t Train Acc:88.73 %  | \tValid Loss:0.0117 \tValid Acc: 87.03 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[1 교차검증] Early stopping\n",
      "10-번 레이어\n",
      "../checkpoint/checkpoint_w2v_large_960ft_10-1.pt\n",
      "[1 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0185\t Train Acc:68.74 %  | \tValid Loss:0.0140 \tValid Acc: 81.23 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.013998).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0150\t Train Acc:77.39 %  | \tValid Loss:0.0225 \tValid Acc: 67.24 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0135\t Train Acc:81.00 %  | \tValid Loss:0.0180 \tValid Acc: 73.72 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0121\t Train Acc:84.40 %  | \tValid Loss:0.0151 \tValid Acc: 80.89 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0117\t Train Acc:83.36 %  | \tValid Loss:0.0163 \tValid Acc: 75.43 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0109\t Train Acc:85.06 %  | \tValid Loss:0.0140 \tValid Acc: 81.57 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[1 교차검증] Early stopping\n",
      "11-번 레이어\n",
      "../checkpoint/checkpoint_w2v_large_960ft_11-1.pt\n",
      "[1 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0188\t Train Acc:69.07 %  | \tValid Loss:0.0184 \tValid Acc: 74.40 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.018418).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0150\t Train Acc:77.72 %  | \tValid Loss:0.0152 \tValid Acc: 79.18 %\n",
      "\n",
      "Validation loss decreased (0.018418 --> 0.015218).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0135\t Train Acc:80.21 %  | \tValid Loss:0.0138 \tValid Acc: 83.62 %\n",
      "\n",
      "Validation loss decreased (0.015218 --> 0.013797).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0129\t Train Acc:81.00 %  | \tValid Loss:0.0139 \tValid Acc: 82.25 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0117\t Train Acc:84.01 %  | \tValid Loss:0.0139 \tValid Acc: 82.25 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0113\t Train Acc:84.86 %  | \tValid Loss:0.0186 \tValid Acc: 77.13 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0107\t Train Acc:85.12 %  | \tValid Loss:0.0121 \tValid Acc: 86.35 %\n",
      "\n",
      "Validation loss decreased (0.013797 --> 0.012099).  Saving model ...\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0102\t Train Acc:86.83 %  | \tValid Loss:0.0159 \tValid Acc: 77.13 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0100\t Train Acc:86.76 %  | \tValid Loss:0.0132 \tValid Acc: 86.01 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0096\t Train Acc:87.29 %  | \tValid Loss:0.0125 \tValid Acc: 84.64 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0086\t Train Acc:88.99 %  | \tValid Loss:0.0116 \tValid Acc: 88.40 %\n",
      "\n",
      "Validation loss decreased (0.012099 --> 0.011594).  Saving model ...\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0082\t Train Acc:89.38 %  | \tValid Loss:0.0120 \tValid Acc: 84.30 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0092\t Train Acc:86.70 %  | \tValid Loss:0.0153 \tValid Acc: 80.20 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0083\t Train Acc:89.65 %  | \tValid Loss:0.0165 \tValid Acc: 78.50 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0078\t Train Acc:90.04 %  | \tValid Loss:0.0144 \tValid Acc: 81.91 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0081\t Train Acc:89.45 %  | \tValid Loss:0.0130 \tValid Acc: 86.69 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[1 교차검증] Early stopping\n",
      "12-번 레이어\n",
      "../checkpoint/checkpoint_w2v_large_960ft_12-1.pt\n",
      "[1 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0186\t Train Acc:69.79 %  | \tValid Loss:0.0231 \tValid Acc: 65.19 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.023123).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0152\t Train Acc:78.44 %  | \tValid Loss:0.0245 \tValid Acc: 66.21 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0134\t Train Acc:81.13 %  | \tValid Loss:0.0130 \tValid Acc: 82.25 %\n",
      "\n",
      "Validation loss decreased (0.023123 --> 0.013019).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0132\t Train Acc:81.72 %  | \tValid Loss:0.0127 \tValid Acc: 82.94 %\n",
      "\n",
      "Validation loss decreased (0.013019 --> 0.012699).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0116\t Train Acc:84.80 %  | \tValid Loss:0.0202 \tValid Acc: 72.01 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0113\t Train Acc:85.45 %  | \tValid Loss:0.0182 \tValid Acc: 74.06 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0107\t Train Acc:86.30 %  | \tValid Loss:0.0166 \tValid Acc: 74.74 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0104\t Train Acc:86.37 %  | \tValid Loss:0.0170 \tValid Acc: 74.40 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0098\t Train Acc:87.29 %  | \tValid Loss:0.0264 \tValid Acc: 63.48 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[1 교차검증] Early stopping\n",
      "13-번 레이어\n",
      "../checkpoint/checkpoint_w2v_large_960ft_13-1.pt\n",
      "[1 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0202\t Train Acc:66.84 %  | \tValid Loss:0.0249 \tValid Acc: 65.53 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.024939).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0161\t Train Acc:74.57 %  | \tValid Loss:0.0210 \tValid Acc: 67.58 %\n",
      "\n",
      "Validation loss decreased (0.024939 --> 0.021031).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0144\t Train Acc:79.36 %  | \tValid Loss:0.0136 \tValid Acc: 83.62 %\n",
      "\n",
      "Validation loss decreased (0.021031 --> 0.013572).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0137\t Train Acc:80.47 %  | \tValid Loss:0.0134 \tValid Acc: 81.57 %\n",
      "\n",
      "Validation loss decreased (0.013572 --> 0.013392).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0127\t Train Acc:82.77 %  | \tValid Loss:0.0127 \tValid Acc: 83.96 %\n",
      "\n",
      "Validation loss decreased (0.013392 --> 0.012667).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0120\t Train Acc:83.68 %  | \tValid Loss:0.0150 \tValid Acc: 80.55 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0115\t Train Acc:83.94 %  | \tValid Loss:0.0186 \tValid Acc: 74.74 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0110\t Train Acc:86.11 %  | \tValid Loss:0.0145 \tValid Acc: 84.30 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0108\t Train Acc:85.52 %  | \tValid Loss:0.0141 \tValid Acc: 84.30 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0102\t Train Acc:87.29 %  | \tValid Loss:0.0122 \tValid Acc: 84.30 %\n",
      "\n",
      "Validation loss decreased (0.012667 --> 0.012199).  Saving model ...\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0101\t Train Acc:87.02 %  | \tValid Loss:0.0136 \tValid Acc: 84.64 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0094\t Train Acc:88.47 %  | \tValid Loss:0.0174 \tValid Acc: 79.52 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0094\t Train Acc:87.29 %  | \tValid Loss:0.0126 \tValid Acc: 84.98 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0093\t Train Acc:87.35 %  | \tValid Loss:0.0167 \tValid Acc: 79.52 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0088\t Train Acc:88.20 %  | \tValid Loss:0.0177 \tValid Acc: 75.77 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[1 교차검증] Early stopping\n",
      "14-번 레이어\n",
      "../checkpoint/checkpoint_w2v_large_960ft_14-1.pt\n",
      "[1 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0189\t Train Acc:69.07 %  | \tValid Loss:0.0222 \tValid Acc: 67.92 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.022165).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EPOCH:2]\t Train Loss:0.0152\t Train Acc:77.52 %  | \tValid Loss:0.0263 \tValid Acc: 62.80 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0138\t Train Acc:80.08 %  | \tValid Loss:0.0220 \tValid Acc: 64.16 %\n",
      "\n",
      "Validation loss decreased (0.022165 --> 0.021985).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0129\t Train Acc:82.11 %  | \tValid Loss:0.0158 \tValid Acc: 76.11 %\n",
      "\n",
      "Validation loss decreased (0.021985 --> 0.015850).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0128\t Train Acc:82.50 %  | \tValid Loss:0.0153 \tValid Acc: 79.18 %\n",
      "\n",
      "Validation loss decreased (0.015850 --> 0.015282).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0118\t Train Acc:83.88 %  | \tValid Loss:0.0212 \tValid Acc: 68.60 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0118\t Train Acc:83.88 %  | \tValid Loss:0.0151 \tValid Acc: 79.52 %\n",
      "\n",
      "Validation loss decreased (0.015282 --> 0.015136).  Saving model ...\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0110\t Train Acc:86.37 %  | \tValid Loss:0.0196 \tValid Acc: 72.35 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0104\t Train Acc:86.17 %  | \tValid Loss:0.0170 \tValid Acc: 78.84 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0105\t Train Acc:85.71 %  | \tValid Loss:0.0160 \tValid Acc: 79.52 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0100\t Train Acc:86.37 %  | \tValid Loss:0.0174 \tValid Acc: 77.82 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0096\t Train Acc:86.96 %  | \tValid Loss:0.0149 \tValid Acc: 79.86 %\n",
      "\n",
      "Validation loss decreased (0.015136 --> 0.014862).  Saving model ...\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0093\t Train Acc:87.81 %  | \tValid Loss:0.0221 \tValid Acc: 71.33 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0096\t Train Acc:87.61 %  | \tValid Loss:0.0183 \tValid Acc: 75.09 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0088\t Train Acc:88.07 %  | \tValid Loss:0.0177 \tValid Acc: 78.50 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0086\t Train Acc:89.12 %  | \tValid Loss:0.0224 \tValid Acc: 69.28 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0086\t Train Acc:88.93 %  | \tValid Loss:0.0155 \tValid Acc: 78.16 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[1 교차검증] Early stopping\n",
      "15-번 레이어\n",
      "../checkpoint/checkpoint_w2v_large_960ft_15-1.pt\n",
      "[1 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0182\t Train Acc:69.72 %  | \tValid Loss:0.0236 \tValid Acc: 62.46 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.023575).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0153\t Train Acc:76.61 %  | \tValid Loss:0.0160 \tValid Acc: 76.45 %\n",
      "\n",
      "Validation loss decreased (0.023575 --> 0.016040).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0139\t Train Acc:80.93 %  | \tValid Loss:0.0185 \tValid Acc: 74.74 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0131\t Train Acc:81.45 %  | \tValid Loss:0.0195 \tValid Acc: 71.33 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0127\t Train Acc:83.62 %  | \tValid Loss:0.0215 \tValid Acc: 69.97 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0115\t Train Acc:85.19 %  | \tValid Loss:0.0145 \tValid Acc: 80.89 %\n",
      "\n",
      "Validation loss decreased (0.016040 --> 0.014525).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0112\t Train Acc:85.12 %  | \tValid Loss:0.0171 \tValid Acc: 77.82 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0110\t Train Acc:84.93 %  | \tValid Loss:0.0162 \tValid Acc: 80.89 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0104\t Train Acc:85.71 %  | \tValid Loss:0.0175 \tValid Acc: 78.16 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0103\t Train Acc:87.09 %  | \tValid Loss:0.0144 \tValid Acc: 79.86 %\n",
      "\n",
      "Validation loss decreased (0.014525 --> 0.014351).  Saving model ...\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0099\t Train Acc:86.63 %  | \tValid Loss:0.0167 \tValid Acc: 79.52 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0094\t Train Acc:89.19 %  | \tValid Loss:0.0217 \tValid Acc: 71.67 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0093\t Train Acc:88.07 %  | \tValid Loss:0.0155 \tValid Acc: 79.18 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0093\t Train Acc:87.68 %  | \tValid Loss:0.0160 \tValid Acc: 78.84 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0087\t Train Acc:87.88 %  | \tValid Loss:0.0135 \tValid Acc: 80.89 %\n",
      "\n",
      "Validation loss decreased (0.014351 --> 0.013488).  Saving model ...\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0084\t Train Acc:89.45 %  | \tValid Loss:0.0238 \tValid Acc: 70.31 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0088\t Train Acc:89.32 %  | \tValid Loss:0.0163 \tValid Acc: 78.16 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0078\t Train Acc:90.24 %  | \tValid Loss:0.0143 \tValid Acc: 80.20 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0077\t Train Acc:90.83 %  | \tValid Loss:0.0237 \tValid Acc: 72.01 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:20]\t Train Loss:0.0074\t Train Acc:91.02 %  | \tValid Loss:0.0147 \tValid Acc: 79.86 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[1 교차검증] Early stopping\n",
      "16-번 레이어\n",
      "../checkpoint/checkpoint_w2v_large_960ft_16-1.pt\n",
      "[1 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0187\t Train Acc:69.46 %  | \tValid Loss:0.0215 \tValid Acc: 66.89 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.021533).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0154\t Train Acc:77.00 %  | \tValid Loss:0.0222 \tValid Acc: 68.60 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0138\t Train Acc:79.55 %  | \tValid Loss:0.0293 \tValid Acc: 62.46 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:76] data. DefaultCPUAllocator: not enough memory: you tried to allocate 13049728 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17524/2652233244.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mEpoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_accuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m31\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mvalid_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17524/1069386869.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(model, valid_loader)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#no_grad : 그래디언트 값 계산 막기.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\local_torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\local_torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\local_torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\local_torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\local_torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\local_torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'numpy'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'string_'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:76] data. DefaultCPUAllocator: not enough memory: you tried to allocate 13049728 bytes."
     ]
    }
   ],
   "source": [
    "#10. 학습 및 평가.\n",
    "# kfold 적용\n",
    "train_accs = []\n",
    "valid_accs = []\n",
    "for num in range(24):\n",
    "    print(\"{}-번 레이어\".format(num))\n",
    "\n",
    "\n",
    "    for data_ind in range(1,2):\n",
    "\n",
    "        check_path = '../checkpoint/checkpoint_w2v_large_960ft_'+str(num)+'-'+str(data_ind)+'.pt'\n",
    "        print(check_path)\n",
    "        early_stopping = EarlyStopping(patience = 5, verbose = True, path=check_path)\n",
    "        train_loader,validation_loader = load_data(data_ind-1)\n",
    "\n",
    "        best_train_acc=0 # accuracy 기록용\n",
    "        best_valid_acc=0\n",
    "\n",
    "        model=model_initialize(num)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)\n",
    "\n",
    "\n",
    "        print(\"[{} 교차검증] 학습 시작\\n ----- \".format(data_ind))\n",
    "        for Epoch in range(1,EPOCHS+1):\n",
    "            train_loss,train_accuracy=train(model,train_loader,optimizer,log_interval=31)\n",
    "            valid_loss,valid_accuracy = evaluate(model, validation_loader)\n",
    "\n",
    "\n",
    "            print(\"\\n[EPOCH:{}]\\t Train Loss:{:.4f}\\t Train Acc:{:.2f} %  | \\tValid Loss:{:.4f} \\tValid Acc: {:.2f} %\\n\".\n",
    "                  format(Epoch,train_loss,train_accuracy,valid_loss,valid_accuracy))\n",
    "            \n",
    "\n",
    "            early_stopping(valid_loss, model)\n",
    "            if -early_stopping.best_score == valid_loss:\n",
    "                best_train_acc, best_valid_acc = train_accuracy,valid_accuracy\n",
    "\n",
    "            if early_stopping.early_stop:\n",
    "                    train_accs.append(best_train_acc)\n",
    "                    valid_accs.append(best_valid_acc)\n",
    "                    print(\"[{} 교차검증] Early stopping\".format(data_ind))\n",
    "                    break\n",
    "\n",
    "            if Epoch==EPOCHS:\n",
    "                #만약 early stop 없이 40 epoch라서 중지 된 경우.\n",
    "                train_accs.append(best_train_acc)\n",
    "                valid_accs.append(best_valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1744b53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번 모델. train :84.4037/ valid: 83.6177\n",
      "2번 모델. train :86.8938/ valid: 87.0307\n",
      "3번 모델. train :88.2700/ valid: 86.0068\n",
      "4번 모델. train :80.3408/ valid: 82.5939\n",
      "5번 모델. train :83.8794/ valid: 82.9352\n",
      "6번 모델. train :91.5465/ valid: 87.0307\n",
      "7번 모델. train :87.8768/ valid: 86.0068\n",
      "8번 모델. train :83.1586/ valid: 83.9590\n",
      "9번 모델. train :86.3041/ valid: 86.6894\n",
      "10번 모델. train :84.5347/ valid: 87.0307\n",
      "11번 모델. train :68.7418/ valid: 81.2287\n",
      "12번 모델. train :88.9908/ valid: 88.3959\n",
      "13번 모델. train :81.7169/ valid: 82.9352\n",
      "14번 모델. train :87.2870/ valid: 84.3003\n",
      "15번 모델. train :86.9594/ valid: 79.8635\n",
      "16번 모델. train :87.8768/ valid: 80.8874\n"
     ]
    }
   ],
   "source": [
    "for num,valid in enumerate(valid_accs):\n",
    "    print(\"{}번 모델. train :{:.4f}/ valid: {:.4f}\".format(num+1,train_accs[num],valid) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afd88307",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'train':train_accs,'vaild':valid_accs},).to_csv(\"./result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "485b74d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번 모델\n",
      "Accuracy : 84.1530% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.8884\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.8661\n",
      "f score : 0.8270 \n",
      "[[207  32]\n",
      " [ 26 101]]\n",
      "-----\n",
      "2번 모델\n",
      "Accuracy : 86.3388% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.9021\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.8870\n",
      "f score : 0.8504 \n",
      "[[212  27]\n",
      " [ 23 104]]\n",
      "-----\n",
      "3번 모델\n",
      "Accuracy : 85.2459% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.8936\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.8787\n",
      "f score : 0.8384 \n",
      "[[210  29]\n",
      " [ 25 102]]\n",
      "-----\n",
      "4번 모델\n",
      "Accuracy : 81.4208% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.9014\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.8033\n",
      "f score : 0.8034 \n",
      "[[192  47]\n",
      " [ 21 106]]\n",
      "-----\n",
      "5번 모델\n",
      "Accuracy : 81.9672% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.9220\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.7908\n",
      "f score : 0.8111 \n",
      "[[189  50]\n",
      " [ 16 111]]\n",
      "-----\n",
      "6번 모델\n",
      "Accuracy : 84.6995% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.8927\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.8703\n",
      "f score : 0.8330 \n",
      "[[208  31]\n",
      " [ 25 102]]\n",
      "-----\n",
      "7번 모델\n",
      "Accuracy : 83.3333% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.9083\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.8285\n",
      "f score : 0.8224 \n",
      "[[198  41]\n",
      " [ 20 107]]\n",
      "-----\n",
      "8번 모델\n",
      "Accuracy : 81.4208% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.9171\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.7866\n",
      "f score : 0.8054 \n",
      "[[188  51]\n",
      " [ 17 110]]\n",
      "-----\n",
      "9번 모델\n",
      "Accuracy : 83.8798% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.8814\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.8703\n",
      "f score : 0.8231 \n",
      "[[208  31]\n",
      " [ 28  99]]\n",
      "-----\n",
      "10번 모델\n",
      "Accuracy : 84.4262% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.8669\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.8996\n",
      "f score : 0.8252 \n",
      "[[215  24]\n",
      " [ 33  94]]\n",
      "-----\n",
      "11번 모델\n",
      "Accuracy : 79.7814% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.8603\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.8243\n",
      "f score : 0.7808 \n",
      "[[197  42]\n",
      " [ 32  95]]\n",
      "-----\n",
      "12번 모델\n",
      "Accuracy : 83.0601% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.8933\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.8410\n",
      "f score : 0.8175 \n",
      "[[201  38]\n",
      " [ 24 103]]\n",
      "-----\n",
      "13번 모델\n",
      "Accuracy : 81.1475% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.9126\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.7866\n",
      "f score : 0.8023 \n",
      "[[188  51]\n",
      " [ 18 109]]\n",
      "-----\n",
      "14번 모델\n",
      "Accuracy : 81.9672% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.8986\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.8159\n",
      "f score : 0.8081 \n",
      "[[195  44]\n",
      " [ 22 105]]\n",
      "-----\n",
      "15번 모델\n",
      "Accuracy : 81.6940% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.9388\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.7699\n",
      "f score : 0.8102 \n",
      "[[184  55]\n",
      " [ 12 115]]\n",
      "-----\n",
      "16번 모델\n",
      "Accuracy : 80.8743% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.9204\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.7741\n",
      "f score : 0.8006 \n",
      "[[185  54]\n",
      " [ 16 111]]\n",
      "-----\n",
      "17번 모델\n",
      "Accuracy : 68.0328% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.9420\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.5439\n",
      "f score : 0.6800 \n",
      "[[130 109]\n",
      " [  8 119]]\n",
      "-----\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../checkpoint/checkpoint_w2v_large_960ft_17-1.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17524/641572437.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17524/1780486567.py\u001b[0m in \u001b[0;36mtest_grid\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mcheck_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../checkpoint/checkpoint_w2v_large_960ft_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_ind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.pt'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheck_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0manswers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\local_torch\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    595\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m             \u001b[1;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\local_torch\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\local_torch\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../checkpoint/checkpoint_w2v_large_960ft_17-1.pt'"
     ]
    }
   ],
   "source": [
    "test_grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67a7256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix (resnet18)\n",
    "# kfold의 confusion matrix는 계산 방법이 다르다.\n",
    "# 모델을 각각 불러와서 test set을 평가한다.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "cf = np.zeros((2,2))\n",
    "cf_list = []\n",
    "average_accuracy = 0\n",
    "average_fscore = 0\n",
    "\n",
    "for data_ind in range(1,6):\n",
    "\n",
    "    check_path = '../checkpoint/checkpoint_w2v_'+str(data_ind)+'.pt'\n",
    "    model.load_state_dict(torch.load(check_path))\n",
    "\n",
    "    predictions,answers = test_evaluate(model, test_loader)\n",
    "    predictions=[ dat.cpu().numpy() for dat in predictions]\n",
    "    answers=[ dat.cpu().numpy() for dat in answers]\n",
    "\n",
    "    \n",
    "    cf = confusion_matrix(answers, predictions)\n",
    "    cf_list.append(cf)\n",
    "    \n",
    "    acc = (cf[0,0]+cf[1,1])/(cf[0,0]+cf[0,1]+cf[1,0]+cf[1,1])\n",
    "    average_accuracy+=acc\n",
    "    precision=cf[0,0]/(cf[0,0]+cf[1,0])\n",
    "    recall=cf[0,0]/(cf[0,0]+cf[0,1])\n",
    "    #fscore=2*precision*recall/(precision+recall)\n",
    "    \n",
    "    #fscroe macro추가\n",
    "    fscore = f1_score(answers,predictions,average='macro')\n",
    "    average_fscore+=fscore\n",
    "    \n",
    "    print('{}번 모델'.format(data_ind))\n",
    "    print(\"Accuracy : {:.4f}% \".format(acc*100))\n",
    "    print(\"Precision (pathology 예측한 것중 맞는 것) : {:.4f}\".format(precision))\n",
    "    print(\"recall (실제 pathology 중  예측이 맞는 것) : {:.4f}\".format(recall))\n",
    "    print(\"f score : {:.4f} \".format(fscore))\n",
    "    print(cf)\n",
    "    print(\"-----\")\n",
    "\n",
    "print(\"평균 acc : {:.4f}\".format(average_accuracy/5))\n",
    "print(\"평균 f1score : {:.4f}\".format(average_fscore/5))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
