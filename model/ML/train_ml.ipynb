{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import wandb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "\n",
    "\n",
    "import torchaudio\n",
    "import json\n",
    "#import torchaudio.functional as F\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# # SVD 문장 데이터에서 Feature 추출\n",
    "# - mfcc\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import librosa, librosa.display \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "#window sizde : FFT를 할때 참조할 그래프 길이 ( 프레임 하나당 sample 수 )\n",
    "#자연어 처리에서는 25ms 사용. https://ahnjg.tistory.com/93\n",
    "#초당 50000hz 중 1250개씩 윈도우 사이즈로 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "call(): incompatible function arguments. The following argument types are supported:\n    1. (command: str, *args, **kwargs) -> object\n    2. (object: parselmouth.Data, command: str, *args, **kwargs) -> object\n    3. (objects: List[parselmouth.Data], command: str, *args, **kwargs) -> object\n\nInvoked with: array([355.18925059, 349.85953346, 356.67431755, 368.36875366,\n       371.84044567,   0.        ,   0.        , 395.28120023,\n       388.17353849, 376.4608266 , 364.81307885, 353.17761733,\n       341.21335322, 310.40877566, 301.9158425 , 590.0317612 ,\n       576.73198157, 565.91866035, 556.48471478, 546.52645592,\n       542.98532396, 546.63551699, 548.24165028, 514.80099036,\n       511.37553029, 510.9539423 , 503.51026941, 489.58728297,\n       472.8141709 , 248.56466476, 255.43849019, 254.53993892,\n         0.        ,   0.        , 319.02414165, 351.02354443,\n       367.33029635, 376.91096841, 376.40668096,   0.        ,\n         0.        , 322.3043507 , 320.88922922, 316.44058416,\n       315.58877867, 314.4846776 , 312.61956079,   0.        ,\n         0.        ,   0.        ,   0.        ,   0.        ,\n         0.        ,   0.        ,   0.        ,   0.        ,\n       537.20090439, 507.04616005, 485.66429433, 469.29331246,\n       460.57864269, 459.49052812, 450.7811097 , 444.6015754 ,\n       443.12486044, 451.07443732, 460.4483004 , 484.41523996,\n       499.0576561 , 503.93395949]), 'To Sound: To Harmonicity (cc): 0.01 50 0.1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11752/338762624.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Calculate GNE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mgne\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparselmouth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpraat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglottal_source\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"To Sound: To Harmonicity (cc): 0.01 50 0.1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mgne_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: call(): incompatible function arguments. The following argument types are supported:\n    1. (command: str, *args, **kwargs) -> object\n    2. (object: parselmouth.Data, command: str, *args, **kwargs) -> object\n    3. (objects: List[parselmouth.Data], command: str, *args, **kwargs) -> object\n\nInvoked with: array([355.18925059, 349.85953346, 356.67431755, 368.36875366,\n       371.84044567,   0.        ,   0.        , 395.28120023,\n       388.17353849, 376.4608266 , 364.81307885, 353.17761733,\n       341.21335322, 310.40877566, 301.9158425 , 590.0317612 ,\n       576.73198157, 565.91866035, 556.48471478, 546.52645592,\n       542.98532396, 546.63551699, 548.24165028, 514.80099036,\n       511.37553029, 510.9539423 , 503.51026941, 489.58728297,\n       472.8141709 , 248.56466476, 255.43849019, 254.53993892,\n         0.        ,   0.        , 319.02414165, 351.02354443,\n       367.33029635, 376.91096841, 376.40668096,   0.        ,\n         0.        , 322.3043507 , 320.88922922, 316.44058416,\n       315.58877867, 314.4846776 , 312.61956079,   0.        ,\n         0.        ,   0.        ,   0.        ,   0.        ,\n         0.        ,   0.        ,   0.        ,   0.        ,\n       537.20090439, 507.04616005, 485.66429433, 469.29331246,\n       460.57864269, 459.49052812, 450.7811097 , 444.6015754 ,\n       443.12486044, 451.07443732, 460.4483004 , 484.41523996,\n       499.0576561 , 503.93395949]), 'To Sound: To Harmonicity (cc): 0.01 50 0.1'"
     ]
    }
   ],
   "source": [
    "# import parselmouth\n",
    "# def load_data(path):\n",
    "#     with open(path, 'rb') as f:\n",
    "#         data = pickle.load(f)\n",
    "#     return data\n",
    "\n",
    "# phrase=load_data(\"../../voice_data/all_data_ver2/phrase_dict_ver2_all.pickle\")\n",
    "\n",
    "# # Load the audio file using Parselmouth\n",
    "# snd = parselmouth.Sound(phrase[\"1-phrase.wav\"])\n",
    "# #snd = phrase[\"1-phrase.wav\"]\n",
    "\n",
    "# # Extract the glottal source waveform\n",
    "# glottal_source = snd.to_pitch().selected_array['frequency']\n",
    "\n",
    "# # Calculate GNE\n",
    "# gne = parselmouth.praat.call(glottal_source, \"To Sound: To Harmonicity (cc): 0.01 50 0.1\")\n",
    "# gne_values = gne.to_array()[0]\n",
    "\n",
    "# # Calculate GQ\n",
    "# gq_closed = parselmouth.praat.call(glottal_source, \"To Sound (slice): 0 0 0.01\")\n",
    "# gq_open = parselmouth.praat.call(glottal_source, \"To Sound (slice): 0 0.5 0.01\")\n",
    "# gq_closed_values = gq_closed.to_array()[0]\n",
    "# gq_open_values = gq_open.to_array()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cv', 'error_score', 'estimator__C', 'estimator__break_ties', 'estimator__cache_size', 'estimator__class_weight', 'estimator__coef0', 'estimator__decision_function_shape', 'estimator__degree', 'estimator__gamma', 'estimator__kernel', 'estimator__max_iter', 'estimator__probability', 'estimator__random_state', 'estimator__shrinking', 'estimator__tol', 'estimator__verbose', 'estimator', 'n_jobs', 'param_grid', 'pre_dispatch', 'refit', 'return_train_score', 'scoring', 'verbose'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.model_selection import PredefinedSplit\n",
    "# import joblib\n",
    "\n",
    "# model = SVC(kernel='linear', C=1.0, random_state=0)\n",
    "\n",
    "# param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "# param_grid = [\n",
    "#     {'clf__C': param_range,},]\n",
    "# grid_search = GridSearchCV(model, param_grid=param_grid,n_jobs=-1)\n",
    "# grid_search.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=pd.read_excel('D:/project/voice_pathology_ai/voice_data/all_data_ver2.xlsx')\n",
    "organics_data=pd.read_excel('D:/project/voice_pathology_ai/voice_data/only_organics_healthy_available_ver2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\local_torch\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "# classifier\n",
    "from xgboost import XGBClassifier\n",
    "# import svm classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### paths\n",
    "from Dataset.cv_spliter import cv_spliter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pickle to load data which path is \"../../voice_data/all_data_ver2/phrase_dict_ver2_all.pickle\"\n",
    "def load_data(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "phrase=load_data(\"../../voice_data/all_data_ver2/phrase_dict_ver2_all.pickle\")\n",
    "DataFrame=pd.read_excel(\"../../voice_data/all_data_ver2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426\n",
      "630\n",
      "총 데이터수 :  1056\n",
      "---\n",
      "훈련 셋 :  844 Counter({'healthy': 504, 'pathology': 340})\n",
      "테스트 셋 :  212 Counter({'healthy': 126, 'pathology': 86})\n",
      "---\n",
      "교차 검증 : 1\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 403, 'pathology': 272}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 101, 'pathology': 68} \n",
      "\n",
      "교차 검증 : 2\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 403, 'pathology': 272}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 101, 'pathology': 68} \n",
      "\n",
      "교차 검증 : 3\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 403, 'pathology': 272}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 101, 'pathology': 68} \n",
      "\n",
      "교차 검증 : 4\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 403, 'pathology': 272}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 101, 'pathology': 68} \n",
      "\n",
      "교차 검증 : 5\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 404, 'pathology': 272}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 100, 'pathology': 68} \n",
      "\n",
      "train. speaker to voice\n",
      "valid. speaker to voice\n",
      "test. speaker to voice\n",
      "\n",
      " fold0 \n",
      "before dataset shape Counter({'healthy': 406, 'pathology': 364})\n",
      "Resampled dataset shape Counter({'healthy': 406, 'pathology': 406})\n",
      "\n",
      " fold1 \n",
      "before dataset shape Counter({'healthy': 407, 'pathology': 402})\n",
      "Resampled dataset shape Counter({'healthy': 407, 'pathology': 407})\n",
      "\n",
      " fold2 \n",
      "before dataset shape Counter({'healthy': 407, 'pathology': 384})\n",
      "Resampled dataset shape Counter({'healthy': 407, 'pathology': 407})\n",
      "\n",
      " fold3 \n",
      "before dataset shape Counter({'healthy': 407, 'pathology': 396})\n",
      "Resampled dataset shape Counter({'healthy': 407, 'pathology': 407})\n",
      "\n",
      " fold4 \n",
      "before dataset shape Counter({'healthy': 405, 'pathology': 394})\n",
      "Resampled dataset shape Counter({'pathology': 405, 'healthy': 405})\n"
     ]
    }
   ],
   "source": [
    "random_state=1004\n",
    "speaker_file_path = \"../../voice_data/only_organics_healthy_available_ver2.xlsx\" # 퓨전셋에 맞게 01.10 수정\n",
    "speaker_file_path_abs = os.path.abspath(speaker_file_path)\n",
    "data_probs=0\n",
    "\n",
    "X_train_list, X_valid_list, X_test, Y_train_list, Y_valid_list, Y_test = cv_spliter(random_state, speaker_file_path_abs, data_probs=data_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write function which transforms list [[1,7,8],[1,2,3,4,5]] -> [[\"1-phrase.wav\", \"7-phrase.wav\", \"8-phrase.wav\"], [\"1-phrase.wav\", \"2-phrase.wav\", \"3-phrase.wav\", \"4-phrase.wav\", \"5-phrase.wav\"]]\n",
    "def list_to_path(list,dataset):\n",
    "    path_list=[]\n",
    "    for i in list:\n",
    "        path_list.append([str(j)+\"-\"+dataset+\".wav\" for j in i])\n",
    "    return path_list\n",
    "\n",
    "# write function which transforms list [1,7,8] -> [\"1-phrase.wav\", \"7-phrase.wav\", \"8-phrase.wav\"]\n",
    "def list_to_path2(list,dataset):\n",
    "    path_list=[]\n",
    "    for i in list:\n",
    "        path_list.append(str(i)+\"-\"+dataset+\".wav\")\n",
    "    return path_list\n",
    "\n",
    "X_train_list=list_to_path(X_train_list,'phrase')\n",
    "X_valid_list=list_to_path(X_valid_list,'phrase')\n",
    "X_test=list_to_path2(X_test,'phrase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistical_feature(feature_vec):\n",
    "    mean = np.mean(feature_vec)\n",
    "    std = np.std(feature_vec) \n",
    "    maxv = np.amax(feature_vec) \n",
    "    minv = np.amin(feature_vec) \n",
    "    median = np.median(feature_vec)\n",
    "    skew = scipy.stats.skew(feature_vec)\n",
    "    kurt = scipy.stats.kurtosis(feature_vec)\n",
    "    q1 = np.quantile(feature_vec, 0.25)\n",
    "    q3 = np.quantile(feature_vec, 0.75)\n",
    "    mode = scipy.stats.mode(feature_vec)[0][0]\n",
    "    iqr = scipy.stats.iqr(feature_vec)\n",
    "\n",
    "    return [mean, std, maxv, minv, median, skew, kurt, q1, q3, mode, iqr]\n",
    "\n",
    "\n",
    "def load_audio_dataset(audio_files,sr=16000):\n",
    "    \"\"\"\n",
    "    Load audio dataset and extract features.\n",
    "    \"\"\"\n",
    "    # Load audio files and extract features\n",
    "    X = []\n",
    "    y = []\n",
    "    # Replace this with your own logic to load audio files and their corresponding labels\n",
    "\n",
    "    # Loop through each audio file\n",
    "    for audio_path in tqdm(audio_files):\n",
    "        # Load audio file\n",
    "        audio = phrase[audio_path]\n",
    "\n",
    "        # Extract F0 using pitch detection (e.g., yin)\n",
    "        f0 = librosa.yin(audio, fmin=librosa.note_to_hz('C2'), fmax=librosa.note_to_hz('C7'), frame_length=1024, hop_length=512)\n",
    "        amplitude = librosa.feature.rms(y=audio, frame_length=1024, hop_length=512)\n",
    "        # Extract Jitter\n",
    "        jitter = (abs(f0[1:] - f0[:-1]).mean() / f0.mean()) * 100\n",
    "        # Extract Shimmer\n",
    "\n",
    "        shimmer = 20*abs(np.log10(amplitude[0][1:]/amplitude[0][:-1])).mean()\n",
    "        # Extract HNR (Harmonic-to-Noise Ratio)\n",
    "        hnr = librosa.effects.harmonic(audio)\n",
    "        \n",
    "        # Extract 13 MFCC (Mel-frequency cepstral coefficients)\n",
    "        mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "\n",
    "        # Extract first and second derivatives of MFCC\n",
    "        mfcc_delta = librosa.feature.delta(mfcc)\n",
    "        mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "\n",
    "        # Concatenate all features into a single feature vector\n",
    "        features = np.concatenate([statistical_feature(f0), #[jitter], [shimmer], \n",
    "                                   statistical_feature(hnr),statistical_feature(mfcc.flatten()), statistical_feature(mfcc_delta.flatten()), statistical_feature(mfcc_delta2.flatten()) ], axis=0)\n",
    "\n",
    "        # Append feature vector and label to X and y, respectively\n",
    "        #print(features.shape)\n",
    "        X.append(features)\n",
    "\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 237/237 [00:14<00:00, 16.35it/s]\n",
      "100%|██████████| 812/812 [00:49<00:00, 16.29it/s]\n",
      "100%|██████████| 223/223 [00:13<00:00, 16.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold valid:  0\n",
      "Accuracy:  0.7623318385650224\n",
      "F1 score:  0.7618529488806947\n",
      "Recall:  0.7843137254901961\n",
      "Specificity:  0.743801652892562\n",
      "UAR score:  0.7640576891913791\n",
      "Confusion matrix: \n",
      " [[80 22]\n",
      " [31 90]]\n",
      "--------------------\n",
      "Fold test:  0\n",
      "Accuracy:  0.7805907172995781\n",
      "F1 score:  0.7791714449541284\n",
      "Recall:  0.8095238095238095\n",
      "Specificity:  0.7477477477477478\n",
      "UAR score:  0.7786357786357787\n",
      "Confusion matrix:  [[102  24]\n",
      " [ 28  83]]\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 814/814 [00:49<00:00, 16.54it/s]\n",
      "100%|██████████| 184/184 [00:10<00:00, 16.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold valid:  1\n",
      "Accuracy:  0.75\n",
      "F1 score:  0.7440735365263667\n",
      "Recall:  0.8217821782178217\n",
      "Specificity:  0.6626506024096386\n",
      "UAR score:  0.7422163903137302\n",
      "Confusion matrix: \n",
      " [[83 18]\n",
      " [28 55]]\n",
      "--------------------\n",
      "Fold test:  1\n",
      "Accuracy:  0.7426160337552743\n",
      "F1 score:  0.7378366125668692\n",
      "Recall:  0.8253968253968254\n",
      "Specificity:  0.6486486486486487\n",
      "UAR score:  0.737022737022737\n",
      "Confusion matrix:  [[104  22]\n",
      " [ 39  72]]\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 814/814 [00:49<00:00, 16.54it/s]\n",
      "100%|██████████| 202/202 [00:12<00:00, 16.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold valid:  2\n",
      "Accuracy:  0.7376237623762376\n",
      "F1 score:  0.7374629098310405\n",
      "Recall:  0.7128712871287128\n",
      "Specificity:  0.7623762376237624\n",
      "UAR score:  0.7376237623762376\n",
      "Confusion matrix: \n",
      " [[72 29]\n",
      " [24 77]]\n",
      "--------------------\n",
      "Fold test:  2\n",
      "Accuracy:  0.7552742616033755\n",
      "F1 score:  0.7540085898353616\n",
      "Recall:  0.7777777777777778\n",
      "Specificity:  0.7297297297297297\n",
      "UAR score:  0.7537537537537538\n",
      "Confusion matrix:  [[98 28]\n",
      " [30 81]]\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 814/814 [00:49<00:00, 16.59it/s]\n",
      "100%|██████████| 190/190 [00:11<00:00, 16.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold valid:  3\n",
      "Accuracy:  0.7631578947368421\n",
      "F1 score:  0.7602288342353964\n",
      "Recall:  0.8217821782178217\n",
      "Specificity:  0.6966292134831461\n",
      "UAR score:  0.7592056958504839\n",
      "Confusion matrix: \n",
      " [[83 18]\n",
      " [27 62]]\n",
      "--------------------\n",
      "Fold test:  3\n",
      "Accuracy:  0.7468354430379747\n",
      "F1 score:  0.7448320413436693\n",
      "Recall:  0.7857142857142857\n",
      "Specificity:  0.7027027027027027\n",
      "UAR score:  0.7442084942084942\n",
      "Confusion matrix:  [[99 27]\n",
      " [33 78]]\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 810/810 [00:49<00:00, 16.34it/s]\n",
      "100%|██████████| 194/194 [00:11<00:00, 16.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold valid:  4\n",
      "Accuracy:  0.8092783505154639\n",
      "F1 score:  0.8092327318149201\n",
      "Recall:  0.7766990291262136\n",
      "Specificity:  0.8461538461538461\n",
      "UAR score:  0.8114264376400299\n",
      "Confusion matrix: \n",
      " [[80 23]\n",
      " [14 77]]\n",
      "--------------------\n",
      "Fold test:  4\n",
      "Accuracy:  0.759493670886076\n",
      "F1 score:  0.7588755020080322\n",
      "Recall:  0.7619047619047619\n",
      "Specificity:  0.7567567567567568\n",
      "UAR score:  0.7593307593307593\n",
      "Confusion matrix:  [[96 30]\n",
      " [27 84]]\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "X_test_data = load_audio_dataset(X_test,16000)\n",
    "\n",
    "for i in range(len(X_train_list)):\n",
    "    X_train_list_data=load_audio_dataset(X_train_list[i],16000)\n",
    "    X_valid_list_data=load_audio_dataset(X_valid_list[i],16000)\n",
    "    \n",
    "\n",
    "    # svm classifier fit X_train_list_data and Y_train_list[i]\n",
    "    svm = SVC(kernel='linear', C=1, random_state=0)\n",
    "    svm.fit(X_train_list_data, Y_train_list[i])\n",
    "    # save svm checkpoint\n",
    "    #with open('./checkpoint/svm_checkpoint_'+str(i)+'.pkl', 'wb') as f:\n",
    "    #    pickle.dump(svm, f)\n",
    "    # \n",
    "    # Test onto X_valid_list_data\n",
    "    y_pred = svm.predict(X_valid_list_data)\n",
    "    # Calculate accuracy score\n",
    "    acc = accuracy_score(Y_valid_list[i], y_pred)\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(Y_valid_list[i], y_pred, average='macro')\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(Y_valid_list[i], y_pred)\n",
    "\n",
    "    print(\"Fold valid: \", i)\n",
    "    print(\"Accuracy: \", acc)\n",
    "    print(\"F1 score: \", f1)\n",
    "    print(\"Recall: \", cm[0][0]/(cm[0][0]+cm[0][1]))\n",
    "    print(\"Specificity: \", cm[1][1]/(cm[1][0]+cm[1][1]))\n",
    "    #UAR score. half of recall and specificity\n",
    "    print(\"UAR score: \", (cm[0][0]/(cm[0][0]+cm[0][1])+cm[1][1]/(cm[1][0]+cm[1][1]))/2)\n",
    "    print(\"Confusion matrix: \\n\", cm)\n",
    "    print(\"--------------------\")\n",
    "\n",
    "    # Test onto X_test_data\n",
    "    y_pred = svm.predict(X_test_data)\n",
    "    # Calculate accuracy score\n",
    "    acc = accuracy_score(Y_test, y_pred)\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(Y_test, y_pred, average='macro')\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(Y_test, y_pred)\n",
    "    print(\"Fold test: \", i)\n",
    "    print(\"Accuracy: \", acc)\n",
    "    print(\"F1 score: \", f1)\n",
    "    print(\"Recall: \", cm[0][0]/(cm[0][0]+cm[0][1]))\n",
    "    print(\"Specificity: \", cm[1][1]/(cm[1][0]+cm[1][1]))\n",
    "    #UAR score. half of recall and specificity\n",
    "    print(\"UAR score: \", (cm[0][0]/(cm[0][0]+cm[0][1])+cm[1][1]/(cm[1][0]+cm[1][1]))/2)\n",
    "    print(\"Confusion matrix: \", cm)    \n",
    "    print(\"--------------------\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
