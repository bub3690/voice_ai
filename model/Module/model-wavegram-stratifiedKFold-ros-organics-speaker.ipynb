{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6505136e",
   "metadata": {},
   "source": [
    "- http://keunwoochoi.blogspot.com/2016/03/2.html\n",
    "- http://www.rex-ai.info/docs/AI_Example_CNN_speech_recognize\n",
    "- https://www.youtube.com/watch?v=oltGIc4uo5c\n",
    "- https://youdaeng-com.tistory.com/5\n",
    "- https://quokkas.tistory.com/37 : early stopping\n",
    "- https://continuous-development.tistory.com/166 : stratified kfold\n",
    "- https://deep-learning-study.tistory.com/476 fiter 시각화\n",
    "- https://wyatt37.tistory.com/10 : random over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20cf3fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:7cgd00tp) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25b913804bf43108926b3d6f95de561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">wise-sea-729</strong>: <a href=\"https://wandb.ai/bub3690/SVD-voice-disorder/runs/7cgd00tp\" target=\"_blank\">https://wandb.ai/bub3690/SVD-voice-disorder/runs/7cgd00tp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230119_131928-7cgd00tp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:7cgd00tp). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\project\\voice_pathology_ai\\model\\Module\\wandb\\run-20230119_131944-273klz44</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/bub3690/SVD-voice-disorder/runs/273klz44\" target=\"_blank\">pious-dragon-730</a></strong> to <a href=\"https://wandb.ai/bub3690/SVD-voice-disorder\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project=\"SVD-voice-disorder\", entity=\"bub3690\",settings=wandb.Settings(_disable_stats=True))\n",
    "wandb.run.name = 'wavegram-organics-speaker'\n",
    "wandb.run.name = 'resnet-attention-organics-speaker'\n",
    "wandb.run.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "275b8092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pytorch version :  1.10.2  Device :  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn # 인공 신경망 모델들 모아놓은 모듈\n",
    "import torch.nn.functional as F #그중 자주 쓰이는것들을 F로\n",
    "from torchvision import transforms, datasets\n",
    "import cv2\n",
    "from torchvision import transforms, datasets\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "\n",
    "from Utils.pytorchtools import EarlyStopping # 상위 폴더에 추가된 모듈.\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "#DEVICE = torch.device('cpu')\n",
    "print('Using Pytorch version : ',torch.__version__,' Device : ',DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0081a011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1dd92236430>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchaudio\n",
    "#import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ebea6",
   "metadata": {},
   "source": [
    "# SVD 문장 데이터에서 Feature 추출\n",
    "- mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dddaab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa, librosa.display \n",
    "import matplotlib.pyplot as plt\n",
    "#window sizde : FFT를 할때 참조할 그래프 길이 ( 프레임 하나당 sample 수 )\n",
    "#자연어 처리에서는 25ms 사용. https://ahnjg.tistory.com/93\n",
    "#초당 50000hz 중 1250개씩 윈도우 사이즈로 사용.\n",
    "\n",
    "\n",
    "#default param\n",
    "mfcc_run_config = dict(\n",
    "    sr=16000,\n",
    "    n_mfcc=27,\n",
    "    #dct_type=3, # type2 default\n",
    "    lifter = 35,\n",
    "\n",
    "    \n",
    "    #mel spectro\n",
    "    n_mels=170,\n",
    "    hop_length=750,\n",
    "    n_fft =14056,    \n",
    "    win_length=1100,\n",
    "    f_max=8000,\n",
    "    \n",
    "    # training\n",
    "    #batch_size=32,\n",
    "    mel_scale ='htk',\n",
    "    \n",
    "    # data\n",
    "    fold=1,\n",
    ")\n",
    "\n",
    "mel_run_config = dict(\n",
    "    sr=16000,\n",
    "    n_mels=128,\n",
    "    win_length =  300,\n",
    "    n_fft= 2048,\n",
    "    hop_length= 50,\n",
    "    f_max = 8000    \n",
    ")\n",
    "\n",
    "\n",
    "spectro_run_config =dict(\n",
    "    sr=16000,\n",
    "    n_fft=350,\n",
    "    hop_length=50,\n",
    "    win_length=350,\n",
    "    # training\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a38dcdc",
   "metadata": {},
   "source": [
    "# 데이터 나누기 - Stratified KFold\n",
    "\n",
    "- pathology : 1194 / healthy : 634 / 총 1828\n",
    "- k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c150342",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_data=pd.read_excel(\"../../voice_data/only_organics_healthy_available_ver2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "503fc854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426\n",
      "630\n"
     ]
    }
   ],
   "source": [
    "pathology = speaker_data[speaker_data['PATHOLOGY']=='p']['SPEAKER'].unique().tolist()\n",
    "healthy = speaker_data[speaker_data['PATHOLOGY']=='n']['SPEAKER'].unique().tolist()\n",
    "print(len(pathology))\n",
    "print(len(healthy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d99c8711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[74, 1524, 142]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(healthy) & set(pathology))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c45e9ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#겹치는 speaker는 곱하기 100을 해준다.\n",
    "#겹치는 speaker는 그대로 둔다.\n",
    "\n",
    "changed_patients = list(set(healthy) & set(pathology))\n",
    "\n",
    "for patient in changed_patients:\n",
    "    temp=pathology[pathology.index(patient)]*100\n",
    "    pathology[pathology.index(patient)] = temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf1c10d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "152400"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathology[pathology.index(152400)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c72d82e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 데이터수 :  1056\n",
      "---\n",
      "훈련 셋 :  844 Counter({'healthy': 504, 'pathology': 340})\n",
      "테스트 셋 :  212 Counter({'healthy': 126, 'pathology': 86})\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "#train test 나누기\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split # train , test 분리에 사용.\n",
    "\n",
    "\n",
    "random_state = 1004 # 1004,1005,1006,1007,1008\n",
    "\n",
    "X = pathology+healthy # path 데이터 합\n",
    "print(\"총 데이터수 : \",len(X))\n",
    "Y = [] # 라벨\n",
    "for idx,x in enumerate(X):\n",
    "    if idx<426:\n",
    "        Y.append(\"pathology\")\n",
    "    else:\n",
    "        Y.append(\"healthy\")\n",
    "\n",
    "X, X_test, Y, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True, stratify=Y, random_state=random_state) #456\n",
    "#stratify를 넣어서, test에도 라벨별 잘 분류되게 한다.\n",
    "\n",
    "print(\"---\")\n",
    "print(\"훈련 셋 : \",len(Y),Counter(Y))\n",
    "print(\"테스트 셋 : \",len(Y_test),Counter(Y_test))\n",
    "print(\"---\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "563178eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'healthy'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[169]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f073a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.index(7400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a99443",
   "metadata": {},
   "source": [
    "## 2. stratified k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c38ceb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 : 1\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 403, 'pathology': 272}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 101, 'pathology': 68} \n",
      "\n",
      "교차 검증 : 2\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 403, 'pathology': 272}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 101, 'pathology': 68} \n",
      "\n",
      "교차 검증 : 3\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 403, 'pathology': 272}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 101, 'pathology': 68} \n",
      "\n",
      "교차 검증 : 4\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 403, 'pathology': 272}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 101, 'pathology': 68} \n",
      "\n",
      "교차 검증 : 5\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 404, 'pathology': 272}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 100, 'pathology': 68} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. train, test 나누기\n",
    "#stratified kfold\n",
    "import os\n",
    "import random #데이터 shuffle 사용\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "skf_iris = StratifiedKFold(n_splits=5,shuffle=True,random_state=456)\n",
    "cnt_iter = 0\n",
    "\n",
    "X_train_list = [] #데이터 셋 보관\n",
    "Y_train_list = []\n",
    "\n",
    "X_valid_list = []\n",
    "Y_valid_list = []\n",
    "\n",
    "for train_idx, test_idx in skf_iris.split(X,Y):\n",
    "    \n",
    "    #split으로 반환된 인덱스를 이용하여, 학습 검증용 테스트 데이터 추출\n",
    "    cnt_iter += 1\n",
    "    X_train, X_valid = [X[idx] for idx in train_idx.tolist() ], [X[idx] for idx in test_idx.tolist() ]\n",
    "    Y_train, Y_valid = [Y[idx] for idx in train_idx.tolist() ], [Y[idx] for idx in test_idx.tolist() ]\n",
    "    \n",
    "    X_train_list.append(X_train)\n",
    "    X_valid_list.append(X_valid)\n",
    "    \n",
    "    Y_train_list.append(Y_train)\n",
    "    Y_valid_list.append(Y_valid)\n",
    "    \n",
    "    \n",
    "    #학습 및 예측\n",
    "    \n",
    "    label_train = Y_train\n",
    "    label_test = Y_valid\n",
    "    unique_train, train_counts = np.unique(label_train, return_counts = True)\n",
    "    unique_test, test_counts = np.unique(label_test, return_counts = True)\n",
    "    \n",
    "    uniq_cnt_train = dict(zip(unique_train, train_counts))\n",
    "    uniq_cnt_test = dict(zip(unique_test, test_counts))\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('교차 검증 : {}'.format(cnt_iter))\n",
    "    print('학습 레이블 데이터 분포 : \\n', uniq_cnt_train)\n",
    "    print('검증 레이블 데이터 분포 : \\n', uniq_cnt_test,'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbcb94b",
   "metadata": {},
   "source": [
    "# speaker to voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f725375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train. speaker to voice\n",
      "152400\n",
      "[932]\n",
      "7400\n",
      "[929]\n",
      "152400\n",
      "[932]\n",
      "7400\n",
      "[929]\n",
      "152400\n",
      "[932]\n",
      "7400\n",
      "[929]\n",
      "7400\n",
      "[929]\n",
      "152400\n",
      "[932]\n",
      "valid. speaker to voice\n",
      "7400\n",
      "[929]\n",
      "152400\n",
      "[932]\n",
      "test. speaker to voice\n",
      "14200\n",
      "[495]\n"
     ]
    }
   ],
   "source": [
    "# speaker to voice\n",
    "\n",
    "label_changer = dict({\"healthy\":\"n\",\"pathology\":\"p\"})\n",
    "\n",
    "\n",
    "all_train_record_list = []\n",
    "all_valid_record_list = []\n",
    "all_test_record_list = []\n",
    "\n",
    "all_train_label_list = []\n",
    "all_valid_label_list = []\n",
    "all_test_label_list = []\n",
    "\n",
    "print(\"train. speaker to voice\")\n",
    "#train\n",
    "for fold_idx,fold in enumerate(X_train_list):\n",
    "    fold_record=[]\n",
    "    fold_y_record=[]\n",
    "    for idx,speaker in enumerate(fold):\n",
    "        record_list = speaker_data[ (speaker_data['SPEAKER']==speaker) & (speaker_data['PATHOLOGY']==label_changer[Y_train_list[fold_idx][idx]])]['RECORDING'].tolist()\n",
    "        if record_list == []:\n",
    "            # speaker가 healthy, pathology 모두 있는 경우\n",
    "            print(speaker)\n",
    "            speaker = speaker // 100\n",
    "            record_list = speaker_data[(speaker_data['SPEAKER']==speaker) & (speaker_data['PATHOLOGY']==label_changer[Y_train_list[fold_idx][idx]] ) ]['RECORDING'].tolist()\n",
    "            print(record_list)\n",
    "\n",
    "        label_list = [ Y_train_list[fold_idx][idx] ] * len(record_list)       \n",
    "        fold_record += record_list\n",
    "        fold_y_record += label_list\n",
    "    all_train_record_list.append(fold_record)\n",
    "    all_train_label_list.append(fold_y_record)\n",
    "\n",
    "print(\"valid. speaker to voice\")\n",
    "#valid\n",
    "for fold_idx,fold in enumerate(X_valid_list):\n",
    "    fold_record=[]\n",
    "    fold_y_record=[]\n",
    "    for idx,speaker in enumerate(fold):\n",
    "        record_list = speaker_data[ (speaker_data['SPEAKER']==speaker) & (speaker_data['PATHOLOGY']==label_changer[Y_valid_list[fold_idx][idx]]) ]['RECORDING'].tolist()\n",
    "        if record_list == []:\n",
    "            # speaker가 healthy, pathology 모두 있는 경우\n",
    "            print(speaker)\n",
    "            speaker = speaker // 100\n",
    "            record_list = speaker_data[(speaker_data['SPEAKER']==speaker) & (speaker_data['PATHOLOGY']==label_changer[Y_valid_list[fold_idx][idx]] ) ]['RECORDING'].tolist()\n",
    "            print(record_list)\n",
    "        label_list = [ Y_valid_list[fold_idx][idx] ] * len(record_list)\n",
    "        \n",
    "        fold_record += record_list\n",
    "        fold_y_record += label_list\n",
    "    all_valid_record_list.append(fold_record)\n",
    "    all_valid_label_list.append(fold_y_record)\n",
    "\n",
    "print(\"test. speaker to voice\")\n",
    "#test\n",
    "fold_record=[]\n",
    "fold_y_record=[]\n",
    "for idx,speaker in enumerate(X_test):\n",
    "    record_list = speaker_data[(speaker_data['SPEAKER']==speaker) & (speaker_data['PATHOLOGY']==label_changer[Y_test[idx]] )]['RECORDING'].tolist()\n",
    "    if record_list == []:\n",
    "        # speaker가 healthy, pathology 모두 있는 경우\n",
    "        print(speaker)\n",
    "        speaker = speaker // 100\n",
    "        record_list = speaker_data[(speaker_data['SPEAKER']==speaker) & (speaker_data['PATHOLOGY']==label_changer[Y_test[idx]] ) ]['RECORDING'].tolist()\n",
    "        print(record_list)\n",
    "    label_list = [ Y_test[idx] ] * len(record_list)\n",
    "    fold_record += record_list\n",
    "    fold_y_record += label_list\n",
    "all_test_record_list = fold_record\n",
    "all_test_label_list = fold_y_record\n",
    "\n",
    "\n",
    "X_train_list = all_train_record_list\n",
    "X_valid_list = all_valid_record_list\n",
    "X_test = all_test_record_list\n",
    "\n",
    "Y_train_list = all_train_label_list\n",
    "Y_valid_list = all_valid_label_list\n",
    "Y_test = all_test_label_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0880b5c",
   "metadata": {},
   "source": [
    "## 3. random over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9517c16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " fold0 \n",
      "before dataset shape Counter({'healthy': 406, 'pathology': 364})\n",
      "Resampled dataset shape Counter({'healthy': 406, 'pathology': 406})\n",
      "\n",
      " fold1 \n",
      "before dataset shape Counter({'healthy': 407, 'pathology': 402})\n",
      "Resampled dataset shape Counter({'healthy': 407, 'pathology': 407})\n",
      "\n",
      " fold2 \n",
      "before dataset shape Counter({'healthy': 407, 'pathology': 384})\n",
      "Resampled dataset shape Counter({'healthy': 407, 'pathology': 407})\n",
      "\n",
      " fold3 \n",
      "before dataset shape Counter({'healthy': 407, 'pathology': 396})\n",
      "Resampled dataset shape Counter({'healthy': 407, 'pathology': 407})\n",
      "\n",
      " fold4 \n",
      "before dataset shape Counter({'healthy': 405, 'pathology': 394})\n",
      "Resampled dataset shape Counter({'pathology': 405, 'healthy': 405})\n"
     ]
    }
   ],
   "source": [
    "#2. random over sampling\n",
    "for i in range(5):\n",
    "    X_temp = np.array(X_train_list[i]).reshape(-1,1)#각 데이터를 다 행으로 넣음. (1194,1)\n",
    "    #Y = np.array(Y)\n",
    "    ros = RandomOverSampler(random_state = 123)\n",
    "    X_res,Y_res = ros.fit_resample(X_temp,Y_train_list[i])\n",
    "    \n",
    "    print(\"\\n fold{} \".format(i))\n",
    "    print('before dataset shape {}'.format(Counter(Y_train_list[i])) )\n",
    "    print('Resampled dataset shape {}'.format(Counter(Y_res)) )   \n",
    "    \n",
    "    #원래대로 돌리기\n",
    "    X_res=X_res.reshape(1, -1)\n",
    "    X_train_list[i]=X_res[0].tolist()\n",
    "    Y_train_list[i]=Y_res\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "478af061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "    \n",
    "#load\n",
    "with open(\"../../voice_data/organics_ver2/phrase_dict_ver2.pickle\",\"rb\") as fr:\n",
    "    phrase_dict = pickle.load(fr)\n",
    "\n",
    "#with open(\"../../voice_data/organics/phrase_minmax_scaler_hyper.pickle\",\"rb\") as fr:\n",
    "#    phrase_scaler = pickle.load(fr)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a663f0",
   "metadata": {},
   "source": [
    "# 데이터 정의\n",
    "- 추가적으로 데이터의 크기를 맞춰주기 위해 3초로 padding 및 truncate 실시 https://sequencedata.tistory.com/25 FixAudioLength\n",
    "- 논문에서는 400frame으로 설정.(여기서는 500frame)\n",
    "- 전처리 방법 결정.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d56df016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8877544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default param\n",
    "mfcc_run_config = dict(\n",
    "    sr=16000,\n",
    "    n_mfcc=27,\n",
    "    #dct_type=3, # type2 default\n",
    "    lifter = 35,\n",
    "\n",
    "    \n",
    "    #mel spectro\n",
    "    n_mels=170,\n",
    "    hop_length=750,\n",
    "    n_fft =14056,    \n",
    "    win_length=1100,\n",
    "    f_max=8000,\n",
    "    \n",
    "    # training\n",
    "    #batch_size=32,\n",
    "    mel_scale ='htk',\n",
    "    \n",
    "    # data\n",
    "    fold=1,\n",
    ")\n",
    "\n",
    "mel_run_config = dict(\n",
    "    sr=16000,\n",
    "    n_mels=128,\n",
    "    win_length =  300,\n",
    "    n_fft= 2048,\n",
    "    hop_length= 50,\n",
    "    f_max = 8000    \n",
    ")\n",
    "\n",
    "\n",
    "spectro_run_config =dict(\n",
    "    sr=16000,\n",
    "    n_fft=350,\n",
    "    hop_length=50,\n",
    "    win_length=350,\n",
    "    # training\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2febf8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "classes = [\"healthy\",\"pathology\"]\n",
    "\n",
    "\n",
    "class svd_dataset(Dataset):\n",
    "    def __init__(self,data_path_list,classes,data_num,training,mfcc_params,mel_params,spectro_params,transform=None,normalize=None,mfcc_normalize=None):\n",
    "        #클래스에서 사용할 인자를 받아 인스턴스 변수로 저장하는 일을 한다.\n",
    "        #예를들면, 이미지의 경로 리스트를 저장하는 일을 하게 된다.\n",
    "        \n",
    "        #data_num : k 개 데이터 셋 중 어떤것을 쓸지\n",
    "        #test인지 아닌지.\n",
    "        \n",
    "        self.path_list = data_path_list[data_num]\n",
    "        self.data_num = data_num\n",
    "        self.training = training\n",
    "        self.label = svd_dataset.get_label(self.path_list,training,data_num)\n",
    "        self.classes=classes\n",
    "        self.transform=transform\n",
    "        self.normalize=normalize\n",
    "        self.mfcc_normalize = mfcc_normalize\n",
    "        # sweep params\n",
    "        self.mel_params = mel_params\n",
    "        self.spectro_params = spectro_params\n",
    "        self.mfcc_params = mfcc_params\n",
    "        #sr,n_mfcc,lifter, hop_length , win_length , n_mels , n_fft , f_max , batch_size\n",
    "\n",
    "        \n",
    "    \n",
    "    @classmethod\n",
    "    def get_label(cls,data_path_list,training,data_num):\n",
    "        label_list=[]\n",
    "        \n",
    "        if training:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_train_list[data_num][idx])\n",
    "        else:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_valid_list[data_num][idx])\n",
    "        #print(label_list)\n",
    "        return label_list\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "        #데이터 셋의 길이를 정수로 반환한다.     \n",
    "    \n",
    "       \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        1. path를 받아서, 소리에서 mfcc를 추출\n",
    "        2. mfcc를 224프레임으로 패딩.\n",
    "        3. resnet에 사용되기 위해 3채널로 복사(rgb 처럼)\n",
    "        4. 0~1 정규화\n",
    "        \n",
    "        \"\"\"\n",
    "        #print(str(self.path_list[idx]))\n",
    "        #print(\"label : \",self.label[idx])\n",
    "        file_name = \"../../voice_data/organics_ver2/\" + self.label[idx]+'/phrase/export/'\n",
    "        sig,sr = torchaudio.load( file_name+str(self.path_list[idx])+'-phrase.wav')\n",
    "        sig = torchaudio.transforms.Resample(sr,self.mfcc_params[\"sr\"])(sig)\n",
    "        #sig = phrase_dict[ str(self.path_list[idx])+'-phrase.wav'] \n",
    "        #sig = preemphasis(sig)\n",
    "        # origin_length = sig.shape[0]\n",
    "        \n",
    "        # if sig.shape[0] > self.mfcc_params[\"sr\"]*2:\n",
    "        #     origin_length = self.mfcc_params[\"sr\"]*2\n",
    "        \n",
    "        # origin_frame_size = 1 + int(np.floor(origin_length//self.mel_params[\"hop_length\"]))\n",
    "        length = self.mfcc_params[\"sr\"]*3 #sample rate *2 padding을 위한 파라미터 (하이퍼 파라미터로인해 사이즈는 계속 바뀐다.)\n",
    "        pad1d = lambda a, i: a[:,0:i] if a.shape[1] > i else torch.hstack((a, torch.zeros((1,i-a.shape[1]))))       \n",
    "        sig = pad1d(sig,length)        \n",
    "        ###signal norm\n",
    "        sig = (sig-sig.mean())/sig.std()\n",
    "        ###\n",
    "        \n",
    "        return sig, self.classes.index(self.label[idx])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f198f535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set 제작을 위한 class\n",
    "class svd_test_set(Dataset):\n",
    "    def __init__(self,data_path_list,classes,mfcc_params,mel_params,spectro_params,transform=None,normalize=None,mfcc_normalize=None):\n",
    "        #클래스에서 사용할 인자를 받아 인스턴스 변수로 저장하는 일을 한다.\n",
    "        #예를들면, 이미지의 경로 리스트를 저장하는 일을 하게 된다.\n",
    "        \n",
    "        #data_num : k 개 데이터 셋 중 어떤것을 쓸지\n",
    "        #test인지 아닌지.\n",
    "        \n",
    "        self.path_list = data_path_list\n",
    "        self.label = svd_test_set.get_label(self.path_list)\n",
    "        self.classes=classes\n",
    "        self.transform=transform\n",
    "        self.normalize=normalize\n",
    "        self.mfcc_normalize = mfcc_normalize        \n",
    "        \n",
    "        # sweep params\n",
    "        self.mel_params = mel_params\n",
    "        self.spectro_params = spectro_params\n",
    "        self.mfcc_params = mfcc_params\n",
    "        #sr,n_mfcc,lifter, hop_length , win_length , n_mels , n_fft , f_max , batch_size           \n",
    "    \n",
    "    @classmethod\n",
    "    def get_label(cls,data_path_list):\n",
    "        label_list=[]\n",
    "        \n",
    "        for idx,x in enumerate(data_path_list):\n",
    "            label_list.append(Y_test[idx])\n",
    "        #print(label_list)\n",
    "        return label_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "        #데이터 셋의 길이를 정수로 반환한다. \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        1. path를 받아서, 소리에서 mfcc를 추출\n",
    "        2. mfcc를 224프레임으로 패딩.\n",
    "        3. resnet에 사용되기 위해 3채널로 복사(rgb 처럼)\n",
    "        4. 0~1 정규화\n",
    "        \n",
    "        \"\"\"\n",
    "        file_name = \"../../voice_data/organics_ver2/\" + self.label[idx]+'/phrase/export/'\n",
    "        sig,sr = torchaudio.load( file_name+str(self.path_list[idx])+'-phrase.wav')\n",
    "        sig = torchaudio.transforms.Resample(sr,self.mfcc_params[\"sr\"])(sig)\n",
    "        #sig = phrase_dict[ str(self.path_list[idx])+'-phrase.wav'] \n",
    "        #sig = preemphasis(sig)\n",
    "        # origin_length = sig.shape[0]\n",
    "        \n",
    "        # if sig.shape[0] > self.mfcc_params[\"sr\"]*2:\n",
    "        #     origin_length = self.mfcc_params[\"sr\"]*2\n",
    "        \n",
    "        # origin_frame_size = 1 + int(np.floor(origin_length//self.mel_params[\"hop_length\"]))\n",
    "        length = self.mfcc_params[\"sr\"]*3 #sample rate *2 padding을 위한 파라미터 (하이퍼 파라미터로인해 사이즈는 계속 바뀐다.)\n",
    "        pad1d = lambda a, i: a[:,0:i] if a.shape[1] > i else torch.hstack((a, torch.zeros((1,i-a.shape[1]))))       \n",
    "        sig = pad1d(sig,length)        \n",
    "        ###signal norm\n",
    "        sig = (sig-sig.mean())/sig.std()\n",
    "        ###\n",
    "        \n",
    "        return sig, self.classes.index(self.label[idx])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074e2949",
   "metadata": {},
   "source": [
    "# 데이터로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "272bc789",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. 하이퍼 파라미터\n",
    "BATCH_SIZE =  16 #한 배치당 32개 음성데이터\n",
    "EPOCHS = 50 # 전체 데이터 셋을 50번 반복\n",
    "lr=1e-4\n",
    "augment_kind=\"no\"\n",
    "weight_decay = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10fec835",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config.update({\n",
    "    \"learning_rate\": lr,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"augment\":augment_kind,\n",
    "    \"weight_decay\":weight_decay,\n",
    "    \"특이사항\":\"speaker indep. temporal attention\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bba97b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA LOADER 함수가 BATCH_size 단위로 분리해 지정.\n",
    "\n",
    "#확인을 위해 데이터셋 하나만 확인\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                           svd_dataset(\n",
    "                                               X_train_list,\n",
    "                                               classes,\n",
    "                                               transform = transforms.ToTensor(),#이걸 composed로 고쳐서 전처리 하도록 수정. to tensor는 -데이터는 노멀라이즈못함.\n",
    "                                               #normalize=transforms.Normalize((-11.4805,-54.7723,-54.7723),(16.87,19.0226,19.0226)),\n",
    "                                               #mfcc_normalize=(53.5582, 217.43),\n",
    "                                               mfcc_params=mfcc_run_config,\n",
    "                                               mel_params=mel_run_config,\n",
    "                                               spectro_params=spectro_run_config,\n",
    "                                               data_num=0,\n",
    "                                               training=True\n",
    "                                           ),\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True,\n",
    "                                           ) # 순서가 암기되는것을 막기위해.\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                           svd_dataset(\n",
    "                                               X_valid_list,\n",
    "                                               classes,\n",
    "                                               transform = transforms.ToTensor(),\n",
    "                                               #normalize=transforms.Normalize((-11.4805,-54.7723,-54.7723),(16.87,19.0226,19.0226)),\n",
    "                                               #mfcc_normalize=(53.5582, 217.43),\n",
    "                                               mfcc_params=mfcc_run_config,\n",
    "                                               mel_params=mel_run_config,\n",
    "                                               spectro_params=spectro_run_config,\n",
    "                                               data_num=0,\n",
    "                                               training=False\n",
    "                                           ),\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True,) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9761d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 로더.\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_test_set(\n",
    "                                                   X_test,\n",
    "                                                   classes,\n",
    "                                                   #normalize=transforms.Normalize((-11.4805,-54.7723,-54.7723),(16.87,19.0226,19.0226)),                                               \n",
    "                                                   #mfcc_normalize=(53.5582, 217.43),\n",
    "                                                   mfcc_params=mfcc_run_config,\n",
    "                                                   mel_params=mel_run_config,\n",
    "                                                   spectro_params=spectro_run_config,\n",
    "                                                   transform = transforms.ToTensor(),\n",
    "                                               ),\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = True,) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b15a86",
   "metadata": {},
   "source": [
    "# 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22bdb134",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sr=16000\n",
    "win_length =  mel_run_config[\"win_length\"] # 400\n",
    "n_fft= mel_run_config[\"n_fft\"] # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding. 세로 길이\n",
    "hop_length=mel_run_config[\"hop_length\"] #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다.\n",
    "\n",
    "spectro_win_length =  spectro_run_config[\"win_length\"] # 400\n",
    "spectro_n_fft= spectro_run_config[\"n_fft\"] # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding. 세로 길이\n",
    "spectro_hop_length= spectro_run_config[\"hop_length\"] #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e879c26",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :  torch.Size([16, 1, 48000]) type: torch.FloatTensor\n",
      "Y_train :  torch.Size([16]) type: torch.LongTensor\n",
      "tensor(1)\n",
      "tensor([[ 0.0459,  0.0678,  0.0598,  ..., -0.0013, -0.0013, -0.0013]])\n"
     ]
    }
   ],
   "source": [
    "## 4. 데이터 확인하기\n",
    "for (X_train,Y_train) in train_loader:\n",
    "    print(\"X_train : \",X_train.size(),'type:',X_train.type())\n",
    "    print(\"Y_train : \",Y_train.size(),'type:',Y_train.type())\n",
    "    break\n",
    "\n",
    "print(Y_train[0])\n",
    "print(X_train[0])\n",
    "#batch: 32 / 3채널 / frame수: 500  /  feature수: 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b29c510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valid :  torch.Size([16, 1, 48000]) type: torch.FloatTensor\n",
      "Y_valid :  torch.Size([16]) type: torch.LongTensor\n",
      "tensor([[ 0.0109,  0.0209,  0.0112,  ..., -0.0063, -0.0063, -0.0063]])\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "#valiation set 확인\n",
    "for (X_valid,Y_valid) in validation_loader:\n",
    "    print(\"X_valid : \",X_valid.size(),'type:',X_valid.type())\n",
    "    print(\"Y_valid : \",Y_valid.size(),'type:',Y_valid.type())\n",
    "    break\n",
    "\n",
    "\n",
    "print(X_valid[0])\n",
    "print(Y_valid[0])\n",
    "\n",
    "#batch: 32 / 3채널 / frame수: 500  /  feature수: 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14a38987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test :  torch.Size([16, 1, 48000]) type: torch.FloatTensor\n",
      "Y_test :  torch.Size([16]) type: torch.LongTensor\n",
      "tensor([[-0.0526, -0.0798, -0.0758,  ..., -0.0001, -0.0001, -0.0001]])\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "#test set 확인\n",
    "for (test_data,test_label) in test_loader:\n",
    "    print(\"X_test : \",test_data.size(),'type:',test_data.type())\n",
    "    print(\"Y_test : \",test_label.size(),'type:',test_label.type())\n",
    "    break\n",
    "\n",
    "print(test_data[0])\n",
    "print(test_label[0])\n",
    "\n",
    "#batch: 32 / 3채널 / frame수: 500  /  feature수: 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1cd682ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 48000])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0].size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fec40ea4",
   "metadata": {},
   "source": [
    "# TGRAM NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c36c24c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResLayer, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=True).cuda() \n",
    "        self.num_ftrs = self.model.fc.out_features\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.fc = nn.Sequential(       \n",
    "            nn.Linear(self.num_ftrs, 64),\n",
    "                             nn.BatchNorm1d(64),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(64,50),\n",
    "                             nn.BatchNorm1d(50),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(50,2)\n",
    "                            )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x  = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TgramNet(nn.Module):\n",
    "    def __init__(self, num_layer=3, mel_bins=128, win_len=1024, hop_len=512):\n",
    "        super(TgramNet, self).__init__()\n",
    "        # if \"center=True\" of stft, padding = win_len / 2\n",
    "\n",
    "        self.num_ftrs = 63\n",
    "\n",
    "        self.conv_extrctor = nn.Conv1d(1, mel_bins, win_len, hop_len, win_len // 2, bias=False)\n",
    "        self.conv_encoder = nn.Sequential(\n",
    "            *[nn.Sequential(\n",
    "                nn.LayerNorm(self.num_ftrs),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Conv1d(mel_bins, mel_bins, 3, 1, 1, bias=False)\n",
    "            ) for _ in range(num_layer)])\n",
    "\n",
    "        self.res = ResLayer()\n",
    "        self.fc = nn.Sequential(\n",
    "                            nn.Linear(mel_bins, 64),\n",
    "                             nn.BatchNorm1d(64),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(64,50),\n",
    "                             nn.BatchNorm1d(50),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(50,2)\n",
    "                            )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_extrctor(x)\n",
    "        out = self.conv_encoder(out)\n",
    "        #out = out.mean(axis=2)\n",
    "        #out=self.fc(out)\n",
    "        out = torch.stack([out,out,out],axis=1)\n",
    "        #print(out.size())\n",
    "        out=self.res(out)\n",
    "        return out\n",
    "def model_initialize():\n",
    "    model = ResLayer().cuda()\n",
    "    return model\n",
    "\n",
    "model=model_initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "965fed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResLayer, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=True).cuda() \n",
    "        self.num_ftrs = self.model.fc.out_features\n",
    "        \n",
    "        self.mel_scale = T.MelSpectrogram(\n",
    "            sample_rate=16000,\n",
    "            n_fft=1360,\n",
    "            win_length=1360,\n",
    "            hop_length=60,\n",
    "            n_mels=70,\n",
    "            f_min=0,\n",
    "            f_max=8000,\n",
    "            center=True,\n",
    "            pad_mode=\"constant\",\n",
    "            power=2.0,\n",
    "            norm=\"slaney\",\n",
    "            mel_scale=\"slaney\",\n",
    "            window_fn=torch.hann_window\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.fc = nn.Sequential(       \n",
    "            nn.Linear(self.num_ftrs, 64),\n",
    "                             nn.BatchNorm1d(64),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(64,50),\n",
    "                             nn.BatchNorm1d(50),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(50,2)\n",
    "                            )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mel_scale(x)\n",
    "        x = torchaudio.functional.amplitude_to_DB(x,amin=1e-10,top_db=80,multiplier=10,db_multiplier=torch.log10(torch.max(x)) )\n",
    "        x = x.squeeze()\n",
    "\n",
    "        x = torch.stack([x,x,x],axis=1)\n",
    "        \n",
    "        x = self.model(x)\n",
    "        x  = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def model_initialize():\n",
    "    model = ResLayer().cuda()\n",
    "    return model\n",
    "\n",
    "model=model_initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de1cdd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.resnet import BasicBlock, ResNet\n",
    "from dropblock import DropBlock2D, LinearScheduler\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision.models.resnet import ResNet, BasicBlock\n",
    "\n",
    "class MyResNet18(ResNet):\n",
    "    def __init__(self,):\n",
    "        super(MyResNet18, self).__init__(BasicBlock, [2, 2, 2, 2])\n",
    "        \n",
    "        self.test_avg=nn.AdaptiveAvgPool2d(output_size=(1,26)) # 48000 : 26\n",
    "        self.downsampling_conv = nn.Conv2d(512,1,kernel_size=(1,1))\n",
    "\n",
    "\n",
    "    def get_atteniton(self,x):\n",
    "        x = self.test_avg(x)\n",
    "        x = self.downsampling_conv(x)\n",
    "        x = torch.softmax(x,dim=3)\n",
    "        return x # score\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # change forward here\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "\n",
    "        #print(x.size())\n",
    "        score = self.get_atteniton(x)\n",
    "        #print(\"score : \",score.size())\n",
    "        x = x.mul(score)\n",
    "        #print('attention : ',x.size())\n",
    "        x = self.avgpool(x)\n",
    "        #print(x.size())\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model = my_resnet18(drop_prob=0.3, block_size=18)\n",
    "# #if you need pretrained weights\n",
    "# model.load_state_dict(models.resnet18(pretrained=True).state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ccfa384",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResLayer, self).__init__()\n",
    "        self.model = MyResNet18().cuda() \n",
    "        self.num_ftrs = self.model.fc.out_features\n",
    "        \n",
    "        self.mel_scale = T.MelSpectrogram(\n",
    "            sample_rate=16000,\n",
    "            n_fft=1360,\n",
    "            win_length=1360,\n",
    "            hop_length=60,\n",
    "            n_mels=70,\n",
    "            f_min=0,\n",
    "            f_max=8000,\n",
    "            center=True,\n",
    "            pad_mode=\"constant\",\n",
    "            power=2.0,\n",
    "            norm=\"slaney\",\n",
    "            mel_scale=\"slaney\",\n",
    "            window_fn=torch.hann_window\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.fc = nn.Sequential(       \n",
    "            nn.Linear(self.num_ftrs, 64),\n",
    "                             nn.BatchNorm1d(64),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(64,50),\n",
    "                             nn.BatchNorm1d(50),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(50,2)\n",
    "                            )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mel_scale(x)\n",
    "        x = torchaudio.functional.amplitude_to_DB(x,amin=1e-10,top_db=80,multiplier=10,db_multiplier=torch.log10(torch.max(x)) )\n",
    "        x = x.squeeze()\n",
    "\n",
    "        x = torch.stack([x,x,x],axis=1)\n",
    "        #print(x.size())\n",
    "        x = self.model(x)\n",
    "        x  = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def model_initialize():\n",
    "    model = ResLayer().cuda()\n",
    "    return model\n",
    "\n",
    "model=model_initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "20f97590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 4, 10])\n",
      "torch.Size([1, 512, 1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6684e-02,  1.7544e-01,  5.9734e-01, -4.9304e-01,  1.8160e-01,\n",
       "         -6.2303e-02, -2.7075e-01,  9.7754e-02,  7.1233e-01,  2.6049e-01,\n",
       "         -4.1850e-01, -6.6837e-01, -7.5051e-02, -5.5405e-01, -2.0861e-02,\n",
       "          8.1709e-01, -1.2531e-01,  3.3770e-02,  7.5282e-02, -1.7200e-01,\n",
       "          7.5786e-01,  5.6098e-02, -2.4138e-01, -7.9253e-01, -6.8719e-02,\n",
       "         -1.0142e+00, -3.0899e-01,  2.1199e-01,  3.4036e-01, -3.0502e-01,\n",
       "          3.7748e-01, -3.6019e-01,  2.3441e-01, -1.5832e+00,  7.6936e-02,\n",
       "         -1.3308e-01, -1.2894e-01, -1.4107e-01, -7.4454e-01, -6.1204e-01,\n",
       "         -2.5404e-01, -7.2357e-01, -3.2855e-01, -1.0321e+00, -2.0616e-01,\n",
       "         -7.5194e-01,  9.6457e-01, -2.2485e-02,  6.9353e-01, -4.8762e-01,\n",
       "         -1.0750e-01, -3.4250e-01, -2.4359e-02, -5.1987e-02, -1.8205e-01,\n",
       "          2.5520e-02, -1.8312e-02, -2.7918e-01, -5.8886e-01, -4.8663e-01,\n",
       "          5.0160e-01, -3.2512e-02,  3.6388e-01,  1.5968e-01, -3.9086e-01,\n",
       "          8.1075e-01, -5.4484e-02, -2.8736e-01,  3.9492e-01, -4.9680e-01,\n",
       "         -4.6006e-01,  3.3614e-01, -5.8667e-01,  8.9734e-01, -4.4021e-01,\n",
       "         -1.6293e-01, -2.9533e-02,  2.2184e-01,  3.6849e-01,  4.0518e-01,\n",
       "          1.6987e-01, -1.7752e-01,  1.4496e-01,  1.5531e-01, -4.1072e-01,\n",
       "          7.4028e-01, -4.6755e-02, -2.5546e-01,  1.6162e-01,  1.8208e-01,\n",
       "         -3.9867e-01,  3.0756e-01,  7.7856e-02, -4.0088e-01,  4.1976e-01,\n",
       "          4.4796e-01, -8.9993e-01,  3.5040e-01, -5.8967e-01,  9.9212e-01,\n",
       "          3.2709e-01,  6.5124e-01, -5.6967e-02, -2.9866e-01, -2.7225e-01,\n",
       "         -1.5623e-01, -9.9497e-02, -3.5587e-02, -1.2584e-01, -3.7155e-01,\n",
       "          1.8448e-01, -2.3431e-01,  8.1798e-01, -2.7179e-01,  8.1747e-01,\n",
       "          4.8899e-01, -7.9068e-01, -1.6427e-01, -4.2345e-01, -6.6522e-01,\n",
       "         -1.4177e+00, -1.3637e-01,  3.7822e-01,  6.6068e-01, -6.5508e-01,\n",
       "         -2.1862e-01, -8.8192e-02,  2.7403e-01, -3.5772e-01, -4.2857e-01,\n",
       "         -4.9581e-01,  5.7859e-01, -2.0208e-01,  4.1865e-01, -1.0448e+00,\n",
       "          1.5785e-01,  5.5147e-01, -2.9484e-01,  4.4682e-01, -4.7837e-01,\n",
       "          5.3886e-01,  6.1628e-01, -3.9286e-01,  6.5126e-02, -4.1268e-01,\n",
       "         -2.8216e-02,  9.2754e-01,  6.5619e-02,  5.6394e-01,  3.0545e-01,\n",
       "         -1.4598e-01, -3.3351e-01,  4.9611e-01,  2.2190e-01, -4.9645e-01,\n",
       "          1.2987e-01,  2.2335e-01, -1.8446e-02,  4.5301e-01, -2.3027e-01,\n",
       "          1.0468e+00, -3.6053e-01,  1.7085e-02,  5.1536e-01,  3.8042e-01,\n",
       "         -2.7931e-01, -8.6765e-01,  5.4576e-01,  9.0701e-01,  9.1170e-02,\n",
       "          3.4288e-01,  5.4562e-02, -1.4648e-01,  4.1751e-04,  2.4651e-01,\n",
       "         -6.6796e-01, -5.5190e-02,  7.2347e-01, -1.0836e-01,  6.6842e-01,\n",
       "          1.0467e+00,  3.0264e-02,  2.5158e-01, -4.7350e-01, -2.0830e-01,\n",
       "         -2.7716e-01, -4.1903e-01, -4.6248e-01, -5.4265e-01, -3.0895e-01,\n",
       "         -1.6518e-01, -2.0203e-01,  7.0951e-01,  1.3495e-01,  6.7872e-01,\n",
       "         -7.6659e-02, -2.7510e-01,  1.9903e-01, -2.9520e-01, -4.9238e-01,\n",
       "          3.2111e-01, -6.6222e-02, -3.4114e-01,  4.8995e-01, -8.0339e-01,\n",
       "          2.8022e-01,  3.7311e-01,  1.4495e+00,  5.7218e-01, -5.4387e-01,\n",
       "          4.5438e-01, -3.9397e-03, -6.3129e-01,  4.7382e-01,  4.1447e-01,\n",
       "          6.7762e-02,  9.2025e-01, -1.5188e-01, -6.2653e-01,  2.8748e-01,\n",
       "          3.2859e-01,  1.3789e-01,  5.4755e-01,  5.5495e-01, -3.1896e-01,\n",
       "          2.9956e-01, -1.9176e-01, -3.1029e-01, -4.2062e-01, -6.4076e-01,\n",
       "          8.1004e-02, -5.1103e-01, -1.3070e-01, -3.4503e-01, -5.0714e-02,\n",
       "         -1.3550e-01, -6.6792e-01,  1.9234e-01, -5.2137e-01,  3.5261e-01,\n",
       "          7.1417e-02,  1.4429e-01, -4.4310e-01,  4.3200e-02, -7.2774e-01,\n",
       "         -5.1903e-01, -1.4388e-01, -6.9026e-02, -5.2673e-02,  1.0096e+00,\n",
       "          5.4025e-01,  2.7761e-01, -5.1703e-01, -2.3276e-01, -5.8694e-01,\n",
       "         -1.7466e-02,  7.5227e-01, -4.6929e-01, -8.4422e-02, -4.8978e-01,\n",
       "          4.2022e-01,  3.4027e-01, -1.5379e-01, -6.9884e-01, -8.6885e-01,\n",
       "          9.6663e-01, -1.1551e-01, -8.7928e-01,  9.4154e-01, -1.1285e-01,\n",
       "          9.6256e-01,  2.0891e-01, -5.6685e-01,  4.2726e-01,  3.4720e-01,\n",
       "         -2.0484e-01, -4.2469e-02,  2.7758e-01, -2.7316e-01, -9.0158e-03,\n",
       "         -3.8164e-01,  5.4601e-01, -1.4260e-02,  1.9393e-02,  2.5861e-01,\n",
       "          2.3226e-02, -6.4273e-01, -3.2994e-01, -1.0293e+00, -9.3595e-01,\n",
       "         -3.3472e-01,  2.2269e-01,  3.8510e-01, -3.6828e-01, -3.4794e-01,\n",
       "         -4.0289e-01, -4.0876e-02,  1.8035e-01, -4.0008e-01, -5.1803e-02,\n",
       "          4.3012e-01, -3.7425e-01,  5.5652e-03,  2.7811e-01, -3.6452e-01,\n",
       "          1.3286e-01, -7.4515e-01,  1.1349e-01,  6.2856e-01, -9.2380e-01,\n",
       "         -5.9304e-01,  3.3699e-01, -4.2656e-01,  4.1134e-01, -4.3373e-01,\n",
       "          8.6592e-01, -7.5652e-02,  8.8244e-01, -6.6123e-01, -4.3925e-01,\n",
       "         -7.7429e-01,  1.5781e-01, -4.0079e-01,  2.9399e-01,  1.7781e-01,\n",
       "         -1.8738e-02, -8.5105e-01, -1.4496e-01, -2.8851e-01,  4.3005e-01,\n",
       "         -4.9725e-01, -3.2645e-01, -4.5773e-01, -3.8024e-02,  1.1612e+00,\n",
       "         -6.4242e-01,  1.6428e-01, -3.7263e-01, -4.6960e-01,  5.3846e-01,\n",
       "          2.2707e-01,  6.1065e-01,  5.2880e-01,  8.0219e-01, -2.6298e-01,\n",
       "          5.1129e-02,  1.1247e+00,  9.7672e-01,  1.2185e-01, -7.3160e-01,\n",
       "         -6.0555e-02, -2.4530e-01,  1.0378e-01, -2.1215e-01,  2.3669e-01,\n",
       "         -1.2731e-01, -1.4961e-01,  5.0549e-02,  1.3720e-01, -4.1615e-01,\n",
       "          5.0107e-01, -5.3898e-01, -3.1563e-01,  7.3725e-01, -2.9024e-01,\n",
       "         -6.4422e-01,  8.3850e-02,  3.3304e-01, -8.8335e-01,  6.6488e-01,\n",
       "         -1.1472e-01,  6.7835e-01,  1.6704e-01,  9.2475e-02, -6.5766e-02,\n",
       "          2.9964e-01,  6.9394e-01, -7.5330e-01,  1.5354e-01, -4.6742e-01,\n",
       "         -1.6336e-01, -6.7720e-01,  4.8708e-01, -5.0686e-02, -1.9258e-01,\n",
       "         -3.9966e-01,  5.2872e-01, -1.0722e-01, -9.5295e-01, -5.7669e-01,\n",
       "         -1.0461e-01,  1.7334e-01, -8.3963e-01,  4.3039e-01,  2.3018e-01,\n",
       "          5.1765e-01, -3.5701e-01, -1.2270e-01,  1.1432e-01, -5.4408e-01,\n",
       "          4.4301e-01, -1.3947e+00, -9.1143e-01, -5.2898e-01,  1.1429e-01,\n",
       "         -9.6634e-02,  9.3760e-02,  3.8098e-01, -9.5531e-01,  4.3396e-01,\n",
       "         -1.1411e+00, -1.0568e+00,  4.2127e-01,  1.7735e-01,  4.2910e-01,\n",
       "         -1.2718e-01,  6.0793e-01, -2.3447e-01,  4.5741e-01, -6.7589e-01,\n",
       "          8.7546e-01,  1.6943e-02,  4.0665e-01,  9.6964e-01, -8.9013e-01,\n",
       "         -2.8275e-01, -2.1342e-01, -5.8111e-02, -5.0814e-02, -4.0441e-02,\n",
       "          3.8541e-01,  4.3753e-01, -2.6344e-01,  3.8818e-01, -1.5448e-01,\n",
       "          4.7980e-01, -6.9458e-02, -1.7769e-01,  7.0128e-01, -4.9420e-01,\n",
       "          3.6694e-01, -1.0816e+00, -8.8249e-02, -1.9954e-01,  2.8378e-01,\n",
       "         -2.1390e-01,  5.1457e-02,  8.5082e-01,  9.3860e-02, -6.1122e-02,\n",
       "         -1.0360e+00, -4.3568e-02,  6.4469e-01, -4.9362e-01, -1.5288e-01,\n",
       "          6.1884e-01,  1.1988e-02, -3.1286e-01,  1.1234e-01, -4.4344e-01,\n",
       "          4.7574e-02,  4.7593e-01,  2.6614e-01, -4.9394e-01,  2.3994e-01,\n",
       "          1.2974e+00,  4.1601e-01,  6.4264e-01,  9.0693e-02,  5.6634e-02,\n",
       "          1.9708e-01,  3.0689e-01, -5.4722e-01,  3.8168e-01,  4.6050e-01,\n",
       "          8.2718e-02,  9.0732e-01, -1.4796e-01, -6.2090e-01,  5.3405e-02,\n",
       "         -1.9343e-01,  4.2551e-01, -4.2900e-01,  4.2585e-01, -2.8719e-01,\n",
       "          2.6283e-01, -9.6858e-02,  4.3024e-01,  3.1741e-01, -1.1806e-01,\n",
       "         -3.2050e-01,  5.7991e-01,  4.4777e-01,  7.2810e-02, -5.2857e-01,\n",
       "          1.7670e-01,  1.1187e-02,  7.7235e-01,  4.8352e-01, -2.0520e-01,\n",
       "         -1.2794e+00,  1.1564e-01, -1.0901e+00, -6.0912e-02,  3.3843e-01,\n",
       "         -3.1148e-01,  6.7172e-01, -1.6109e-02,  1.2646e-02, -2.9203e-01,\n",
       "          7.0497e-01, -3.9166e-01,  1.7071e-01, -4.7802e-01,  4.6087e-01,\n",
       "         -1.5455e-01, -6.2846e-01, -3.7124e-01, -1.1368e-01,  3.6719e-01,\n",
       "          2.0438e-01,  1.8256e-01, -1.7762e-01, -2.8905e-01,  3.7888e-02,\n",
       "         -2.4898e-01, -2.5257e-01, -5.5169e-01,  6.3845e-01,  4.3957e-02,\n",
       "          4.4384e-01, -3.8609e-01,  1.2683e-01,  3.4387e-01,  4.6043e-01,\n",
       "          5.8525e-01,  1.0062e-02, -4.2922e-01, -1.4586e-01, -1.5812e-01,\n",
       "         -7.9023e-02, -2.3002e-01,  3.7963e-01,  5.7746e-01,  2.6797e-01,\n",
       "         -8.0357e-01,  2.7183e-01,  1.2646e-01,  4.1231e-01,  1.8211e-01,\n",
       "          3.4393e-01, -4.1309e-01,  2.0029e-01, -6.0464e-01,  2.0509e-02,\n",
       "         -1.2137e-01,  6.3190e-01,  8.0591e-01,  2.5570e-01, -2.7017e-01,\n",
       "          1.6198e-02, -1.0340e+00, -2.4698e-01, -8.7739e-01, -3.3668e-01,\n",
       "          2.4447e-01,  7.3358e-02,  5.8816e-01,  5.3249e-01, -5.1595e-01,\n",
       "          1.1839e-01, -3.5815e-01, -2.4457e-01,  2.8467e-01, -4.2368e-01,\n",
       "          5.9576e-02, -3.3917e-02, -2.2391e-02,  1.6185e-02, -3.3291e-01,\n",
       "         -5.5969e-01,  5.7843e-01, -3.0922e-01, -1.1890e-01,  9.2493e-01,\n",
       "          1.0838e-01, -6.5796e-02, -2.2123e-01,  2.6758e-02, -5.7380e-02,\n",
       "          3.1706e-02, -1.0169e+00, -4.1793e-01,  3.1035e-01, -1.3830e-01,\n",
       "         -9.9751e-01, -3.9304e-01, -7.0542e-02,  4.2850e-01,  4.3611e-02,\n",
       "         -5.2857e-01,  5.6750e-01, -9.3776e-01, -3.1106e-02,  2.0490e-01,\n",
       "          5.6338e-02, -1.5010e-01,  1.3852e-01,  1.0775e-01,  1.1526e-01,\n",
       "          1.0745e-02,  4.8317e-02,  7.7982e-01,  3.0123e-01, -2.0262e-01,\n",
       "         -3.9054e-01,  1.1849e+00, -4.8431e-01,  4.8031e-01, -3.7432e-01,\n",
       "          8.2647e-01,  1.7410e-01, -6.4863e-01, -3.4949e-01, -2.9537e-01,\n",
       "          2.5777e-01,  2.5516e-01, -6.4136e-02,  7.3363e-01, -3.5501e-01,\n",
       "          5.9523e-01, -1.5536e-02, -5.0487e-02,  6.1057e-01, -3.7707e-01,\n",
       "          2.0668e-01, -3.9709e-01,  2.9269e-02,  4.2521e-01, -1.0875e-01,\n",
       "         -1.3030e-01, -9.3063e-02, -4.4231e-01, -1.3357e-01,  5.3528e-01,\n",
       "          1.8554e-01, -5.1231e-01, -7.4480e-01,  4.7299e-01,  3.5774e-02,\n",
       "         -5.5880e-01,  4.6193e-01,  2.0932e-01, -1.5665e-01, -5.8580e-01,\n",
       "         -9.0722e-02, -5.8040e-01,  6.4157e-02, -2.1340e-01,  1.4622e+00,\n",
       "         -2.1528e-01,  2.3366e-01, -4.7820e-01, -1.2952e-01,  1.1118e+00,\n",
       "          8.3466e-01, -3.0295e-01,  1.3364e-01,  6.0205e-01, -2.9532e-01,\n",
       "         -6.9198e-01,  3.7892e-01, -5.9508e-01,  7.2579e-01, -9.9882e-01,\n",
       "         -3.3273e-02, -5.9456e-01, -3.8690e-01, -3.4641e-01, -4.8262e-01,\n",
       "         -4.0342e-01,  8.3789e-01, -3.4463e-01,  1.6593e-01, -3.4724e-01,\n",
       "         -2.4164e-01,  2.7873e-02,  5.5124e-01, -5.8570e-01,  5.8567e-01,\n",
       "          7.3456e-01,  7.6889e-02, -8.0367e-01,  3.6581e-01, -2.1262e-01,\n",
       "         -1.5750e-01, -1.4914e-02, -3.8614e-01, -2.8211e-01, -4.7522e-01,\n",
       "         -7.7502e-01, -4.9396e-01, -5.2586e-01, -1.5299e+00,  7.4655e-02,\n",
       "          1.8275e-01, -4.4180e-01,  1.2452e-01,  2.8221e-01,  7.2685e-01,\n",
       "          3.2312e-01, -5.0693e-01,  3.6126e-01, -2.6809e-02,  1.9322e-01,\n",
       "         -7.5913e-01, -5.5375e-03, -5.1807e-02,  1.3875e+00,  1.0656e+00,\n",
       "         -4.0672e-02, -2.3272e-01,  8.8633e-01, -9.8075e-01,  3.2513e-01,\n",
       "          1.3564e-01,  9.2973e-02, -2.7548e-01, -2.8141e-01,  2.8519e-01,\n",
       "          9.4095e-01, -2.9412e-01,  6.9569e-01,  2.6975e-01, -2.3907e-01,\n",
       "         -9.0673e-02, -5.2732e-01,  8.2925e-02,  1.8004e-01, -3.3789e-01,\n",
       "          3.8773e-02,  2.2660e-01, -6.1076e-01,  6.1116e-01, -3.8367e-01,\n",
       "         -2.6127e-01,  3.5262e-01, -5.2068e-01, -5.6392e-02, -5.5429e-01,\n",
       "         -3.9158e-01, -9.5749e-01,  9.6561e-02, -5.8974e-01,  4.6306e-01,\n",
       "          2.2108e-02, -7.8020e-01,  1.9628e-01, -1.6823e-01, -1.6870e-01,\n",
       "         -3.5919e-01,  8.2941e-01, -9.5144e-01, -3.0742e-01, -2.6763e-01,\n",
       "          6.5920e-01, -2.3641e-01, -4.2406e-01, -3.2502e-01, -8.1237e-01,\n",
       "          4.5238e-02, -5.4469e-01, -1.0674e-02, -3.3621e-01,  2.8027e-01,\n",
       "         -3.0440e-01,  7.5681e-01,  4.4015e-01,  2.6664e-01,  3.6799e-01,\n",
       "          1.2877e-01, -2.5641e-01, -3.6934e-01, -4.4610e-01,  2.4858e-01,\n",
       "          5.2055e-01, -1.5875e-02,  2.1406e-01,  5.5489e-01,  3.1282e-01,\n",
       "         -6.1332e-01, -8.9295e-02,  7.3640e-02,  2.9845e-01,  5.7762e-01,\n",
       "         -4.6765e-01, -9.1998e-01,  4.2389e-01,  5.1620e-03, -2.9170e-01,\n",
       "         -5.5001e-01,  1.6565e-01, -2.5562e-01,  6.1127e-02,  3.2279e-01,\n",
       "          1.4084e-01,  1.4776e-01, -6.8759e-02, -2.1821e-01,  3.9762e-01,\n",
       "         -8.1858e-01, -1.8036e-01,  6.1353e-01, -1.8170e-02, -1.4431e-01,\n",
       "          1.7556e-01,  4.1664e-01,  2.7170e-01, -3.9602e-01, -7.5946e-01,\n",
       "          1.7409e-01,  1.0868e-01, -5.8126e-01,  5.4196e-01, -3.9396e-01,\n",
       "         -4.9536e-01,  4.1594e-01,  2.2015e-01,  6.4013e-02,  4.6018e-01,\n",
       "          8.0214e-03, -5.4610e-02, -1.4155e-01,  4.8339e-01, -1.8598e-01,\n",
       "         -7.2797e-01, -1.8172e-01,  4.7098e-01, -1.2710e-01, -2.6039e-01,\n",
       "          5.6213e-01,  8.1837e-01,  9.6912e-02, -8.6514e-01,  2.5072e-01,\n",
       "          3.2590e-02, -8.1663e-01, -2.8773e-02, -6.8714e-02,  2.3170e-02,\n",
       "          4.3616e-01,  9.0775e-04,  4.1511e-01, -5.1563e-01,  1.3856e+00,\n",
       "         -1.0172e+00, -1.2376e-01,  1.6903e-01, -3.4326e-01, -4.2307e-02,\n",
       "          1.4910e-01,  1.2877e-01, -6.7721e-01,  4.9824e-01, -5.2122e-01,\n",
       "          4.7136e-01,  6.4074e-02, -1.1026e-01, -1.6646e-01, -6.7910e-01,\n",
       "          2.5999e-01, -2.3886e-01,  5.7769e-01, -6.6655e-01,  1.9450e-01,\n",
       "         -1.8079e-01,  3.1947e-01, -8.0684e-01,  2.6437e-01,  5.7809e-02,\n",
       "          2.1869e-01, -1.4851e-01, -2.1718e-01,  3.4114e-01, -1.3681e+00,\n",
       "         -1.3278e-01,  1.7709e-01,  8.1625e-01, -1.8330e-01, -1.0641e+00,\n",
       "          7.1615e-03,  4.8931e-01,  1.8555e-01,  2.1867e-01, -1.1072e-01,\n",
       "          3.6902e-01,  4.0522e-01, -1.3792e-01,  1.5250e-01,  5.1111e-01,\n",
       "         -3.7119e-01,  9.1799e-02, -1.5179e-01, -1.1730e-01,  1.3706e-01,\n",
       "         -6.5028e-02,  7.3423e-02,  1.0645e+00, -7.4257e-01,  7.9474e-01,\n",
       "          5.4188e-01,  8.6537e-01,  5.4476e-01,  9.3135e-01,  2.5088e-01,\n",
       "          2.4332e-02, -2.4032e-01,  6.2884e-02,  1.7045e-02,  2.7840e-01,\n",
       "         -8.7854e-01, -2.3857e-01, -1.8616e-02, -1.7873e-01,  7.1228e-01,\n",
       "         -6.8331e-01, -4.4876e-01, -1.9889e-01,  1.0327e+00, -1.6885e-02,\n",
       "          2.3719e-01, -1.4137e-01,  1.9077e-02, -6.5846e-02,  3.4021e-01,\n",
       "         -6.5585e-01, -8.3266e-01, -5.2883e-01,  6.1137e-01,  6.0072e-02,\n",
       "         -1.0975e+00,  5.3178e-02,  4.6106e-02,  1.4203e-01,  5.6814e-01,\n",
       "          4.1831e-02,  3.7431e-01,  2.9562e-01,  2.3862e-01, -8.2810e-01,\n",
       "          3.3526e-02,  5.1485e-02,  7.2504e-01,  5.2323e-02, -2.3984e-01,\n",
       "          9.5434e-02,  3.6032e-01,  3.7366e-01,  1.7441e-01, -3.8307e-01,\n",
       "          4.2148e-01,  1.8601e-01, -4.0781e-01, -2.1148e-01,  5.3221e-02,\n",
       "          9.5512e-02,  8.8004e-01, -4.0890e-01, -3.3350e-02,  6.9956e-01,\n",
       "          2.5854e-03, -7.4307e-01, -2.3440e-02, -9.4721e-01, -1.3847e-01,\n",
       "         -2.2226e-01, -3.1614e-02,  1.8904e-02,  1.6312e-01, -1.5512e-01,\n",
       "          6.5608e-01, -1.6424e-01,  7.9320e-01,  5.6611e-01, -5.7302e-01,\n",
       "          1.4053e-01, -2.6351e-01,  1.2123e-01,  6.6621e-01, -1.4850e-01,\n",
       "         -4.1128e-01,  2.3654e-01,  1.3441e-01, -5.2236e-01, -6.5709e-01,\n",
       "          2.6440e-01,  8.7309e-01,  5.8538e-02, -7.3931e-02, -1.9422e-01]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=MyResNet18()\n",
    "\n",
    "model(torch.randn((1,3,128,300)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df58011f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 64, 512])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn((1,64,64,512))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a797ce67",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.AdaptiveAvgPool1d(5)\n",
    "input = torch.randn(1, 64, 8)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "101e28b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 5])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f0336cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randn((1,64,64,601))\n",
    "test_avg=nn.AdaptiveAvgPool2d(output_size=(1,19))\n",
    "downsampling_conv = nn.Conv2d(512,1,kernel_size=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "50399edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 1, 19])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsampling_conv(test_avg(torch.randn((2,512,3,19)))).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2bb8c7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaptiveAvgPool2d(output_size=(1, 1))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.avgpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bddb25c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResLayer(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       "  (mel_scale): MelSpectrogram(\n",
       "    (spectrogram): Spectrogram()\n",
       "    (mel_scale): MelScale()\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=1000, out_features=64, bias=True)\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=64, out_features=50, bias=True)\n",
       "    (5): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.5, inplace=False)\n",
       "    (8): Linear(in_features=50, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb4a27b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TgramNetConcat(nn.Module):\n",
    "    def __init__(self, num_layer=3, mel_bins=128, win_len=1024, hop_len=512):\n",
    "        super(TgramNetConcat, self).__init__()\n",
    "        # if \"center=True\" of stft, padding = win_len / 2\n",
    "\n",
    "        self.num_ftrs = 63\n",
    "\n",
    "        self.conv_extrctor = nn.Conv1d(1, mel_bins, win_len, hop_len, win_len // 2, bias=False)\n",
    "        self.conv_encoder = nn.Sequential(\n",
    "            *[nn.Sequential(\n",
    "                nn.LayerNorm(self.num_ftrs),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Conv1d(mel_bins, mel_bins, 3, 1, 1, bias=False)\n",
    "            ) for _ in range(num_layer)])\n",
    "\n",
    "        self.res = ResLayer()\n",
    "        self.fc = nn.Sequential(\n",
    "                            nn.Linear(mel_bins, 64),\n",
    "                             nn.BatchNorm1d(64),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(64,50),\n",
    "                             nn.BatchNorm1d(50),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(50,2)\n",
    "                            )\n",
    "\n",
    "        self.spec = T.Spectrogram(n_fft=win_len,hop_length=hop_len,power=2)\n",
    "\n",
    "        self.mel_scale = T.MelScale(\n",
    "            n_mels=mel_bins, sample_rate=16000, n_stft=win_len // 2 + 1)\n",
    "\n",
    "        stretch_factor=0.8\n",
    "        self.spec_aug = torch.nn.Sequential(\n",
    "            T.TimeStretch(stretch_factor, fixed_rate=True),\n",
    "            T.FrequencyMasking(freq_mask_param=80),\n",
    "            T.TimeMasking(time_mask_param=40),\n",
    "        )        \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_extrctor(x)\n",
    "        out = self.conv_encoder(out)\n",
    "        spec = self.spec(x)\n",
    "        mel = self.mel_scale(spec)\n",
    "        #mel = self.spec_aug(mel)\n",
    "        mel = torch.squeeze(mel,dim=1)\n",
    "\n",
    "        #out = out.mean(axis=2)\n",
    "        #out=self.fc(out)\n",
    "        \n",
    "        #concated_feature = torch.concat([mel,out],axis=2)\n",
    "\n",
    "        out = torch.stack([mel,mel,out],axis=1)\n",
    "        #print(out.size())\n",
    "        out=self.res(out)\n",
    "        return out\n",
    "\n",
    "def model_initialize():\n",
    "    model = TgramNetConcat().cuda()\n",
    "    return model\n",
    "\n",
    "model=model_initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a8f3ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.avgpool= nn.Sequential(\n",
    "    \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aaaf71c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=model(torch.randn(4,1,32000).to(DEVICE))\n",
    "res.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bd816a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2150, -0.3051],\n",
      "        [ 0.3843,  0.6991],\n",
      "        [ 0.0279, -1.0197],\n",
      "        [ 0.0399, -0.9149]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74b42e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(res[0].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "2fe5d1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델\n",
    "# pretrained\n",
    "\n",
    "class ResLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResLayer, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=True).cuda() \n",
    "        self.num_ftrs = self.model.fc.out_features\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.fc = nn.Sequential(       \n",
    "            nn.Linear(self.num_ftrs, 64),\n",
    "                             nn.BatchNorm1d(64),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(64,50),\n",
    "                             nn.BatchNorm1d(50),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(50,2)\n",
    "                            )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x  = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def model_initialize():\n",
    "    model = ResLayer().cuda()\n",
    "    return model\n",
    "\n",
    "model=model_initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1ab03234",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResLayer(\n",
      "  (model): MyResNet18(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      "    (test_avg): AdaptiveAvgPool2d(output_size=(1, 26))\n",
      "    (downsampling_conv): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (mel_scale): MelSpectrogram(\n",
      "    (spectrogram): Spectrogram()\n",
      "    (mel_scale): MelScale()\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=64, bias=True)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=64, out_features=50, bias=True)\n",
      "    (5): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.5, inplace=False)\n",
      "    (8): Linear(in_features=50, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a47749e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the model summary\n",
    "from torchsummary import summary\n",
    "#summary(model, input_size=(3, 128, 300), device=DEVICE.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f2ca15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. 학습\n",
    "def train(model,train_loader,optimizer, log_interval):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    train_loss = 0\n",
    "    for batch_idx,(image,label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        #데이터들 장비에 할당\n",
    "        optimizer.zero_grad() # device 에 저장된 gradient 제거\n",
    "        output = model(image) # model로 output을 계산\n",
    "        loss = criterion(output, label) #loss 계산\n",
    "        train_loss += loss.item()\n",
    "        prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "        correct += prediction.eq(label.view_as(prediction)).sum().item()# 아웃풋이 배치 사이즈 32개라서.\n",
    "        loss.backward() # loss 값을 이용해 gradient를 계산\n",
    "        optimizer.step() # Gradient 값을 이용해 파라미터 업데이트.\n",
    "    train_loss/=len(train_loader.dataset)\n",
    "    train_accuracy = 100. * correct / len(train_loader.dataset)\n",
    "    return train_loss,train_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b09341bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. 학습 진행하며, validation 데이터로 모델 성능확인\n",
    "def evaluate(model,valid_loader):\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    #no_grad : 그래디언트 값 계산 막기.\n",
    "    with torch.no_grad():\n",
    "        for image,label in valid_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            valid_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()# 아웃풋이 배치 사이즈 32개라서.\n",
    "            #true.false값을 sum해줌. item\n",
    "        valid_loss /= len(valid_loader.dataset)\n",
    "        valid_accuracy = 100. * correct / len(valid_loader.dataset)\n",
    "        return valid_loss,valid_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa7fc2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 로더 제작 함수\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "def load_data(data_ind):\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_dataset(\n",
    "                                                   X_train_list,\n",
    "                                                   classes,\n",
    "                                                   transform = transforms.ToTensor(),#이걸 composed로 고쳐서 전처리 하도록 수정.\n",
    "                                                   data_num=data_ind,\n",
    "                                                   #normalize=transforms.Normalize((-11.4805,-54.7723,-54.7723),(16.87,19.0226,19.0226)),\n",
    "                                                   #mfcc_normalize=(53.5582, 217.43),\n",
    "                                                   mfcc_params=mfcc_run_config,\n",
    "                                                   mel_params=mel_run_config,\n",
    "                                                   spectro_params=spectro_run_config,\n",
    "                                                   training=True\n",
    "                                               ),\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = True,\n",
    "                                               worker_init_fn=seed_worker\n",
    "                                               ) # 순서가 암기되는것을 막기위해.\n",
    "\n",
    "    validation_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_dataset(\n",
    "                                                   X_valid_list,\n",
    "                                                   classes,\n",
    "                                                   transform = transforms.ToTensor(),\n",
    "                                                   data_num=data_ind,\n",
    "                                                   #normalize=transforms.Normalize((-11.4805,-54.7723,-54.7723),(16.87,19.0226,19.0226)),\n",
    "                                                   #mfcc_normalize=(53.5582, 217.43),\n",
    "                                                   mfcc_params=mfcc_run_config,\n",
    "                                                   mel_params=mel_run_config,\n",
    "                                                   spectro_params=spectro_run_config,\n",
    "                                                   training=False\n",
    "                                               ),\n",
    "                                                    batch_size = BATCH_SIZE,\n",
    "                                                    shuffle = True,\n",
    "                                                    worker_init_fn=seed_worker) \n",
    "    return train_loader,validation_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b970e322",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoint/checkpoint_attentionRes_ros_1_organics_speaker.pt\n",
      "[1 교차검증] 학습 시작\n",
      " ----- \n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([12, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([15, 512, 3, 26])\n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0353\t Train Acc:72.66 %  | \tValid Loss:0.0420 \tValid Acc: 54.26 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.041970).  Saving model ...\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([12, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([15, 512, 3, 26])\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0308\t Train Acc:78.94 %  | \tValid Loss:0.0328 \tValid Acc: 75.34 %\n",
      "\n",
      "Validation loss decreased (0.041970 --> 0.032811).  Saving model ...\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([12, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([15, 512, 3, 26])\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0264\t Train Acc:83.25 %  | \tValid Loss:0.0436 \tValid Acc: 60.09 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([12, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([15, 512, 3, 26])\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0217\t Train Acc:89.78 %  | \tValid Loss:0.0302 \tValid Acc: 77.58 %\n",
      "\n",
      "Validation loss decreased (0.032811 --> 0.030150).  Saving model ...\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([12, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([15, 512, 3, 26])\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0185\t Train Acc:93.10 %  | \tValid Loss:0.0606 \tValid Acc: 48.88 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([12, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([15, 512, 3, 26])\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0152\t Train Acc:96.31 %  | \tValid Loss:0.0336 \tValid Acc: 72.20 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([12, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([15, 512, 3, 26])\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0139\t Train Acc:96.18 %  | \tValid Loss:0.0279 \tValid Acc: 79.82 %\n",
      "\n",
      "Validation loss decreased (0.030150 --> 0.027869).  Saving model ...\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([12, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([15, 512, 3, 26])\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0129\t Train Acc:96.06 %  | \tValid Loss:0.0318 \tValid Acc: 72.20 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([12, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([15, 512, 3, 26])\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0105\t Train Acc:98.52 %  | \tValid Loss:0.0265 \tValid Acc: 80.72 %\n",
      "\n",
      "Validation loss decreased (0.027869 --> 0.026509).  Saving model ...\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([12, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([15, 512, 3, 26])\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0110\t Train Acc:96.43 %  | \tValid Loss:0.0381 \tValid Acc: 67.71 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([12, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([15, 512, 3, 26])\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0120\t Train Acc:94.70 %  | \tValid Loss:0.0282 \tValid Acc: 78.48 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([12, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([15, 512, 3, 26])\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0115\t Train Acc:94.70 %  | \tValid Loss:0.0273 \tValid Acc: 81.17 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([12, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([15, 512, 3, 26])\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0109\t Train Acc:95.32 %  | \tValid Loss:0.0355 \tValid Acc: 76.23 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([12, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([15, 512, 3, 26])\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0107\t Train Acc:95.57 %  | \tValid Loss:0.0280 \tValid Acc: 80.27 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[1 교차검증] Early stopping\n",
      "./checkpoint/checkpoint_attentionRes_ros_2_organics_speaker.pt\n",
      "[2 교차검증] 학습 시작\n",
      " ----- \n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([14, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([8, 512, 3, 26])\n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0360\t Train Acc:71.13 %  | \tValid Loss:0.0407 \tValid Acc: 67.39 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.040700).  Saving model ...\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([14, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n",
      "torch.Size([16, 512, 3, 26])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23640/2601755591.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mEpoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_accuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m31\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mvalid_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         wandb.log({\n\u001b[0;32m     35\u001b[0m                 \u001b[1;34m\"valid {}fold Accuracy\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_ind\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mvalid_accuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23640/3715514481.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(model, valid_loader)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#no_grad : 그래디언트 값 계산 막기.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\local_torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\local_torch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\local_torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\local_torch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23640/4254808780.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0msig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m###signal norm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0msig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[1;31m###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##### 10. 학습 및 평가.\n",
    "# resnet34 pretrained true\n",
    "# kfold 적용\n",
    "\n",
    "train_accs = []\n",
    "valid_accs = []\n",
    "\n",
    "for data_ind in range(1,6): \n",
    "\n",
    "    #check_path = './checkpoint/checkpoint_wavegram_ros_'+str(data_ind)+'_organics_speaker.pt'\n",
    "    check_path = './checkpoint/checkpoint_attentionRes_ros_'+str(data_ind)+'_organics_speaker.pt'\n",
    "    print(check_path)\n",
    "    early_stopping = EarlyStopping(patience = 5, verbose = True, path=check_path)\n",
    "    train_loader,validation_loader = load_data(data_ind-1)\n",
    "\n",
    "    best_train_acc=0 # accuracy 기록용\n",
    "    best_valid_acc=0\n",
    "    \n",
    "    model=model_initialize()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=weight_decay)\n",
    "    #scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = lambda epoch: 0.95 ** epoch)\n",
    "    #scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,\n",
    "    #                                               max_lr=0.0001,\n",
    "    #                                               steps_per_epoch=len(train_loader),\n",
    "    #                                               epochs=20,\n",
    "    #                                               anneal_strategy='linear')\n",
    "    \n",
    "    \n",
    "    print(\"[{} 교차검증] 학습 시작\\n ----- \".format(data_ind))\n",
    "    for Epoch in range(1,EPOCHS+1):\n",
    "        train_loss,train_accuracy=train(model,train_loader,optimizer,log_interval=31)\n",
    "        valid_loss,valid_accuracy = evaluate(model, validation_loader)\n",
    "        wandb.log({\n",
    "                \"valid {}fold Accuracy\".format(data_ind) : valid_accuracy,\n",
    "                \"valid {}fold loss\".format(data_ind) : valid_loss},\n",
    "                commit=True,\n",
    "                step=Epoch)\n",
    "\n",
    "        print(\"\\n[EPOCH:{}]\\t Train Loss:{:.4f}\\t Train Acc:{:.2f} %  | \\tValid Loss:{:.4f} \\tValid Acc: {:.2f} %\\n\".\n",
    "              format(Epoch,train_loss,train_accuracy,valid_loss,valid_accuracy))\n",
    "        \n",
    "\n",
    "        early_stopping(valid_loss, model)\n",
    "        if -early_stopping.best_score == valid_loss:\n",
    "            best_train_acc, best_valid_acc = train_accuracy,valid_accuracy\n",
    "            wandb.run.summary.update({\"best_valid_{}fold_acc\".format(data_ind) : best_valid_acc})\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "                train_accs.append(best_train_acc)\n",
    "                valid_accs.append(best_valid_acc)\n",
    "                print(\"[{} 교차검증] Early stopping\".format(data_ind))\n",
    "                break\n",
    "\n",
    "        if Epoch==EPOCHS:\n",
    "            #만약 early stop 없이 40 epoch라서 중지 된 경우. \n",
    "            train_accs.append(best_train_acc)\n",
    "            valid_accs.append(best_valid_acc)\n",
    "        #scheduler.step()\n",
    "        #print(scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d969079c",
   "metadata": {},
   "source": [
    "# Model 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "8d8ef002",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 교차검증] train ACC : 99.1379 |\t valid ACC: 84.3049 \n",
      "[2 교차검증] train ACC : 99.8771 |\t valid ACC: 88.5870 \n",
      "[3 교차검증] train ACC : 99.1400 |\t valid ACC: 82.6733 \n",
      "[4 교차검증] train ACC : 98.8943 |\t valid ACC: 87.8947 \n",
      "[5 교차검증] train ACC : 98.6420 |\t valid ACC: 86.5979 \n",
      "평균 검증 정확도 86.01156631406658 %\n"
     ]
    }
   ],
   "source": [
    "sum_valid=0\n",
    "for data_ind in range(5):\n",
    "    print(\"[{} 교차검증] train ACC : {:.4f} |\\t valid ACC: {:.4f} \".format(data_ind+1,train_accs[data_ind],valid_accs[data_ind] ))\n",
    "    sum_valid+=valid_accs[data_ind]\n",
    "    \n",
    "print(\"평균 검증 정확도\",sum_valid/5,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7d3f46",
   "metadata": {},
   "source": [
    "# Model Test\n",
    "\n",
    "- test set\n",
    "- confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "b597b674",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix 계산\n",
    "#test set 계산.\n",
    "def test_evaluate(model,test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    predictions = []\n",
    "    answers = []\n",
    "    #no_grad : 그래디언트 값 계산 막기.\n",
    "    with torch.no_grad():\n",
    "        for image,label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "            answers +=label\n",
    "            predictions +=prediction\n",
    "            \n",
    "        return predictions,answers,test_loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "446269f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번 모델\n",
      "Accuracy : 81.4346% \n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.8829\n",
      "specificity : 0.7540%\n",
      "UAR : 0.8184%\n",
      "f score : 0.8143 \n",
      "[[95 31]\n",
      " [13 98]]\n",
      "-----\n",
      "2번 모델\n",
      "Accuracy : 83.9662% \n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.7748\n",
      "specificity : 0.8968%\n",
      "UAR : 0.8358%\n",
      "f score : 0.8376 \n",
      "[[113  13]\n",
      " [ 25  86]]\n",
      "-----\n",
      "3번 모델\n",
      "Accuracy : 83.1224% \n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.7838\n",
      "specificity : 0.8730%\n",
      "UAR : 0.8284%\n",
      "f score : 0.8296 \n",
      "[[110  16]\n",
      " [ 24  87]]\n",
      "-----\n",
      "4번 모델\n",
      "Accuracy : 84.3882% \n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.8559\n",
      "specificity : 0.8333%\n",
      "UAR : 0.8446%\n",
      "f score : 0.8436 \n",
      "[[105  21]\n",
      " [ 16  95]]\n",
      "-----\n",
      "5번 모델\n",
      "Accuracy : 80.5907% \n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.6667\n",
      "specificity : 0.9286%\n",
      "UAR : 0.7976%\n",
      "f score : 0.7993 \n",
      "[[117   9]\n",
      " [ 37  74]]\n",
      "-----\n",
      "평균 acc : 0.8270\n",
      "평균 UAR : 0.8250\n",
      "평균 f1score : 0.8249\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix (resnet18)\n",
    "# kfold의 confusion matrix는 계산 방법이 다르다.\n",
    "# 모델을 각각 불러와서 test set을 평가한다.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "cf = np.zeros((2,2))\n",
    "cf_list = []\n",
    "average_accuracy = 0\n",
    "average_fscore = 0\n",
    "average_uar = 0\n",
    "\n",
    "for data_ind in range(1,6):\n",
    "    model=model_initialize()\n",
    "    check_path = './checkpoint/checkpoint_wavegram_ros_'+str(data_ind)+'_organics_speaker.pt'\n",
    "    model.load_state_dict(torch.load(check_path))\n",
    "\n",
    "    predictions,answers,test_loss = test_evaluate(model, test_loader)\n",
    "    predictions=[ dat.cpu().numpy() for dat in predictions]\n",
    "    answers=[ dat.cpu().numpy() for dat in answers]\n",
    "\n",
    "    \n",
    "    cf = confusion_matrix(answers, predictions)\n",
    "    cf_list.append(cf)\n",
    "    \n",
    "    acc = (cf[0,0]+cf[1,1])/(cf[0,0]+cf[0,1]+cf[1,0]+cf[1,1])\n",
    "    average_accuracy+=acc\n",
    "    \n",
    "    precision=cf[1,1]/(cf[0,1]+cf[1,1])\n",
    "    \n",
    "    recall=cf[1,1]/(cf[1,1]+cf[1,0])\n",
    "    \n",
    "    specificity=cf[0,0]/(cf[0,0]+cf[0,1])\n",
    "    average_uar += (specificity+recall)/2\n",
    "    #fscore=2*precision*recall/(precision+recall)\n",
    "    \n",
    "    #fscroe macro추가\n",
    "    fscore = f1_score(answers,predictions,average='macro')\n",
    "    average_fscore+=fscore\n",
    "    \n",
    "    print('{}번 모델'.format(data_ind))\n",
    "    print(\"Accuracy : {:.4f}% \".format(acc*100))\n",
    "    #print(\"Precision (pathology 예측한 것중 맞는 것) : {:.4f}\".format(precision))\n",
    "    print(\"recall (실제 pathology 중  예측이 맞는 것) : {:.4f}\".format(recall))\n",
    "    print(\"specificity : {:.4f}%\".format(specificity))\n",
    "    print(\"UAR : {:.4f}%\".format( (specificity+recall)/2 ))\n",
    "    \n",
    "    \n",
    "    print(\"f score : {:.4f} \".format(fscore))\n",
    "    print(cf)\n",
    "    print(\"-----\")\n",
    "    #### wandb\n",
    "    \n",
    "\n",
    "    wandb.log({\"{}fold Confusion Matrix\".format(data_ind) :wandb.sklearn.plot_confusion_matrix(answers, predictions, labels=classes)})\n",
    "    \n",
    "    ####\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "print(\"평균 acc : {:.4f}\".format(average_accuracy/5))\n",
    "print(\"평균 UAR : {:.4f}\".format(average_uar/5))\n",
    "print(\"평균 f1score : {:.4f}\".format(average_fscore/5))\n",
    "wandb.run.summary.update({\"test 평균 acc\" : average_accuracy/5})\n",
    "wandb.run.summary.update({\"test 평균 f1\" : average_fscore/5})\n",
    "wandb.run.summary.update({\"test 평균 UAR\" : average_uar/5})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d4cac4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ᄋᄋᄋᄋᄋᄋᄋᄋᄋ' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3184/757536221.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mㅇㅇㅇㅇㅇㅇㅇㅇㅇ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ᄋᄋᄋᄋᄋᄋᄋᄋᄋ' is not defined"
     ]
    }
   ],
   "source": [
    "ㅇㅇㅇㅇㅇㅇㅇㅇㅇ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38befa06",
   "metadata": {},
   "source": [
    "# loss 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726a124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_list[0])\n",
    "plt.plot(valid_loss_list[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4c63c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_list[1])\n",
    "plt.plot(valid_loss_list[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20a80e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_list[2])\n",
    "plt.plot(valid_loss_list[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0844b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_list[3])\n",
    "plt.plot(valid_loss_list[3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967cb3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_list[4])\n",
    "plt.plot(valid_loss_list[4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a30c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accs_list[0])\n",
    "plt.plot(valid_accs_list[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb4d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accs_list[1])\n",
    "plt.plot(valid_accs_list[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab39285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accs_list[2])\n",
    "plt.plot(valid_accs_list[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abbc85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accs_list[3])\n",
    "plt.plot(valid_accs_list[3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba0b821",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accs_list[4])\n",
    "plt.plot(valid_accs_list[4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e84a9f",
   "metadata": {},
   "source": [
    "# 결과 출력 -validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb4245e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델\n",
    "# pretrained\n",
    "\n",
    "class ResLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResLayer, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=True).cuda() \n",
    "        self.num_ftrs = self.model.fc.out_features\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.fc = nn.Sequential(       \n",
    "            nn.Linear(self.num_ftrs, 64),\n",
    "                             nn.BatchNorm1d(64),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(64,50),\n",
    "                             nn.BatchNorm1d(50),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(50,2)\n",
    "                            )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x  = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def model_initialize():\n",
    "    model = ResLayer().cuda()\n",
    "    return model\n",
    "\n",
    "model=model_initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53988588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default param\n",
    "mfcc_run_config = dict(\n",
    "    sr=16000,\n",
    "    n_mfcc=27,\n",
    "    #dct_type=3, # type2 default\n",
    "    lifter = 35,\n",
    "\n",
    "    \n",
    "    #mel spectro\n",
    "    n_mels=170,\n",
    "    hop_length=750,\n",
    "    n_fft =14056,    \n",
    "    win_length=1100,\n",
    "    f_max=8000,\n",
    "    \n",
    "    # training\n",
    "    #batch_size=32,\n",
    "    mel_scale ='htk',\n",
    "    \n",
    "    # data\n",
    "    fold=1,\n",
    ")\n",
    "\n",
    "mel_run_config = dict(\n",
    "    sr=16000,\n",
    "    n_mels=128,\n",
    "    win_length =  300,\n",
    "    n_fft= 2048,\n",
    "    hop_length= 50,\n",
    "    f_max = 8000    \n",
    ")\n",
    "\n",
    "\n",
    "spectro_run_config =dict(\n",
    "    sr=16000,\n",
    "    n_fft=350,\n",
    "    hop_length=50,\n",
    "    win_length=350,\n",
    "    # training\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bbbe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "classes = [\"healthy\",\"pathology\"]\n",
    "\n",
    "\n",
    "class svd_dataset_valid(Dataset):\n",
    "    def __init__(self,data_path_list,classes,data_num,training,mfcc_params,mel_params,spectro_params,transform=None,normalize=None,mfcc_normalize=None):\n",
    "        #클래스에서 사용할 인자를 받아 인스턴스 변수로 저장하는 일을 한다.\n",
    "        #예를들면, 이미지의 경로 리스트를 저장하는 일을 하게 된다.\n",
    "        \n",
    "        #data_num : k 개 데이터 셋 중 어떤것을 쓸지\n",
    "        #test인지 아닌지.\n",
    "        \n",
    "        self.path_list = data_path_list[data_num]\n",
    "        self.data_num = data_num\n",
    "        self.training = training\n",
    "        self.label = svd_dataset_valid.get_label(self.path_list,training,data_num)\n",
    "        self.classes=classes\n",
    "        self.transform=transform\n",
    "        self.normalize=normalize\n",
    "        self.mfcc_normalize = mfcc_normalize\n",
    "        # sweep params\n",
    "        self.mel_params = mel_params\n",
    "        self.spectro_params = spectro_params\n",
    "        self.mfcc_params = mfcc_params\n",
    "        #sr,n_mfcc,lifter, hop_length , win_length , n_mels , n_fft , f_max , batch_size\n",
    "\n",
    "        \n",
    "    \n",
    "    @classmethod\n",
    "    def get_label(cls,data_path_list,training,data_num):\n",
    "        label_list=[]\n",
    "        \n",
    "        if training:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_train_list[data_num][idx])\n",
    "        else:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_valid_list[data_num][idx])\n",
    "        #print(label_list)\n",
    "        return label_list\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "        #데이터 셋의 길이를 정수로 반환한다.     \n",
    "    \n",
    "       \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        1. path를 받아서, 소리에서 mfcc를 추출\n",
    "        2. mfcc를 224프레임으로 패딩.\n",
    "        3. resnet에 사용되기 위해 3채널로 복사(rgb 처럼)\n",
    "        4. 0~1 정규화\n",
    "        \n",
    "        \"\"\"\n",
    "        sig = phrase_dict[ str(self.path_list[idx])+'-phrase.wav'] \n",
    "        #sig = preemphasis(sig)\n",
    "        \n",
    "        origin_length = sig.shape[0]\n",
    "        \n",
    "        if sig.shape[0] > self.mfcc_params[\"sr\"]*2:\n",
    "            origin_length = self.mfcc_params[\"sr\"]*2\n",
    "        \n",
    "        origin_frame_size = 1 + int(np.floor(origin_length//self.mel_params[\"hop_length\"]))\n",
    "        \n",
    "        length = self.mfcc_params[\"sr\"]*2 #sample rate *2 padding을 위한 파라미터 (하이퍼 파라미터로인해 사이즈는 계속 바뀐다.)\n",
    "        pad1d = lambda a, i: a[0:i] if a.shape[0] > i else np.hstack((a, np.zeros((i-a.shape[0]))))        \n",
    "        sig = pad1d(sig,length)        \n",
    "        \n",
    "        ###signal norm\n",
    "        sig = (sig-sig.mean())/sig.std()\n",
    "        ###\n",
    "        \n",
    "        mel_feature = librosa.feature.melspectrogram(y=sig,\n",
    "                                                     sr=self.mel_params[\"sr\"],\n",
    "                                                     # hyp param\n",
    "                                                     n_mels = self.mel_params[\"n_mels\"],\n",
    "                                                     n_fft = self.mel_params[\"n_fft\"],\n",
    "                                                     win_length = self.mel_params[\"win_length\"],\n",
    "                                                     hop_length = self.mel_params[\"hop_length\"],\n",
    "                                                     fmax = self.mel_params[\"f_max\"]\n",
    "                                                    )\n",
    "        mel_feature = librosa.core.power_to_db(mel_feature,ref=np.max) \n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            mel_feature = self.transform(mel_feature).type(torch.float32)# 데이터 0~1 정규화\n",
    "            MSF = torch.stack([mel_feature, mel_feature, mel_feature])# 3채널로 복사.\n",
    "            MSF = MSF.squeeze(dim=1)    \n",
    "            \n",
    "            # global normalize\n",
    "            if self.normalize:\n",
    "                #MFCCs=self.normalize(MFCCs)\n",
    "                MSF = self.normalize(MSF)\n",
    "        else:\n",
    "            pass\n",
    "            #print(\"else\")\n",
    "            mel_feature = torch.from_numpy(mel_feature).type(torch.float32)\n",
    "            mel_feature = mel_feature.unsqueeze(0)#cnn 사용위해서 추가\n",
    "            #MFCCs = MFCCs.permute(2, 0, 1)\n",
    "        return MSF, self.classes.index(self.label[idx]),str(self.path_list[idx])+'-phrase.wav'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae6e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_filename=[]\n",
    "all_prediction=[]\n",
    "all_answers=[]\n",
    "\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "def valid_evaluate(model,data_ind):\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    predictions = []\n",
    "    answers = []\n",
    "    file_name = []\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    BATCH_SIZE=16\n",
    "\n",
    "    validation_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_dataset_valid(\n",
    "                                                   X_valid_list,\n",
    "                                                   classes,\n",
    "                                                   transform = transforms.ToTensor(),\n",
    "                                                   data_num=data_ind,\n",
    "                                                   #normalize=transforms.Normalize((-11.4805,-54.7723,-54.7723),(16.87,19.0226,19.0226)),\n",
    "                                                   #mfcc_normalize=(53.5582, 217.43),\n",
    "                                                   mfcc_params=mfcc_run_config,\n",
    "                                                   mel_params=mel_run_config,\n",
    "                                                   spectro_params=spectro_run_config,\n",
    "                                                   training=False\n",
    "                                               ),\n",
    "                                                    batch_size = BATCH_SIZE,\n",
    "                                                    shuffle = True,\n",
    "                                                    worker_init_fn=seed_worker)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for image,label,path_list in validation_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "            answers +=label\n",
    "            predictions +=prediction\n",
    "            file_name+=(path_list)\n",
    "        all_filename.append(file_name)\n",
    "        all_prediction.append(predictions)\n",
    "        all_answers.append(answers)\n",
    "    return predictions,answers,test_loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f542e566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번 모델\n",
      "Accuracy : 84.8624% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.8636\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.8407\n",
      "specificity : 0.8571%\n",
      "UAR : 0.8489%\n",
      "f score : 0.8485 \n",
      "[[90 15]\n",
      " [18 95]]\n",
      "-----\n",
      "2번 모델\n",
      "Accuracy : 87.8505% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.8707\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.9018\n",
      "specificity : 0.8529%\n",
      "UAR : 0.8774%\n",
      "f score : 0.8780 \n",
      "[[ 87  15]\n",
      " [ 11 101]]\n",
      "-----\n",
      "3번 모델\n",
      "Accuracy : 86.1702% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.8488\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.8488\n",
      "specificity : 0.8725%\n",
      "UAR : 0.8607%\n",
      "f score : 0.8607 \n",
      "[[89 13]\n",
      " [13 73]]\n",
      "-----\n",
      "4번 모델\n",
      "Accuracy : 88.8889% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.8642\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.8861\n",
      "specificity : 0.8911%\n",
      "UAR : 0.8886%\n",
      "f score : 0.8875 \n",
      "[[90 11]\n",
      " [ 9 70]]\n",
      "-----\n",
      "5번 모델\n",
      "Accuracy : 92.3858% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.9263\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.9167\n",
      "specificity : 0.9307%\n",
      "UAR : 0.9237%\n",
      "f score : 0.9238 \n",
      "[[94  7]\n",
      " [ 8 88]]\n",
      "-----\n",
      "평균 acc : 0.8803\n",
      "평균 UAR : 0.8798\n",
      "평균 f1score : 0.8797\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix (resnet18)\n",
    "# kfold의 confusion matrix는 계산 방법이 다르다.\n",
    "# 모델을 각각 불러와서 test set을 평가한다.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "cf = np.zeros((2,2))\n",
    "cf_list = []\n",
    "average_accuracy = 0\n",
    "average_fscore = 0\n",
    "average_uar = 0\n",
    "\n",
    "all_filename=[]\n",
    "all_prediction=[]\n",
    "all_answers=[]\n",
    "\n",
    "args={  'model':'baseline',\n",
    "        'seed':1004\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for data_ind in range(1,6):\n",
    "    model=model_initialize()\n",
    "    check_path = './checkpoint/checkpoint_ros_fold_'+str(data_ind)+'_'+args['model']+'_seed_'+str(args['seed'])+'_organics_speaker.pt'\n",
    "    model.load_state_dict(torch.load(check_path))\n",
    "\n",
    "    predictions,answers,valid_loss = valid_evaluate(model, data_ind-1)\n",
    "    predictions=[ dat.cpu().numpy() for dat in predictions]\n",
    "    answers=[ dat.cpu().numpy() for dat in answers]\n",
    "\n",
    "    \n",
    "    cf = confusion_matrix(answers, predictions)\n",
    "    cf_list.append(cf)\n",
    "    \n",
    "    acc = (cf[0,0]+cf[1,1])/(cf[0,0]+cf[0,1]+cf[1,0]+cf[1,1])\n",
    "    average_accuracy+=acc\n",
    "    \n",
    "    precision=cf[1,1]/(cf[0,1]+cf[1,1])\n",
    "    \n",
    "    recall=cf[1,1]/(cf[1,1]+cf[1,0])\n",
    "    \n",
    "    specificity=cf[0,0]/(cf[0,0]+cf[0,1])\n",
    "    average_uar += (specificity+recall)/2\n",
    "    \n",
    "    #fscroe macro추가\n",
    "    fscore = f1_score(answers,predictions,average='macro')\n",
    "    average_fscore+=fscore\n",
    "    \n",
    "    print('{}번 모델'.format(data_ind))\n",
    "    print(\"Accuracy : {:.4f}% \".format(acc*100))\n",
    "    print(\"Precision (pathology 예측한 것중 맞는 것) : {:.4f}\".format(precision))\n",
    "    print(\"recall (실제 pathology 중  예측이 맞는 것) : {:.4f}\".format(recall))\n",
    "    print(\"specificity : {:.4f}%\".format(specificity))\n",
    "    print(\"UAR : {:.4f}%\".format( (specificity+recall)/2 ))\n",
    "    \n",
    "    \n",
    "    print(\"f score : {:.4f} \".format(fscore))\n",
    "    print(cf)\n",
    "    print(\"-----\")\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "print(\"평균 acc : {:.4f}\".format(average_accuracy/5))\n",
    "print(\"평균 UAR : {:.4f}\".format(average_uar/5))\n",
    "print(\"평균 f1score : {:.4f}\".format(average_fscore/5))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb7b2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd19358",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_excel = []\n",
    "for i in range(5):\n",
    "    fold_excel.append(pd.DataFrame({'filename':all_filename[i],\n",
    "                  'prediction':[data.cpu().numpy().item() for data in all_prediction[i]],\n",
    "                  'answer':[ data.cpu().numpy().item() for data in all_answers[i]],\n",
    "                  'fold':i+1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afc7e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_excel_all=pd.concat(fold_excel,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d553f2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECORDING</th>\n",
       "      <th>PATHOLOGY</th>\n",
       "      <th>DATE</th>\n",
       "      <th>SPEAKER</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DETAIL</th>\n",
       "      <th>DIAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>715</td>\n",
       "      <td>p</td>\n",
       "      <td>20.05.1998</td>\n",
       "      <td>1407</td>\n",
       "      <td>w</td>\n",
       "      <td>63</td>\n",
       "      <td>Laryngitis; Leukoplakie</td>\n",
       "      <td>structural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1303</td>\n",
       "      <td>p</td>\n",
       "      <td>21.04.1999</td>\n",
       "      <td>1407</td>\n",
       "      <td>w</td>\n",
       "      <td>64</td>\n",
       "      <td>Leukoplakie</td>\n",
       "      <td>structural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1557</td>\n",
       "      <td>p</td>\n",
       "      <td>08.12.1999</td>\n",
       "      <td>1407</td>\n",
       "      <td>w</td>\n",
       "      <td>65</td>\n",
       "      <td>Leukoplakie</td>\n",
       "      <td>structural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1559</td>\n",
       "      <td>p</td>\n",
       "      <td>15.12.1999</td>\n",
       "      <td>1407</td>\n",
       "      <td>w</td>\n",
       "      <td>65</td>\n",
       "      <td>Leukoplakie</td>\n",
       "      <td>structural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1864</td>\n",
       "      <td>p</td>\n",
       "      <td>29.11.2000</td>\n",
       "      <td>1407</td>\n",
       "      <td>w</td>\n",
       "      <td>66</td>\n",
       "      <td>Leukoplakie</td>\n",
       "      <td>structural</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RECORDING PATHOLOGY        DATE  SPEAKER GENDER  AGE  \\\n",
       "0        715         p  20.05.1998     1407      w   63   \n",
       "1       1303         p  21.04.1999     1407      w   64   \n",
       "2       1557         p  08.12.1999     1407      w   65   \n",
       "3       1559         p  15.12.1999     1407      w   65   \n",
       "4       1864         p  29.11.2000     1407      w   66   \n",
       "\n",
       "                    DETAIL        DIAG  \n",
       "0  Laryngitis; Leukoplakie  structural  \n",
       "1              Leukoplakie  structural  \n",
       "2              Leukoplakie  structural  \n",
       "3              Leukoplakie  structural  \n",
       "4              Leukoplakie  structural  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_paper=pd.read_excel('D:/project/voice_pathology_ai/voice_data/only_organics_healthy.xlsx')\n",
    "answer_paper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c041ccab",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_paper['RECORDING']=answer_paper['RECORDING'].values.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f744d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_paper['RECORDING']=answer_paper['RECORDING']+'-phrase.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6390fe95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECORDING</th>\n",
       "      <th>DETAIL</th>\n",
       "      <th>AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>715-phrase.wav</td>\n",
       "      <td>Laryngitis; Leukoplakie</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1303-phrase.wav</td>\n",
       "      <td>Leukoplakie</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1557-phrase.wav</td>\n",
       "      <td>Leukoplakie</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1559-phrase.wav</td>\n",
       "      <td>Leukoplakie</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1864-phrase.wav</td>\n",
       "      <td>Leukoplakie</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>80-phrase.wav</td>\n",
       "      <td>control</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>81-phrase.wav</td>\n",
       "      <td>control</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>82-phrase.wav</td>\n",
       "      <td>control</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>83-phrase.wav</td>\n",
       "      <td>control</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>153-phrase.wav</td>\n",
       "      <td>control</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1466 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            RECORDING                   DETAIL  AGE\n",
       "0      715-phrase.wav  Laryngitis; Leukoplakie   63\n",
       "1     1303-phrase.wav              Leukoplakie   64\n",
       "2     1557-phrase.wav              Leukoplakie   65\n",
       "3     1559-phrase.wav              Leukoplakie   65\n",
       "4     1864-phrase.wav              Leukoplakie   66\n",
       "...               ...                      ...  ...\n",
       "1461    80-phrase.wav                  control   49\n",
       "1462    81-phrase.wav                  control   42\n",
       "1463    82-phrase.wav                  control   49\n",
       "1464    83-phrase.wav                  control   46\n",
       "1465   153-phrase.wav                  control   60\n",
       "\n",
       "[1466 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_paper[['RECORDING','DETAIL','AGE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623c791c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>prediction</th>\n",
       "      <th>answer</th>\n",
       "      <th>fold</th>\n",
       "      <th>RECORDING</th>\n",
       "      <th>DETAIL</th>\n",
       "      <th>AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>946-phrase.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>946-phrase.wav</td>\n",
       "      <td>control</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94-phrase.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>94-phrase.wav</td>\n",
       "      <td>control</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>876-phrase.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>876-phrase.wav</td>\n",
       "      <td>Diplophonie; Kontaktpachydermie</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1181-phrase.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1181-phrase.wav</td>\n",
       "      <td>control</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2028-phrase.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2028-phrase.wav</td>\n",
       "      <td>Dysphonie; Laryngitis</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>1967-phrase.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1967-phrase.wav</td>\n",
       "      <td>Kontaktpachydermie</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>21-phrase.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>21-phrase.wav</td>\n",
       "      <td>control</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>2498-phrase.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2498-phrase.wav</td>\n",
       "      <td>Kontaktpachydermie</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2375-phrase.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2375-phrase.wav</td>\n",
       "      <td>Reinke ?em</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>680-phrase.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>680-phrase.wav</td>\n",
       "      <td>control</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>997 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  prediction  answer  fold        RECORDING  \\\n",
       "0     946-phrase.wav           0       0     1   946-phrase.wav   \n",
       "1      94-phrase.wav           1       0     1    94-phrase.wav   \n",
       "2     876-phrase.wav           1       1     1   876-phrase.wav   \n",
       "3    1181-phrase.wav           0       0     1  1181-phrase.wav   \n",
       "4    2028-phrase.wav           1       1     1  2028-phrase.wav   \n",
       "..               ...         ...     ...   ...              ...   \n",
       "992  1967-phrase.wav           1       1     5  1967-phrase.wav   \n",
       "993    21-phrase.wav           0       0     5    21-phrase.wav   \n",
       "994  2498-phrase.wav           0       1     5  2498-phrase.wav   \n",
       "995  2375-phrase.wav           1       1     5  2375-phrase.wav   \n",
       "996   680-phrase.wav           0       0     5   680-phrase.wav   \n",
       "\n",
       "                              DETAIL  AGE  \n",
       "0                            control   37  \n",
       "1                            control   55  \n",
       "2    Diplophonie; Kontaktpachydermie   73  \n",
       "3                            control   32  \n",
       "4              Dysphonie; Laryngitis   36  \n",
       "..                               ...  ...  \n",
       "992               Kontaktpachydermie   60  \n",
       "993                          control   20  \n",
       "994               Kontaktpachydermie   29  \n",
       "995                       Reinke ?em   52  \n",
       "996                          control   20  \n",
       "\n",
       "[997 rows x 7 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_left = pd.merge(fold_excel_all,answer_paper[['RECORDING','DETAIL','AGE']], how='left', left_on='filename', right_on='RECORDING')\n",
    "merge_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7224bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_left.drop(['RECORDING'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95705a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_left['result']=merge_left['prediction']==merge_left['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71de1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>prediction</th>\n",
       "      <th>answer</th>\n",
       "      <th>fold</th>\n",
       "      <th>DETAIL</th>\n",
       "      <th>AGE</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>946-phrase.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>control</td>\n",
       "      <td>37</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94-phrase.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>control</td>\n",
       "      <td>55</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>876-phrase.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Diplophonie; Kontaktpachydermie</td>\n",
       "      <td>73</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1181-phrase.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>control</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2028-phrase.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dysphonie; Laryngitis</td>\n",
       "      <td>36</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>1967-phrase.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Kontaktpachydermie</td>\n",
       "      <td>60</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>21-phrase.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>control</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>2498-phrase.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Kontaktpachydermie</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2375-phrase.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Reinke ?em</td>\n",
       "      <td>52</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>680-phrase.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>control</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>997 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  prediction  answer  fold  \\\n",
       "0     946-phrase.wav           0       0     1   \n",
       "1      94-phrase.wav           1       0     1   \n",
       "2     876-phrase.wav           1       1     1   \n",
       "3    1181-phrase.wav           0       0     1   \n",
       "4    2028-phrase.wav           1       1     1   \n",
       "..               ...         ...     ...   ...   \n",
       "992  1967-phrase.wav           1       1     5   \n",
       "993    21-phrase.wav           0       0     5   \n",
       "994  2498-phrase.wav           0       1     5   \n",
       "995  2375-phrase.wav           1       1     5   \n",
       "996   680-phrase.wav           0       0     5   \n",
       "\n",
       "                              DETAIL  AGE  result  \n",
       "0                            control   37    True  \n",
       "1                            control   55   False  \n",
       "2    Diplophonie; Kontaktpachydermie   73    True  \n",
       "3                            control   32    True  \n",
       "4              Dysphonie; Laryngitis   36    True  \n",
       "..                               ...  ...     ...  \n",
       "992               Kontaktpachydermie   60    True  \n",
       "993                          control   20    True  \n",
       "994               Kontaktpachydermie   29   False  \n",
       "995                       Reinke ?em   52    True  \n",
       "996                          control   20    True  \n",
       "\n",
       "[997 rows x 7 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86057b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_name = 'D:/project/voice_pathology_ai/voice_data/'+args['model']+'_seed_'+str(args['seed'])+'_organics_speaker.xlsx'\n",
    "merge_left.to_excel(excel_name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a27fad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "561.143px",
    "left": "22px",
    "top": "111.143px",
    "width": "255.025px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "427fa2592f9d0b947426e18ee897f81f41d4196bbcbbd4ad171fc20ee58cf88d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
