{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5180db41",
   "metadata": {},
   "source": [
    "# a, phrase 퓨전\n",
    "\n",
    "2023-01-05\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6505136e",
   "metadata": {},
   "source": [
    "- http://keunwoochoi.blogspot.com/2016/03/2.html\n",
    "- http://www.rex-ai.info/docs/AI_Example_CNN_speech_recognize\n",
    "- https://www.youtube.com/watch?v=oltGIc4uo5c\n",
    "- https://youdaeng-com.tistory.com/5\n",
    "- https://quokkas.tistory.com/37 : early stopping\n",
    "- https://continuous-development.tistory.com/166 : stratified kfold\n",
    "- https://deep-learning-study.tistory.com/476 fiter 시각화\n",
    "- https://wyatt37.tistory.com/10 : random over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20cf3fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbub3690\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\project\\voice_pathology_ai\\model\\Module\\wandb\\run-20230104_154307-3761w1cv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/bub3690/SVD-voice-disorder/runs/3761w1cv\" target=\"_blank\">firm-flower-336</a></strong> to <a href=\"https://wandb.ai/bub3690/SVD-voice-disorder\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project=\"SVD-voice-disorder\", entity=\"bub3690\")\n",
    "wandb.run.name = 'wavegram-organics-speaker'\n",
    "wandb.run.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "275b8092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pytorch version :  1.10.2  Device :  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn # 인공 신경망 모델들 모아놓은 모듈\n",
    "import torch.nn.functional as F #그중 자주 쓰이는것들을 F로\n",
    "from torchvision import transforms, datasets\n",
    "import cv2\n",
    "from torchvision import transforms, datasets\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "\n",
    "from Utils.pytorchtools import EarlyStopping # 상위 폴더에 추가된 모듈.\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "#DEVICE = torch.device('cpu')\n",
    "print('Using Pytorch version : ',torch.__version__,' Device : ',DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0081a011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x17050d9baf0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchaudio\n",
    "#import torchaudio.functional as F\n",
    "import torchaudio.transforms as T\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ebea6",
   "metadata": {},
   "source": [
    "# SVD 문장 데이터에서 Feature 추출\n",
    "- mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dddaab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa, librosa.display \n",
    "import matplotlib.pyplot as plt\n",
    "#window sizde : FFT를 할때 참조할 그래프 길이 ( 프레임 하나당 sample 수 )\n",
    "#자연어 처리에서는 25ms 사용. https://ahnjg.tistory.com/93\n",
    "#초당 50000hz 중 1250개씩 윈도우 사이즈로 사용.\n",
    "\n",
    "\n",
    "#default param\n",
    "mfcc_run_config = dict(\n",
    "    sr=16000,\n",
    "    n_mfcc=27,\n",
    "    #dct_type=3, # type2 default\n",
    "    lifter = 35,\n",
    "\n",
    "    \n",
    "    #mel spectro\n",
    "    n_mels=170,\n",
    "    hop_length=750,\n",
    "    n_fft =14056,    \n",
    "    win_length=1100,\n",
    "    f_max=8000,\n",
    "    \n",
    "    # training\n",
    "    #batch_size=32,\n",
    "    mel_scale ='htk',\n",
    "    \n",
    "    # data\n",
    "    fold=1,\n",
    ")\n",
    "\n",
    "mel_run_config = dict(\n",
    "    sr=16000,\n",
    "    n_mels=128,\n",
    "    win_length =  300,\n",
    "    n_fft= 2048,\n",
    "    hop_length= 50,\n",
    "    f_max = 8000    \n",
    ")\n",
    "\n",
    "\n",
    "spectro_run_config =dict(\n",
    "    sr=16000,\n",
    "    n_fft=350,\n",
    "    hop_length=50,\n",
    "    win_length=350,\n",
    "    # training\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a38dcdc",
   "metadata": {},
   "source": [
    "# 데이터 나누기 - Stratified KFold\n",
    "\n",
    "- pathology : 1194 / healthy : 634 / 총 1828\n",
    "- k = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a148977",
   "metadata": {},
   "source": [
    "## 1. test/ train 나누기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c150342",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_data=pd.read_excel(\"../../voice_data/only_organics_healthy_available.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "503fc854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "427\n",
      "630\n"
     ]
    }
   ],
   "source": [
    "pathology = speaker_data[speaker_data['PATHOLOGY']=='p']['SPEAKER'].unique().tolist()\n",
    "healthy = speaker_data[speaker_data['PATHOLOGY']=='n']['SPEAKER'].unique().tolist()\n",
    "print(len(pathology))\n",
    "print(len(healthy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c45e9ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#겹치는 speaker는 곱하기 100을 해준다.\n",
    "#3명이 겹친다.\n",
    "changed_patients = list(set(healthy) & set(pathology))\n",
    "\n",
    "for patient in changed_patients:\n",
    "    temp=pathology[pathology.index(patient)]*100\n",
    "    pathology[pathology.index(patient)] = temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c72d82e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 데이터수 :  1057\n",
      "---\n",
      "훈련 셋 :  845 Counter({'healthy': 504, 'pathology': 341})\n",
      "테스트 셋 :  212 Counter({'healthy': 126, 'pathology': 86})\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "#train test 나누기\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split # train , test 분리에 사용.\n",
    "\n",
    "\n",
    "random_state = 1004 # 1004,1005,1006,1007,1008\n",
    "\n",
    "X = pathology+healthy # path 데이터 합\n",
    "print(\"총 데이터수 : \",len(X))\n",
    "Y = [] # 라벨\n",
    "for idx,x in enumerate(X):\n",
    "    if idx<427:\n",
    "        Y.append(\"pathology\")\n",
    "    else:\n",
    "        Y.append(\"healthy\")\n",
    "\n",
    "X, X_test, Y, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True, stratify=Y, random_state=random_state) #456\n",
    "#stratify를 넣어서, test에도 라벨별 잘 분류되게 한다.\n",
    "\n",
    "print(\"---\")\n",
    "print(\"훈련 셋 : \",len(Y),Counter(Y))\n",
    "print(\"테스트 셋 : \",len(Y_test),Counter(Y_test))\n",
    "print(\"---\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a99443",
   "metadata": {},
   "source": [
    "## 2. stratified k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c38ceb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 : 1\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 403, 'pathology': 273}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 101, 'pathology': 68} \n",
      "\n",
      "교차 검증 : 2\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 403, 'pathology': 273}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 101, 'pathology': 68} \n",
      "\n",
      "교차 검증 : 3\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 403, 'pathology': 273}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 101, 'pathology': 68} \n",
      "\n",
      "교차 검증 : 4\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 403, 'pathology': 273}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 101, 'pathology': 68} \n",
      "\n",
      "교차 검증 : 5\n",
      "학습 레이블 데이터 분포 : \n",
      " {'healthy': 404, 'pathology': 272}\n",
      "검증 레이블 데이터 분포 : \n",
      " {'healthy': 100, 'pathology': 69} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. train, test 나누기\n",
    "#stratified kfold\n",
    "import os\n",
    "import random #데이터 shuffle 사용\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n",
    "skf_iris = StratifiedKFold(n_splits=5,shuffle=True,random_state=456)\n",
    "cnt_iter = 0\n",
    "\n",
    "X_train_list = [] #데이터 셋 보관\n",
    "Y_train_list = []\n",
    "\n",
    "X_valid_list = []\n",
    "Y_valid_list = []\n",
    "\n",
    "for train_idx, test_idx in skf_iris.split(X,Y):\n",
    "    \n",
    "    #split으로 반환된 인덱스를 이용하여, 학습 검증용 테스트 데이터 추출\n",
    "    cnt_iter += 1\n",
    "    X_train, X_valid = [X[idx] for idx in train_idx.tolist() ], [X[idx] for idx in test_idx.tolist() ]\n",
    "    Y_train, Y_valid = [Y[idx] for idx in train_idx.tolist() ], [Y[idx] for idx in test_idx.tolist() ]\n",
    "    \n",
    "    X_train_list.append(X_train)\n",
    "    X_valid_list.append(X_valid)\n",
    "    \n",
    "    Y_train_list.append(Y_train)\n",
    "    Y_valid_list.append(Y_valid)\n",
    "    \n",
    "    \n",
    "    #학습 및 예측\n",
    "    \n",
    "    label_train = Y_train\n",
    "    label_test = Y_valid\n",
    "    unique_train, train_counts = np.unique(label_train, return_counts = True)\n",
    "    unique_test, test_counts = np.unique(label_test, return_counts = True)\n",
    "    \n",
    "    uniq_cnt_train = dict(zip(unique_train, train_counts))\n",
    "    uniq_cnt_test = dict(zip(unique_test, test_counts))\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('교차 검증 : {}'.format(cnt_iter))\n",
    "    print('학습 레이블 데이터 분포 : \\n', uniq_cnt_train)\n",
    "    print('검증 레이블 데이터 분포 : \\n', uniq_cnt_test,'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbcb94b",
   "metadata": {},
   "source": [
    "# speaker to voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f725375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# speaker to voice\n",
    "\n",
    "all_train_record_list = []\n",
    "all_valid_record_list = []\n",
    "all_test_record_list = []\n",
    "\n",
    "all_train_label_list = []\n",
    "all_valid_label_list = []\n",
    "all_test_label_list = []\n",
    "\n",
    "#train\n",
    "for fold_idx,fold in enumerate(X_train_list):\n",
    "    fold_record=[]\n",
    "    fold_y_record=[]\n",
    "    for idx,speaker in enumerate(fold):\n",
    "        record_list = speaker_data[speaker_data['SPEAKER']==speaker]['RECORDING'].tolist()\n",
    "        label_list = [ Y_train_list[fold_idx][idx] ] * len(record_list)\n",
    "        \n",
    "        fold_record += record_list\n",
    "        fold_y_record += label_list\n",
    "    all_train_record_list.append(fold_record)\n",
    "    all_train_label_list.append(fold_y_record)\n",
    "\n",
    "    \n",
    "#valid\n",
    "for fold_idx,fold in enumerate(X_valid_list):\n",
    "    fold_record=[]\n",
    "    fold_y_record=[]\n",
    "    for idx,speaker in enumerate(fold):\n",
    "        record_list = speaker_data[speaker_data['SPEAKER']==speaker]['RECORDING'].tolist()\n",
    "        label_list = [ Y_valid_list[fold_idx][idx] ] * len(record_list)\n",
    "        \n",
    "        fold_record += record_list\n",
    "        fold_y_record += label_list\n",
    "    all_valid_record_list.append(fold_record)\n",
    "    all_valid_label_list.append(fold_y_record)\n",
    "    \n",
    "#test\n",
    "fold_record=[]\n",
    "fold_y_record=[]\n",
    "for idx,speaker in enumerate(X_test):\n",
    "    record_list = speaker_data[speaker_data['SPEAKER']==speaker]['RECORDING'].tolist()\n",
    "    label_list = [ Y_test[idx] ] * len(record_list)\n",
    "    fold_record += record_list\n",
    "    fold_y_record += label_list\n",
    "all_test_record_list = fold_record\n",
    "all_test_label_list = fold_y_record\n",
    "\n",
    "\n",
    "X_train_list = all_train_record_list\n",
    "X_valid_list = all_valid_record_list\n",
    "X_test = all_test_record_list\n",
    "\n",
    "Y_train_list = all_train_label_list\n",
    "Y_valid_list = all_valid_label_list\n",
    "Y_test = all_test_label_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0880b5c",
   "metadata": {},
   "source": [
    "## 3. random over sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9517c16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " fold0 \n",
      "before dataset shape Counter({'healthy': 406, 'pathology': 373})\n",
      "Resampled dataset shape Counter({'healthy': 406, 'pathology': 406})\n",
      "\n",
      " fold1 \n",
      "before dataset shape Counter({'healthy': 409, 'pathology': 374})\n",
      "Resampled dataset shape Counter({'healthy': 409, 'pathology': 409})\n",
      "\n",
      " fold2 \n",
      "before dataset shape Counter({'healthy': 409, 'pathology': 400})\n",
      "Resampled dataset shape Counter({'healthy': 409, 'pathology': 409})\n",
      "\n",
      " fold3 \n",
      "before dataset shape Counter({'healthy': 410, 'pathology': 407})\n",
      "Resampled dataset shape Counter({'healthy': 410, 'pathology': 410})\n",
      "\n",
      " fold4 \n",
      "before dataset shape Counter({'healthy': 410, 'pathology': 390})\n",
      "Resampled dataset shape Counter({'pathology': 410, 'healthy': 410})\n"
     ]
    }
   ],
   "source": [
    "#2. random over sampling\n",
    "for i in range(5):\n",
    "    X_temp = np.array(X_train_list[i]).reshape(-1,1)#각 데이터를 다 행으로 넣음. (1194,1)\n",
    "    #Y = np.array(Y)\n",
    "    ros = RandomOverSampler(random_state = 123)\n",
    "    X_res,Y_res = ros.fit_resample(X_temp,Y_train_list[i])\n",
    "    \n",
    "    print(\"\\n fold{} \".format(i))\n",
    "    print('before dataset shape {}'.format(Counter(Y_train_list[i])) )\n",
    "    print('Resampled dataset shape {}'.format(Counter(Y_res)) )   \n",
    "    \n",
    "    #원래대로 돌리기\n",
    "    X_res=X_res.reshape(1, -1)\n",
    "    X_train_list[i]=X_res[0].tolist()\n",
    "    Y_train_list[i]=Y_res\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "478af061",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../voice_data/organics_ver2/phrase_sig_dict.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18848/1296989731.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../../voice_data/organics_ver2/phrase_sig_dict.pickle\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mphrase_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../voice_data/organics_ver2/phrase_sig_dict.pickle'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "    \n",
    "#load\n",
    "with open(\"../../voice_data/organics_ver2/phrase_sig_dict.pickle\",\"rb\") as fr:\n",
    "    phrase_dict = pickle.load(fr)\n",
    "\n",
    "#with open(\"../../voice_data/organics/phrase_minmax_scaler_hyper.pickle\",\"rb\") as fr:\n",
    "#    phrase_scaler = pickle.load(fr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44f957ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load\n",
    "with open(\"../../voice_data/organics_ver2/phrase_dict_ver2_EGG.pickle\",\"rb\") as fr:\n",
    "    phrase_egg_dict = pickle.load(fr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a663f0",
   "metadata": {},
   "source": [
    "# 데이터 정의\n",
    "- 추가적으로 데이터의 크기를 맞춰주기 위해 3초로 padding 및 truncate 실시 https://sequencedata.tistory.com/25 FixAudioLength\n",
    "- 논문에서는 400frame으로 설정.(여기서는 500frame)\n",
    "- 전처리 방법 결정.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56df016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8877544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default param\n",
    "mfcc_run_config = dict(\n",
    "    sr=16000,\n",
    "    n_mfcc=27,\n",
    "    #dct_type=3, # type2 default\n",
    "    lifter = 35,\n",
    "\n",
    "    \n",
    "    #mel spectro\n",
    "    n_mels=170,\n",
    "    hop_length=750,\n",
    "    n_fft =14056,    \n",
    "    win_length=1100,\n",
    "    f_max=8000,\n",
    "    \n",
    "    # training\n",
    "    #batch_size=32,\n",
    "    mel_scale ='htk',\n",
    "    \n",
    "    # data\n",
    "    fold=1,\n",
    ")\n",
    "\n",
    "mel_run_config = dict(\n",
    "    sr=16000,\n",
    "    n_mels=128,\n",
    "    win_length =  300,\n",
    "    n_fft= 2048,\n",
    "    hop_length= 50,\n",
    "    f_max = 8000    \n",
    ")\n",
    "\n",
    "\n",
    "spectro_run_config =dict(\n",
    "    sr=16000,\n",
    "    n_fft=350,\n",
    "    hop_length=50,\n",
    "    win_length=350,\n",
    "    # training\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2febf8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "classes = [\"healthy\",\"pathology\"]\n",
    "\n",
    "\n",
    "class svd_dataset(Dataset):\n",
    "    def __init__(self,data_path_list,classes,data_num,training,mfcc_params,mel_params,spectro_params,transform=None,normalize=None,mfcc_normalize=None):\n",
    "        #클래스에서 사용할 인자를 받아 인스턴스 변수로 저장하는 일을 한다.\n",
    "        #예를들면, 이미지의 경로 리스트를 저장하는 일을 하게 된다.\n",
    "        \n",
    "        #data_num : k 개 데이터 셋 중 어떤것을 쓸지\n",
    "        #test인지 아닌지.\n",
    "        \n",
    "        self.path_list = data_path_list[data_num]\n",
    "        self.data_num = data_num\n",
    "        self.training = training\n",
    "        self.label = svd_dataset.get_label(self.path_list,training,data_num)\n",
    "        self.classes=classes\n",
    "        self.transform=transform\n",
    "        self.normalize=normalize\n",
    "        self.mfcc_normalize = mfcc_normalize\n",
    "        # sweep params\n",
    "        self.mel_params = mel_params\n",
    "        self.spectro_params = spectro_params\n",
    "        self.mfcc_params = mfcc_params\n",
    "        #sr,n_mfcc,lifter, hop_length , win_length , n_mels , n_fft , f_max , batch_size\n",
    "\n",
    "        \n",
    "    \n",
    "    @classmethod\n",
    "    def get_label(cls,data_path_list,training,data_num):\n",
    "        label_list=[]\n",
    "        \n",
    "        if training:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_train_list[data_num][idx])\n",
    "        else:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_valid_list[data_num][idx])\n",
    "        #print(label_list)\n",
    "        return label_list\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "        #데이터 셋의 길이를 정수로 반환한다.     \n",
    "    \n",
    "       \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        1. path를 받아서, 소리에서 mfcc를 추출\n",
    "        2. mfcc를 224프레임으로 패딩.\n",
    "        3. resnet에 사용되기 위해 3채널로 복사(rgb 처럼)\n",
    "        4. 0~1 정규화\n",
    "        \n",
    "        \"\"\"\n",
    "        sig = phrase_dict[ str(self.path_list[idx])+'-phrase.wav'] \n",
    "\n",
    "        sig_egg = phrase_egg_dict[str(self.path_list[idx])+'-phrase-egg.wav']\n",
    "        #sig = preemphasis(sig)\n",
    "        \n",
    "        origin_length = sig.shape[0]\n",
    "        \n",
    "        if sig.shape[0] > self.mfcc_params[\"sr\"]*2:\n",
    "            origin_length = self.mfcc_params[\"sr\"]*2\n",
    "        \n",
    "        origin_frame_size = 1 + int(np.floor(origin_length//self.mel_params[\"hop_length\"]))\n",
    "        \n",
    "        length = self.mfcc_params[\"sr\"]*2 #sample rate *2 padding을 위한 파라미터 (하이퍼 파라미터로인해 사이즈는 계속 바뀐다.)\n",
    "        pad1d = lambda a, i: a[0:i] if a.shape[0] > i else np.hstack((a, np.zeros((i-a.shape[0]))))        \n",
    "        \n",
    "        sig = pad1d(sig,length)\n",
    "        sig_egg = pad1d(sig_egg,length)     \n",
    "        \n",
    "        ###signal norm\n",
    "        #sig = (sig-sig.mean())/sig.std()\n",
    "\n",
    "        ###\n",
    "        sig=torch.from_numpy(sig).type(torch.float32)# 타입 변화\n",
    "        sig=sig.unsqueeze(0)\n",
    "\n",
    "        sig_egg=torch.from_numpy(sig_egg).type(torch.float32)# 타입 변화\n",
    "        sig_egg=sig_egg.unsqueeze(0)\n",
    "        \n",
    "        \n",
    "        return sig,sig_egg, self.classes.index(self.label[idx])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f198f535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set 제작을 위한 class\n",
    "class svd_test_set(Dataset):\n",
    "    def __init__(self,data_path_list,classes,mfcc_params,mel_params,spectro_params,transform=None,normalize=None,mfcc_normalize=None):\n",
    "        #클래스에서 사용할 인자를 받아 인스턴스 변수로 저장하는 일을 한다.\n",
    "        #예를들면, 이미지의 경로 리스트를 저장하는 일을 하게 된다.\n",
    "        \n",
    "        #data_num : k 개 데이터 셋 중 어떤것을 쓸지\n",
    "        #test인지 아닌지.\n",
    "        \n",
    "        self.path_list = data_path_list\n",
    "        self.label = svd_test_set.get_label(self.path_list)\n",
    "        self.classes=classes\n",
    "        self.transform=transform\n",
    "        self.normalize=normalize\n",
    "        self.mfcc_normalize = mfcc_normalize        \n",
    "        \n",
    "        # sweep params\n",
    "        self.mel_params = mel_params\n",
    "        self.spectro_params = spectro_params\n",
    "        self.mfcc_params = mfcc_params\n",
    "        #sr,n_mfcc,lifter, hop_length , win_length , n_mels , n_fft , f_max , batch_size           \n",
    "    \n",
    "    @classmethod\n",
    "    def get_label(cls,data_path_list):\n",
    "        label_list=[]\n",
    "        \n",
    "        for idx,x in enumerate(data_path_list):\n",
    "            label_list.append(Y_test[idx])\n",
    "        #print(label_list)\n",
    "        return label_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "        #데이터 셋의 길이를 정수로 반환한다. \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        1. path를 받아서, 소리에서 mfcc를 추출\n",
    "        2. mfcc를 224프레임으로 패딩.\n",
    "        3. resnet에 사용되기 위해 3채널로 복사(rgb 처럼)\n",
    "        4. 0~1 정규화\n",
    "        \n",
    "        \"\"\"\n",
    "        sig = phrase_dict[ str(self.path_list[idx])+'-phrase.wav'] \n",
    "        #sig = preemphasis(sig)\n",
    "        \n",
    "        origin_length = sig.shape[0]\n",
    "        \n",
    "        if sig.shape[0] > self.mfcc_params[\"sr\"]*2:\n",
    "            origin_length = self.mfcc_params[\"sr\"]*2\n",
    "        \n",
    "        origin_frame_size = 1 + int(np.floor(origin_length//self.mel_params[\"hop_length\"]))\n",
    "        \n",
    "        length = self.mfcc_params[\"sr\"]*2 #sample rate *2 padding을 위한 파라미터 (하이퍼 파라미터로인해 사이즈는 계속 바뀐다.)\n",
    "        pad1d = lambda a, i: a[0:i] if a.shape[0] > i else np.hstack((a, np.zeros((i-a.shape[0]))))        \n",
    "        sig = pad1d(sig,length)        \n",
    "        \n",
    "        ###signal norm\n",
    "        sig = (sig-sig.mean())/sig.std()\n",
    "        ###\n",
    "        sig=torch.from_numpy(sig).type(torch.float32)# 타입 변화\n",
    "        sig=sig.unsqueeze(0)\n",
    "        \n",
    "        return sig, self.classes.index(self.label[idx])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074e2949",
   "metadata": {},
   "source": [
    "# 데이터로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "272bc789",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. 하이퍼 파라미터\n",
    "BATCH_SIZE =  16 #한 배치당 32개 음성데이터\n",
    "EPOCHS = 50 # 전체 데이터 셋을 50번 반복\n",
    "lr=1e-4\n",
    "augment_kind=\"no\"\n",
    "weight_decay = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10fec835",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config.update({\n",
    "    \"learning_rate\": lr,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"augment\":augment_kind,\n",
    "    \"weight_decay\":weight_decay,\n",
    "    \"특이사항\":\"fmax 8000. speaker indep.\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bba97b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA LOADER 함수가 BATCH_size 단위로 분리해 지정.\n",
    "\n",
    "#확인을 위해 데이터셋 하나만 확인\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                           svd_dataset(\n",
    "                                               X_train_list,\n",
    "                                               classes,\n",
    "                                               transform = transforms.ToTensor(),#이걸 composed로 고쳐서 전처리 하도록 수정. to tensor는 -데이터는 노멀라이즈못함.\n",
    "                                               #normalize=transforms.Normalize((-11.4805,-54.7723,-54.7723),(16.87,19.0226,19.0226)),\n",
    "                                               #mfcc_normalize=(53.5582, 217.43),\n",
    "                                               mfcc_params=mfcc_run_config,\n",
    "                                               mel_params=mel_run_config,\n",
    "                                               spectro_params=spectro_run_config,\n",
    "                                               data_num=0,\n",
    "                                               training=True\n",
    "                                           ),\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True,\n",
    "                                           ) # 순서가 암기되는것을 막기위해.\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                           svd_dataset(\n",
    "                                               X_valid_list,\n",
    "                                               classes,\n",
    "                                               transform = transforms.ToTensor(),\n",
    "                                               #normalize=transforms.Normalize((-11.4805,-54.7723,-54.7723),(16.87,19.0226,19.0226)),\n",
    "                                               #mfcc_normalize=(53.5582, 217.43),\n",
    "                                               mfcc_params=mfcc_run_config,\n",
    "                                               mel_params=mel_run_config,\n",
    "                                               spectro_params=spectro_run_config,\n",
    "                                               data_num=0,\n",
    "                                               training=False\n",
    "                                           ),\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True,) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9761d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 로더.\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_test_set(\n",
    "                                                   X_test,\n",
    "                                                   classes,\n",
    "                                                   #normalize=transforms.Normalize((-11.4805,-54.7723,-54.7723),(16.87,19.0226,19.0226)),                                               \n",
    "                                                   #mfcc_normalize=(53.5582, 217.43),\n",
    "                                                   mfcc_params=mfcc_run_config,\n",
    "                                                   mel_params=mel_run_config,\n",
    "                                                   spectro_params=spectro_run_config,\n",
    "                                                   transform = transforms.ToTensor(),\n",
    "                                               ),\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = True,) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b15a86",
   "metadata": {},
   "source": [
    "# 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22bdb134",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sr=16000\n",
    "win_length =  mel_run_config[\"win_length\"] # 400\n",
    "n_fft= mel_run_config[\"n_fft\"] # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding. 세로 길이\n",
    "hop_length=mel_run_config[\"hop_length\"] #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다.\n",
    "\n",
    "spectro_win_length =  spectro_run_config[\"win_length\"] # 400\n",
    "spectro_n_fft= spectro_run_config[\"n_fft\"] # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding. 세로 길이\n",
    "spectro_hop_length= spectro_run_config[\"hop_length\"] #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e879c26",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :  torch.Size([16, 1, 32000]) type: torch.FloatTensor\n",
      "Y_train :  torch.Size([16]) type: torch.LongTensor\n",
      "tensor(0)\n",
      "tensor([[ 0.0052,  0.0128,  0.0088,  ..., -0.5957, -0.6097, -0.6255]])\n"
     ]
    }
   ],
   "source": [
    "## 4. 데이터 확인하기\n",
    "for (X_train,Y_train) in train_loader:\n",
    "    print(\"X_train : \",X_train.size(),'type:',X_train.type())\n",
    "    print(\"Y_train : \",Y_train.size(),'type:',Y_train.type())\n",
    "    break\n",
    "\n",
    "print(Y_train[0])\n",
    "print(X_train[0])\n",
    "#batch: 32 / 3채널 / frame수: 500  /  feature수: 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b29c510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_valid :  torch.Size([16, 1, 32000]) type: torch.FloatTensor\n",
      "Y_valid :  torch.Size([16]) type: torch.LongTensor\n",
      "tensor([[ 0.1003,  0.1670,  0.1439,  ..., -0.0082, -0.0082, -0.0082]])\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "#valiation set 확인\n",
    "for (X_valid,Y_valid) in validation_loader:\n",
    "    print(\"X_valid : \",X_valid.size(),'type:',X_valid.type())\n",
    "    print(\"Y_valid : \",Y_valid.size(),'type:',Y_valid.type())\n",
    "    break\n",
    "\n",
    "\n",
    "print(X_valid[0])\n",
    "print(Y_valid[0])\n",
    "\n",
    "#batch: 32 / 3채널 / frame수: 500  /  feature수: 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14a38987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test :  torch.Size([16, 1, 32000]) type: torch.FloatTensor\n",
      "Y_test :  torch.Size([16]) type: torch.LongTensor\n",
      "tensor([[-0.1075, -0.1591, -0.1425,  ..., -0.0167, -0.0167, -0.0167]])\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "#test set 확인\n",
    "for (test_data,test_label) in test_loader:\n",
    "    print(\"X_test : \",test_data.size(),'type:',test_data.type())\n",
    "    print(\"Y_test : \",test_label.size(),'type:',test_label.type())\n",
    "    break\n",
    "\n",
    "print(test_data[0])\n",
    "print(test_label[0])\n",
    "\n",
    "#batch: 32 / 3채널 / frame수: 500  /  feature수: 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd682ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32000])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0].size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fec40ea4",
   "metadata": {},
   "source": [
    "# TGRAM NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "965fed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResLayer, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=True).cuda() \n",
    "        self.num_ftrs = self.model.fc.out_features\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.fc = nn.Sequential(       \n",
    "            nn.Linear(self.num_ftrs, 64),\n",
    "                             nn.BatchNorm1d(64),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(64,50),\n",
    "                             nn.BatchNorm1d(50),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(50,2)\n",
    "                            )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x  = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TgramNet(nn.Module):\n",
    "    def __init__(self, num_layer=3, mel_bins=128, win_len=1024, hop_len=512):\n",
    "        super(TgramNet, self).__init__()\n",
    "        # if \"center=True\" of stft, padding = win_len / 2\n",
    "\n",
    "        self.num_ftrs = 63\n",
    "\n",
    "        self.conv_extrctor = nn.Conv1d(1, mel_bins, win_len, hop_len, win_len // 2, bias=False)\n",
    "        self.conv_encoder = nn.Sequential(\n",
    "            *[nn.Sequential(\n",
    "                nn.LayerNorm(self.num_ftrs),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Conv1d(mel_bins, mel_bins, 3, 1, 1, bias=False)\n",
    "            ) for _ in range(num_layer)])\n",
    "\n",
    "        self.res = ResLayer()\n",
    "        self.fc = nn.Sequential(\n",
    "                            nn.Linear(mel_bins, 64),\n",
    "                             nn.BatchNorm1d(64),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(64,50),\n",
    "                             nn.BatchNorm1d(50),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(50,2)\n",
    "                            )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_extrctor(x)\n",
    "        out = self.conv_encoder(out)\n",
    "        #out = out.mean(axis=2)\n",
    "        #out=self.fc(out)\n",
    "        out = torch.stack([out,out,out],axis=1)\n",
    "        #print(out.size())\n",
    "        out=self.res(out)\n",
    "        return out\n",
    "\n",
    "def model_initialize():\n",
    "    model = TgramNet().cuda()\n",
    "    return model\n",
    "\n",
    "model=model_initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb4a27b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TgramNetConcat(nn.Module):\n",
    "    def __init__(self, num_layer=3, mel_bins=128, win_len=1024, hop_len=512):\n",
    "        super(TgramNetConcat, self).__init__()\n",
    "        # if \"center=True\" of stft, padding = win_len / 2\n",
    "\n",
    "        self.num_ftrs = 63\n",
    "\n",
    "        self.conv_extrctor = nn.Conv1d(1, mel_bins, win_len, hop_len, win_len // 2, bias=False)\n",
    "        self.conv_encoder = nn.Sequential(\n",
    "            *[nn.Sequential(\n",
    "                nn.LayerNorm(self.num_ftrs),\n",
    "                nn.LeakyReLU(0.2, inplace=True),\n",
    "                nn.Conv1d(mel_bins, mel_bins, 3, 1, 1, bias=False)\n",
    "            ) for _ in range(num_layer)])\n",
    "\n",
    "        self.res = ResLayer()\n",
    "        self.fc = nn.Sequential(\n",
    "                            nn.Linear(mel_bins, 64),\n",
    "                             nn.BatchNorm1d(64),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(64,50),\n",
    "                             nn.BatchNorm1d(50),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(50,2)\n",
    "                            )\n",
    "\n",
    "        self.spec = T.Spectrogram(n_fft=win_len,hop_length=hop_len,power=2)\n",
    "\n",
    "        self.mel_scale = T.MelScale(\n",
    "            n_mels=mel_bins, sample_rate=16000, n_stft=win_len // 2 + 1)\n",
    "\n",
    "        stretch_factor=0.8\n",
    "        self.spec_aug = torch.nn.Sequential(\n",
    "            T.TimeStretch(stretch_factor, fixed_rate=True),\n",
    "            T.FrequencyMasking(freq_mask_param=80),\n",
    "            T.TimeMasking(time_mask_param=40),\n",
    "        )        \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_extrctor(x)\n",
    "        out = self.conv_encoder(out)\n",
    "        spec = self.spec(x)\n",
    "        mel = self.mel_scale(spec)\n",
    "        #mel = self.spec_aug(mel)\n",
    "        mel = torch.squeeze(mel,dim=1)\n",
    "\n",
    "        #out = out.mean(axis=2)\n",
    "        #out=self.fc(out)\n",
    "        \n",
    "        #concated_feature = torch.concat([mel,out],axis=2)\n",
    "\n",
    "        out = torch.stack([mel,mel,out],axis=1)\n",
    "        #print(out.size())\n",
    "        out=self.res(out)\n",
    "        return out\n",
    "\n",
    "def model_initialize():\n",
    "    model = TgramNetConcat().cuda()\n",
    "    return model\n",
    "\n",
    "model=model_initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a8f3ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TgramNetConcat(\n",
       "  (conv_extrctor): Conv1d(1, 128, kernel_size=(1024,), stride=(512,), padding=(512,), bias=False)\n",
       "  (conv_encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): LayerNorm((63,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): LayerNorm((63,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): LayerNorm((63,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "      (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (res): ResLayer(\n",
       "    (model): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "    )\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=1000, out_features=64, bias=True)\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Dropout(p=0.5, inplace=False)\n",
       "      (4): Linear(in_features=64, out_features=50, bias=True)\n",
       "      (5): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ReLU()\n",
       "      (7): Dropout(p=0.5, inplace=False)\n",
       "      (8): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=64, out_features=50, bias=True)\n",
       "    (5): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.5, inplace=False)\n",
       "    (8): Linear(in_features=50, out_features=2, bias=True)\n",
       "  )\n",
       "  (spec): Spectrogram()\n",
       "  (mel_scale): MelScale()\n",
       "  (spec_aug): Sequential(\n",
       "    (0): TimeStretch()\n",
       "    (1): FrequencyMasking()\n",
       "    (2): TimeMasking()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aaaf71c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=model(torch.randn(4,1,32000).to(DEVICE))\n",
    "res.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bd816a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2150, -0.3051],\n",
      "        [ 0.3843,  0.6991],\n",
      "        [ 0.0279, -1.0197],\n",
      "        [ 0.0399, -0.9149]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74b42e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(res[0].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2fe5d1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델\n",
    "# pretrained\n",
    "\n",
    "class ResLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResLayer, self).__init__()\n",
    "        self.wav_model = models.resnet18(pretrained=True).cuda() \n",
    "        self.egg_model = models.resnet18(pretrained=True).cuda() \n",
    "        self.num_ftrs = self.model.fc.out_features\n",
    "        hidden_size = 256\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size = self.num_ftrs*2,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers = 1,\n",
    "                            batch_first = True,\n",
    "                            bidirectional = True)\n",
    "        \n",
    "        \n",
    "        self.fc = nn.Sequential(       \n",
    "            nn.Linear(hidden_size*2, 64),\n",
    "                             nn.BatchNorm1d(64),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(64,50),\n",
    "                             nn.BatchNorm1d(50),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(50,2)\n",
    "                            )\n",
    "        \n",
    "\n",
    "    def forward(self, wav, egg):\n",
    "        \n",
    "        wav = self.wav_model(wav)\n",
    "        egg = self.egg_model(egg)\n",
    "        x = self.lstm(torch.concat([wav,egg],axis=1))\n",
    "\n",
    "        x  = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def model_initialize():\n",
    "    model = ResLayer().cuda()\n",
    "    return model\n",
    "\n",
    "model=model_initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ab03234",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TgramNetConcat(\n",
      "  (conv_extrctor): Conv1d(1, 128, kernel_size=(1024,), stride=(512,), padding=(512,), bias=False)\n",
      "  (conv_encoder): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): LayerNorm((63,), eps=1e-05, elementwise_affine=True)\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): LayerNorm((63,), eps=1e-05, elementwise_affine=True)\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): LayerNorm((63,), eps=1e-05, elementwise_affine=True)\n",
      "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (res): ResLayer(\n",
      "    (model): ResNet(\n",
      "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (layer1): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (layer3): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (layer4): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "      (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=1000, out_features=64, bias=True)\n",
      "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Dropout(p=0.5, inplace=False)\n",
      "      (4): Linear(in_features=64, out_features=50, bias=True)\n",
      "      (5): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (6): ReLU()\n",
      "      (7): Dropout(p=0.5, inplace=False)\n",
      "      (8): Linear(in_features=50, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=64, out_features=50, bias=True)\n",
      "    (5): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.5, inplace=False)\n",
      "    (8): Linear(in_features=50, out_features=2, bias=True)\n",
      "  )\n",
      "  (spec): Spectrogram()\n",
      "  (mel_scale): MelScale()\n",
      "  (spec_aug): Sequential(\n",
      "    (0): TimeStretch()\n",
      "    (1): FrequencyMasking()\n",
      "    (2): TimeMasking()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a47749e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the model summary\n",
    "from torchsummary import summary\n",
    "#summary(model, input_size=(3, 128, 300), device=DEVICE.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f2ca15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. 학습\n",
    "def train(model,train_loader,optimizer, log_interval):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    train_loss = 0\n",
    "    for batch_idx,(image,label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        #데이터들 장비에 할당\n",
    "        optimizer.zero_grad() # device 에 저장된 gradient 제거\n",
    "        output = model(image) # model로 output을 계산\n",
    "        loss = criterion(output, label) #loss 계산\n",
    "        train_loss += loss.item()\n",
    "        prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "        correct += prediction.eq(label.view_as(prediction)).sum().item()# 아웃풋이 배치 사이즈 32개라서.\n",
    "        loss.backward() # loss 값을 이용해 gradient를 계산\n",
    "        optimizer.step() # Gradient 값을 이용해 파라미터 업데이트.\n",
    "    train_loss/=len(train_loader.dataset)\n",
    "    train_accuracy = 100. * correct / len(train_loader.dataset)\n",
    "    return train_loss,train_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b09341bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. 학습 진행하며, validation 데이터로 모델 성능확인\n",
    "def evaluate(model,valid_loader):\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    correct = 0\n",
    "    #no_grad : 그래디언트 값 계산 막기.\n",
    "    with torch.no_grad():\n",
    "        for image,label in valid_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            valid_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()# 아웃풋이 배치 사이즈 32개라서.\n",
    "            #true.false값을 sum해줌. item\n",
    "        valid_loss /= len(valid_loader.dataset)\n",
    "        valid_accuracy = 100. * correct / len(valid_loader.dataset)\n",
    "        return valid_loss,valid_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa7fc2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 로더 제작 함수\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "def load_data(data_ind):\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_dataset(\n",
    "                                                   X_train_list,\n",
    "                                                   classes,\n",
    "                                                   transform = transforms.ToTensor(),#이걸 composed로 고쳐서 전처리 하도록 수정.\n",
    "                                                   data_num=data_ind,\n",
    "                                                   #normalize=transforms.Normalize((-11.4805,-54.7723,-54.7723),(16.87,19.0226,19.0226)),\n",
    "                                                   #mfcc_normalize=(53.5582, 217.43),\n",
    "                                                   mfcc_params=mfcc_run_config,\n",
    "                                                   mel_params=mel_run_config,\n",
    "                                                   spectro_params=spectro_run_config,\n",
    "                                                   training=True\n",
    "                                               ),\n",
    "                                               batch_size = BATCH_SIZE,\n",
    "                                               shuffle = True,\n",
    "                                               worker_init_fn=seed_worker\n",
    "                                               ) # 순서가 암기되는것을 막기위해.\n",
    "\n",
    "    validation_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_dataset(\n",
    "                                                   X_valid_list,\n",
    "                                                   classes,\n",
    "                                                   transform = transforms.ToTensor(),\n",
    "                                                   data_num=data_ind,\n",
    "                                                   #normalize=transforms.Normalize((-11.4805,-54.7723,-54.7723),(16.87,19.0226,19.0226)),\n",
    "                                                   #mfcc_normalize=(53.5582, 217.43),\n",
    "                                                   mfcc_params=mfcc_run_config,\n",
    "                                                   mel_params=mel_run_config,\n",
    "                                                   spectro_params=spectro_run_config,\n",
    "                                                   training=False\n",
    "                                               ),\n",
    "                                                    batch_size = BATCH_SIZE,\n",
    "                                                    shuffle = True,\n",
    "                                                    worker_init_fn=seed_worker) \n",
    "    return train_loader,validation_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b970e322",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./checkpoint/checkpoint_wavegram_ros_1_organics_speaker.pt\n",
      "[1 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0435\t Train Acc:58.37 %  | \tValid Loss:0.0367 \tValid Acc: 69.27 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.036731).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0338\t Train Acc:72.78 %  | \tValid Loss:0.0342 \tValid Acc: 76.15 %\n",
      "\n",
      "Validation loss decreased (0.036731 --> 0.034204).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0306\t Train Acc:76.85 %  | \tValid Loss:0.0323 \tValid Acc: 77.06 %\n",
      "\n",
      "Validation loss decreased (0.034204 --> 0.032317).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0271\t Train Acc:84.24 %  | \tValid Loss:0.0337 \tValid Acc: 72.02 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0237\t Train Acc:87.56 %  | \tValid Loss:0.0349 \tValid Acc: 73.39 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0207\t Train Acc:90.76 %  | \tValid Loss:0.0307 \tValid Acc: 76.61 %\n",
      "\n",
      "Validation loss decreased (0.032317 --> 0.030658).  Saving model ...\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0177\t Train Acc:92.98 %  | \tValid Loss:0.0300 \tValid Acc: 77.52 %\n",
      "\n",
      "Validation loss decreased (0.030658 --> 0.029986).  Saving model ...\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0160\t Train Acc:94.95 %  | \tValid Loss:0.0308 \tValid Acc: 77.06 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0137\t Train Acc:97.78 %  | \tValid Loss:0.0327 \tValid Acc: 76.61 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0130\t Train Acc:97.41 %  | \tValid Loss:0.0316 \tValid Acc: 75.23 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0117\t Train Acc:96.31 %  | \tValid Loss:0.0337 \tValid Acc: 72.94 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0095\t Train Acc:98.52 %  | \tValid Loss:0.0305 \tValid Acc: 76.61 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[1 교차검증] Early stopping\n",
      "./checkpoint/checkpoint_wavegram_ros_2_organics_speaker.pt\n",
      "[2 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0439\t Train Acc:58.19 %  | \tValid Loss:0.0383 \tValid Acc: 68.22 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.038285).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0362\t Train Acc:70.78 %  | \tValid Loss:0.0333 \tValid Acc: 78.97 %\n",
      "\n",
      "Validation loss decreased (0.038285 --> 0.033336).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0296\t Train Acc:81.05 %  | \tValid Loss:0.0331 \tValid Acc: 79.91 %\n",
      "\n",
      "Validation loss decreased (0.033336 --> 0.033070).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0284\t Train Acc:83.25 %  | \tValid Loss:0.0341 \tValid Acc: 77.57 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0236\t Train Acc:89.49 %  | \tValid Loss:0.0320 \tValid Acc: 81.31 %\n",
      "\n",
      "Validation loss decreased (0.033070 --> 0.032030).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0204\t Train Acc:92.30 %  | \tValid Loss:0.0322 \tValid Acc: 80.84 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0171\t Train Acc:94.62 %  | \tValid Loss:0.0315 \tValid Acc: 78.50 %\n",
      "\n",
      "Validation loss decreased (0.032030 --> 0.031510).  Saving model ...\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0160\t Train Acc:95.23 %  | \tValid Loss:0.0314 \tValid Acc: 77.57 %\n",
      "\n",
      "Validation loss decreased (0.031510 --> 0.031360).  Saving model ...\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0158\t Train Acc:95.84 %  | \tValid Loss:0.0354 \tValid Acc: 74.77 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0139\t Train Acc:96.82 %  | \tValid Loss:0.0332 \tValid Acc: 77.10 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0131\t Train Acc:97.56 %  | \tValid Loss:0.0318 \tValid Acc: 78.04 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0121\t Train Acc:97.92 %  | \tValid Loss:0.0327 \tValid Acc: 80.37 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0090\t Train Acc:98.17 %  | \tValid Loss:0.0312 \tValid Acc: 80.37 %\n",
      "\n",
      "Validation loss decreased (0.031360 --> 0.031170).  Saving model ...\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0105\t Train Acc:96.45 %  | \tValid Loss:0.0372 \tValid Acc: 71.96 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0116\t Train Acc:97.31 %  | \tValid Loss:0.0290 \tValid Acc: 80.84 %\n",
      "\n",
      "Validation loss decreased (0.031170 --> 0.028989).  Saving model ...\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0113\t Train Acc:96.58 %  | \tValid Loss:0.0347 \tValid Acc: 74.77 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:17]\t Train Loss:0.0097\t Train Acc:97.19 %  | \tValid Loss:0.0354 \tValid Acc: 79.44 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:18]\t Train Loss:0.0106\t Train Acc:98.04 %  | \tValid Loss:0.0376 \tValid Acc: 75.70 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:19]\t Train Loss:0.0100\t Train Acc:97.68 %  | \tValid Loss:0.0343 \tValid Acc: 76.64 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:20]\t Train Loss:0.0075\t Train Acc:97.92 %  | \tValid Loss:0.0384 \tValid Acc: 73.36 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[2 교차검증] Early stopping\n",
      "./checkpoint/checkpoint_wavegram_ros_3_organics_speaker.pt\n",
      "[3 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0429\t Train Acc:60.15 %  | \tValid Loss:0.0352 \tValid Acc: 69.15 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.035203).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0350\t Train Acc:73.84 %  | \tValid Loss:0.0311 \tValid Acc: 76.06 %\n",
      "\n",
      "Validation loss decreased (0.035203 --> 0.031133).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0300\t Train Acc:80.56 %  | \tValid Loss:0.0312 \tValid Acc: 80.32 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0262\t Train Acc:84.35 %  | \tValid Loss:0.0296 \tValid Acc: 77.66 %\n",
      "\n",
      "Validation loss decreased (0.031133 --> 0.029553).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0216\t Train Acc:90.10 %  | \tValid Loss:0.0298 \tValid Acc: 79.79 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0175\t Train Acc:93.77 %  | \tValid Loss:0.0296 \tValid Acc: 80.85 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0154\t Train Acc:95.84 %  | \tValid Loss:0.0303 \tValid Acc: 78.72 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0151\t Train Acc:94.99 %  | \tValid Loss:0.0299 \tValid Acc: 78.72 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0133\t Train Acc:95.97 %  | \tValid Loss:0.0304 \tValid Acc: 77.66 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[3 교차검증] Early stopping\n",
      "./checkpoint/checkpoint_wavegram_ros_4_organics_speaker.pt\n",
      "[4 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0430\t Train Acc:59.39 %  | \tValid Loss:0.0357 \tValid Acc: 77.78 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.035660).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0344\t Train Acc:72.20 %  | \tValid Loss:0.0327 \tValid Acc: 79.44 %\n",
      "\n",
      "Validation loss decreased (0.035660 --> 0.032735).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0297\t Train Acc:80.00 %  | \tValid Loss:0.0315 \tValid Acc: 80.56 %\n",
      "\n",
      "Validation loss decreased (0.032735 --> 0.031501).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0264\t Train Acc:83.17 %  | \tValid Loss:0.0335 \tValid Acc: 77.78 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0231\t Train Acc:90.00 %  | \tValid Loss:0.0295 \tValid Acc: 78.89 %\n",
      "\n",
      "Validation loss decreased (0.031501 --> 0.029495).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0205\t Train Acc:91.46 %  | \tValid Loss:0.0296 \tValid Acc: 80.56 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0210\t Train Acc:90.49 %  | \tValid Loss:0.0339 \tValid Acc: 73.89 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0173\t Train Acc:93.29 %  | \tValid Loss:0.0292 \tValid Acc: 76.67 %\n",
      "\n",
      "Validation loss decreased (0.029495 --> 0.029217).  Saving model ...\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0153\t Train Acc:95.00 %  | \tValid Loss:0.0347 \tValid Acc: 77.22 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0131\t Train Acc:95.61 %  | \tValid Loss:0.0326 \tValid Acc: 80.00 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0115\t Train Acc:97.07 %  | \tValid Loss:0.0311 \tValid Acc: 79.44 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0109\t Train Acc:97.44 %  | \tValid Loss:0.0316 \tValid Acc: 76.11 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0100\t Train Acc:97.68 %  | \tValid Loss:0.0353 \tValid Acc: 76.67 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[4 교차검증] Early stopping\n",
      "./checkpoint/checkpoint_wavegram_ros_5_organics_speaker.pt\n",
      "[5 교차검증] 학습 시작\n",
      " ----- \n",
      "\n",
      "[EPOCH:1]\t Train Loss:0.0416\t Train Acc:61.10 %  | \tValid Loss:0.0364 \tValid Acc: 72.08 %\n",
      "\n",
      "Validation loss decreased (inf --> 0.036406).  Saving model ...\n",
      "\n",
      "[EPOCH:2]\t Train Loss:0.0351\t Train Acc:73.17 %  | \tValid Loss:0.0330 \tValid Acc: 78.17 %\n",
      "\n",
      "Validation loss decreased (0.036406 --> 0.032973).  Saving model ...\n",
      "\n",
      "[EPOCH:3]\t Train Loss:0.0307\t Train Acc:77.93 %  | \tValid Loss:0.0320 \tValid Acc: 77.16 %\n",
      "\n",
      "Validation loss decreased (0.032973 --> 0.031962).  Saving model ...\n",
      "\n",
      "[EPOCH:4]\t Train Loss:0.0272\t Train Acc:82.07 %  | \tValid Loss:0.0313 \tValid Acc: 78.68 %\n",
      "\n",
      "Validation loss decreased (0.031962 --> 0.031298).  Saving model ...\n",
      "\n",
      "[EPOCH:5]\t Train Loss:0.0224\t Train Acc:88.41 %  | \tValid Loss:0.0301 \tValid Acc: 79.19 %\n",
      "\n",
      "Validation loss decreased (0.031298 --> 0.030117).  Saving model ...\n",
      "\n",
      "[EPOCH:6]\t Train Loss:0.0201\t Train Acc:89.51 %  | \tValid Loss:0.0323 \tValid Acc: 77.66 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:7]\t Train Loss:0.0180\t Train Acc:91.34 %  | \tValid Loss:0.0291 \tValid Acc: 79.70 %\n",
      "\n",
      "Validation loss decreased (0.030117 --> 0.029148).  Saving model ...\n",
      "\n",
      "[EPOCH:8]\t Train Loss:0.0143\t Train Acc:95.73 %  | \tValid Loss:0.0302 \tValid Acc: 80.20 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:9]\t Train Loss:0.0123\t Train Acc:97.07 %  | \tValid Loss:0.0322 \tValid Acc: 76.14 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:10]\t Train Loss:0.0117\t Train Acc:95.73 %  | \tValid Loss:0.0298 \tValid Acc: 79.70 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:11]\t Train Loss:0.0115\t Train Acc:95.85 %  | \tValid Loss:0.0274 \tValid Acc: 81.22 %\n",
      "\n",
      "Validation loss decreased (0.029148 --> 0.027437).  Saving model ...\n",
      "\n",
      "[EPOCH:12]\t Train Loss:0.0091\t Train Acc:97.93 %  | \tValid Loss:0.0277 \tValid Acc: 82.74 %\n",
      "\n",
      "EarlyStopping counter: 1 out of 5\n",
      "\n",
      "[EPOCH:13]\t Train Loss:0.0083\t Train Acc:98.66 %  | \tValid Loss:0.0313 \tValid Acc: 77.66 %\n",
      "\n",
      "EarlyStopping counter: 2 out of 5\n",
      "\n",
      "[EPOCH:14]\t Train Loss:0.0108\t Train Acc:96.83 %  | \tValid Loss:0.0330 \tValid Acc: 79.19 %\n",
      "\n",
      "EarlyStopping counter: 3 out of 5\n",
      "\n",
      "[EPOCH:15]\t Train Loss:0.0120\t Train Acc:94.88 %  | \tValid Loss:0.0307 \tValid Acc: 81.22 %\n",
      "\n",
      "EarlyStopping counter: 4 out of 5\n",
      "\n",
      "[EPOCH:16]\t Train Loss:0.0118\t Train Acc:94.51 %  | \tValid Loss:0.0336 \tValid Acc: 79.19 %\n",
      "\n",
      "EarlyStopping counter: 5 out of 5\n",
      "[5 교차검증] Early stopping\n"
     ]
    }
   ],
   "source": [
    "##### 10. 학습 및 평가.\n",
    "# resnet34 pretrained true\n",
    "# kfold 적용\n",
    "\n",
    "train_accs = []\n",
    "valid_accs = []\n",
    "\n",
    "for data_ind in range(1,6): \n",
    "\n",
    "    check_path = './checkpoint/checkpoint_wavegram_ros_'+str(data_ind)+'_organics_speaker.pt'\n",
    "    print(check_path)\n",
    "    early_stopping = EarlyStopping(patience = 5, verbose = True, path=check_path)\n",
    "    train_loader,validation_loader = load_data(data_ind-1)\n",
    "\n",
    "    best_train_acc=0 # accuracy 기록용\n",
    "    best_valid_acc=0\n",
    "    \n",
    "    model=model_initialize()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=weight_decay)\n",
    "    #scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = lambda epoch: 0.95 ** epoch)\n",
    "    #scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,\n",
    "    #                                               max_lr=0.0001,\n",
    "    #                                               steps_per_epoch=len(train_loader),\n",
    "    #                                               epochs=20,\n",
    "    #                                               anneal_strategy='linear')\n",
    "    \n",
    "    \n",
    "    print(\"[{} 교차검증] 학습 시작\\n ----- \".format(data_ind))\n",
    "    for Epoch in range(1,EPOCHS+1):\n",
    "        train_loss,train_accuracy=train(model,train_loader,optimizer,log_interval=31)\n",
    "        valid_loss,valid_accuracy = evaluate(model, validation_loader)\n",
    "        wandb.log({\n",
    "                \"valid {}fold Accuracy\".format(data_ind) : valid_accuracy,\n",
    "                \"valid {}fold loss\".format(data_ind) : valid_loss},\n",
    "                commit=True,\n",
    "                step=Epoch)\n",
    "\n",
    "        print(\"\\n[EPOCH:{}]\\t Train Loss:{:.4f}\\t Train Acc:{:.2f} %  | \\tValid Loss:{:.4f} \\tValid Acc: {:.2f} %\\n\".\n",
    "              format(Epoch,train_loss,train_accuracy,valid_loss,valid_accuracy))\n",
    "        \n",
    "\n",
    "        early_stopping(valid_loss, model)\n",
    "        if -early_stopping.best_score == valid_loss:\n",
    "            best_train_acc, best_valid_acc = train_accuracy,valid_accuracy\n",
    "            wandb.run.summary.update({\"best_valid_{}fold_acc\".format(data_ind) : best_valid_acc})\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "                train_accs.append(best_train_acc)\n",
    "                valid_accs.append(best_valid_acc)\n",
    "                print(\"[{} 교차검증] Early stopping\".format(data_ind))\n",
    "                break\n",
    "\n",
    "        if Epoch==EPOCHS:\n",
    "            #만약 early stop 없이 40 epoch라서 중지 된 경우. \n",
    "            train_accs.append(best_train_acc)\n",
    "            valid_accs.append(best_valid_acc)\n",
    "        #scheduler.step()\n",
    "        #print(scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d969079c",
   "metadata": {},
   "source": [
    "# Model 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d8ef002",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 교차검증] train ACC : 92.9803 |\t valid ACC: 77.5229 \n",
      "[2 교차검증] train ACC : 97.3105 |\t valid ACC: 80.8411 \n",
      "[3 교차검증] train ACC : 84.3521 |\t valid ACC: 77.6596 \n",
      "[4 교차검증] train ACC : 93.2927 |\t valid ACC: 76.6667 \n",
      "[5 교차검증] train ACC : 95.8537 |\t valid ACC: 81.2183 \n",
      "평균 검증 정확도 78.7817145043141 %\n"
     ]
    }
   ],
   "source": [
    "sum_valid=0\n",
    "for data_ind in range(5):\n",
    "    print(\"[{} 교차검증] train ACC : {:.4f} |\\t valid ACC: {:.4f} \".format(data_ind+1,train_accs[data_ind],valid_accs[data_ind] ))\n",
    "    sum_valid+=valid_accs[data_ind]\n",
    "    \n",
    "print(\"평균 검증 정확도\",sum_valid/5,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7d3f46",
   "metadata": {},
   "source": [
    "# Model Test\n",
    "\n",
    "- test set\n",
    "- confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b597b674",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix 계산\n",
    "#test set 계산.\n",
    "def test_evaluate(model,test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    predictions = []\n",
    "    answers = []\n",
    "    #no_grad : 그래디언트 값 계산 막기.\n",
    "    with torch.no_grad():\n",
    "        for image,label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "            answers +=label\n",
    "            predictions +=prediction\n",
    "            \n",
    "        return predictions,answers,test_loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "446269f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번 모델\n",
      "Accuracy : 79.4872% \n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.7593\n",
      "specificity : 0.8254%\n",
      "UAR : 0.7923%\n",
      "f score : 0.7930 \n",
      "[[104  22]\n",
      " [ 26  82]]\n",
      "-----\n",
      "2번 모델\n",
      "Accuracy : 78.6325% \n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.7778\n",
      "specificity : 0.7937%\n",
      "UAR : 0.7857%\n",
      "f score : 0.7853 \n",
      "[[100  26]\n",
      " [ 24  84]]\n",
      "-----\n",
      "3번 모델\n",
      "Accuracy : 83.7607% \n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.7870\n",
      "specificity : 0.8810%\n",
      "UAR : 0.8340%\n",
      "f score : 0.8356 \n",
      "[[111  15]\n",
      " [ 23  85]]\n",
      "-----\n",
      "4번 모델\n",
      "Accuracy : 77.3504% \n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.7870\n",
      "specificity : 0.7619%\n",
      "UAR : 0.7745%\n",
      "f score : 0.7730 \n",
      "[[96 30]\n",
      " [23 85]]\n",
      "-----\n",
      "5번 모델\n",
      "Accuracy : 79.9145% \n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.7130\n",
      "specificity : 0.8730%\n",
      "UAR : 0.7930%\n",
      "f score : 0.7951 \n",
      "[[110  16]\n",
      " [ 31  77]]\n",
      "-----\n",
      "평균 acc : 0.7983\n",
      "평균 UAR : 0.7959\n",
      "평균 f1score : 0.7964\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix (resnet18)\n",
    "# kfold의 confusion matrix는 계산 방법이 다르다.\n",
    "# 모델을 각각 불러와서 test set을 평가한다.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "cf = np.zeros((2,2))\n",
    "cf_list = []\n",
    "average_accuracy = 0\n",
    "average_fscore = 0\n",
    "average_uar = 0\n",
    "\n",
    "for data_ind in range(1,6):\n",
    "    model=model_initialize()\n",
    "    check_path = './checkpoint/checkpoint_wavegram_ros_'+str(data_ind)+'_organics_speaker.pt'\n",
    "    model.load_state_dict(torch.load(check_path))\n",
    "\n",
    "    predictions,answers,test_loss = test_evaluate(model, test_loader)\n",
    "    predictions=[ dat.cpu().numpy() for dat in predictions]\n",
    "    answers=[ dat.cpu().numpy() for dat in answers]\n",
    "\n",
    "    \n",
    "    cf = confusion_matrix(answers, predictions)\n",
    "    cf_list.append(cf)\n",
    "    \n",
    "    acc = (cf[0,0]+cf[1,1])/(cf[0,0]+cf[0,1]+cf[1,0]+cf[1,1])\n",
    "    average_accuracy+=acc\n",
    "    \n",
    "    precision=cf[1,1]/(cf[0,1]+cf[1,1])\n",
    "    \n",
    "    recall=cf[1,1]/(cf[1,1]+cf[1,0])\n",
    "    \n",
    "    specificity=cf[0,0]/(cf[0,0]+cf[0,1])\n",
    "    average_uar += (specificity+recall)/2\n",
    "    #fscore=2*precision*recall/(precision+recall)\n",
    "    \n",
    "    #fscroe macro추가\n",
    "    fscore = f1_score(answers,predictions,average='macro')\n",
    "    average_fscore+=fscore\n",
    "    \n",
    "    print('{}번 모델'.format(data_ind))\n",
    "    print(\"Accuracy : {:.4f}% \".format(acc*100))\n",
    "    #print(\"Precision (pathology 예측한 것중 맞는 것) : {:.4f}\".format(precision))\n",
    "    print(\"recall (실제 pathology 중  예측이 맞는 것) : {:.4f}\".format(recall))\n",
    "    print(\"specificity : {:.4f}%\".format(specificity))\n",
    "    print(\"UAR : {:.4f}%\".format( (specificity+recall)/2 ))\n",
    "    \n",
    "    \n",
    "    print(\"f score : {:.4f} \".format(fscore))\n",
    "    print(cf)\n",
    "    print(\"-----\")\n",
    "    #### wandb\n",
    "    \n",
    "\n",
    "    wandb.log({\"{}fold Confusion Matrix\".format(data_ind) :wandb.sklearn.plot_confusion_matrix(answers, predictions, labels=classes)})\n",
    "    \n",
    "    ####\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "print(\"평균 acc : {:.4f}\".format(average_accuracy/5))\n",
    "print(\"평균 UAR : {:.4f}\".format(average_uar/5))\n",
    "print(\"평균 f1score : {:.4f}\".format(average_fscore/5))\n",
    "wandb.run.summary.update({\"test 평균 acc\" : average_accuracy/5})\n",
    "wandb.run.summary.update({\"test 평균 f1\" : average_fscore/5})\n",
    "wandb.run.summary.update({\"test 평균 UAR\" : average_uar/5})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d4cac4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ᄋᄋᄋᄋᄋᄋᄋᄋᄋ' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3184/757536221.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mㅇㅇㅇㅇㅇㅇㅇㅇㅇ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ᄋᄋᄋᄋᄋᄋᄋᄋᄋ' is not defined"
     ]
    }
   ],
   "source": [
    "ㅇㅇㅇㅇㅇㅇㅇㅇㅇ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38befa06",
   "metadata": {},
   "source": [
    "# loss 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726a124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_list[0])\n",
    "plt.plot(valid_loss_list[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4c63c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_list[1])\n",
    "plt.plot(valid_loss_list[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20a80e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_list[2])\n",
    "plt.plot(valid_loss_list[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0844b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_list[3])\n",
    "plt.plot(valid_loss_list[3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967cb3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_list[4])\n",
    "plt.plot(valid_loss_list[4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a30c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accs_list[0])\n",
    "plt.plot(valid_accs_list[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb4d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accs_list[1])\n",
    "plt.plot(valid_accs_list[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab39285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accs_list[2])\n",
    "plt.plot(valid_accs_list[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abbc85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accs_list[3])\n",
    "plt.plot(valid_accs_list[3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba0b821",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accs_list[4])\n",
    "plt.plot(valid_accs_list[4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e84a9f",
   "metadata": {},
   "source": [
    "# 결과 출력 -validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb4245e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델\n",
    "# pretrained\n",
    "\n",
    "class ResLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResLayer, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=True).cuda() \n",
    "        self.num_ftrs = self.model.fc.out_features\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.fc = nn.Sequential(       \n",
    "            nn.Linear(self.num_ftrs, 64),\n",
    "                             nn.BatchNorm1d(64),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(64,50),\n",
    "                             nn.BatchNorm1d(50),\n",
    "                             nn.ReLU(),\n",
    "                             nn.Dropout(p=0.5),\n",
    "                             nn.Linear(50,2)\n",
    "                            )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x  = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def model_initialize():\n",
    "    model = ResLayer().cuda()\n",
    "    return model\n",
    "\n",
    "model=model_initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53988588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default param\n",
    "mfcc_run_config = dict(\n",
    "    sr=16000,\n",
    "    n_mfcc=27,\n",
    "    #dct_type=3, # type2 default\n",
    "    lifter = 35,\n",
    "\n",
    "    \n",
    "    #mel spectro\n",
    "    n_mels=170,\n",
    "    hop_length=750,\n",
    "    n_fft =14056,    \n",
    "    win_length=1100,\n",
    "    f_max=8000,\n",
    "    \n",
    "    # training\n",
    "    #batch_size=32,\n",
    "    mel_scale ='htk',\n",
    "    \n",
    "    # data\n",
    "    fold=1,\n",
    ")\n",
    "\n",
    "mel_run_config = dict(\n",
    "    sr=16000,\n",
    "    n_mels=128,\n",
    "    win_length =  300,\n",
    "    n_fft= 2048,\n",
    "    hop_length= 50,\n",
    "    f_max = 8000    \n",
    ")\n",
    "\n",
    "\n",
    "spectro_run_config =dict(\n",
    "    sr=16000,\n",
    "    n_fft=350,\n",
    "    hop_length=50,\n",
    "    win_length=350,\n",
    "    # training\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bbbe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "classes = [\"healthy\",\"pathology\"]\n",
    "\n",
    "\n",
    "class svd_dataset_valid(Dataset):\n",
    "    def __init__(self,data_path_list,classes,data_num,training,mfcc_params,mel_params,spectro_params,transform=None,normalize=None,mfcc_normalize=None):\n",
    "        #클래스에서 사용할 인자를 받아 인스턴스 변수로 저장하는 일을 한다.\n",
    "        #예를들면, 이미지의 경로 리스트를 저장하는 일을 하게 된다.\n",
    "        \n",
    "        #data_num : k 개 데이터 셋 중 어떤것을 쓸지\n",
    "        #test인지 아닌지.\n",
    "        \n",
    "        self.path_list = data_path_list[data_num]\n",
    "        self.data_num = data_num\n",
    "        self.training = training\n",
    "        self.label = svd_dataset_valid.get_label(self.path_list,training,data_num)\n",
    "        self.classes=classes\n",
    "        self.transform=transform\n",
    "        self.normalize=normalize\n",
    "        self.mfcc_normalize = mfcc_normalize\n",
    "        # sweep params\n",
    "        self.mel_params = mel_params\n",
    "        self.spectro_params = spectro_params\n",
    "        self.mfcc_params = mfcc_params\n",
    "        #sr,n_mfcc,lifter, hop_length , win_length , n_mels , n_fft , f_max , batch_size\n",
    "\n",
    "        \n",
    "    \n",
    "    @classmethod\n",
    "    def get_label(cls,data_path_list,training,data_num):\n",
    "        label_list=[]\n",
    "        \n",
    "        if training:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_train_list[data_num][idx])\n",
    "        else:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_valid_list[data_num][idx])\n",
    "        #print(label_list)\n",
    "        return label_list\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "        #데이터 셋의 길이를 정수로 반환한다.     \n",
    "    \n",
    "       \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        1. path를 받아서, 소리에서 mfcc를 추출\n",
    "        2. mfcc를 224프레임으로 패딩.\n",
    "        3. resnet에 사용되기 위해 3채널로 복사(rgb 처럼)\n",
    "        4. 0~1 정규화\n",
    "        \n",
    "        \"\"\"\n",
    "        sig = phrase_dict[ str(self.path_list[idx])+'-phrase.wav'] \n",
    "        #sig = preemphasis(sig)\n",
    "        \n",
    "        origin_length = sig.shape[0]\n",
    "        \n",
    "        if sig.shape[0] > self.mfcc_params[\"sr\"]*2:\n",
    "            origin_length = self.mfcc_params[\"sr\"]*2\n",
    "        \n",
    "        origin_frame_size = 1 + int(np.floor(origin_length//self.mel_params[\"hop_length\"]))\n",
    "        \n",
    "        length = self.mfcc_params[\"sr\"]*2 #sample rate *2 padding을 위한 파라미터 (하이퍼 파라미터로인해 사이즈는 계속 바뀐다.)\n",
    "        pad1d = lambda a, i: a[0:i] if a.shape[0] > i else np.hstack((a, np.zeros((i-a.shape[0]))))        \n",
    "        sig = pad1d(sig,length)        \n",
    "        \n",
    "        ###signal norm\n",
    "        sig = (sig-sig.mean())/sig.std()\n",
    "        ###\n",
    "        \n",
    "        mel_feature = librosa.feature.melspectrogram(y=sig,\n",
    "                                                     sr=self.mel_params[\"sr\"],\n",
    "                                                     # hyp param\n",
    "                                                     n_mels = self.mel_params[\"n_mels\"],\n",
    "                                                     n_fft = self.mel_params[\"n_fft\"],\n",
    "                                                     win_length = self.mel_params[\"win_length\"],\n",
    "                                                     hop_length = self.mel_params[\"hop_length\"],\n",
    "                                                     fmax = self.mel_params[\"f_max\"]\n",
    "                                                    )\n",
    "        mel_feature = librosa.core.power_to_db(mel_feature,ref=np.max) \n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            mel_feature = self.transform(mel_feature).type(torch.float32)# 데이터 0~1 정규화\n",
    "            MSF = torch.stack([mel_feature, mel_feature, mel_feature])# 3채널로 복사.\n",
    "            MSF = MSF.squeeze(dim=1)    \n",
    "            \n",
    "            # global normalize\n",
    "            if self.normalize:\n",
    "                #MFCCs=self.normalize(MFCCs)\n",
    "                MSF = self.normalize(MSF)\n",
    "        else:\n",
    "            pass\n",
    "            #print(\"else\")\n",
    "            mel_feature = torch.from_numpy(mel_feature).type(torch.float32)\n",
    "            mel_feature = mel_feature.unsqueeze(0)#cnn 사용위해서 추가\n",
    "            #MFCCs = MFCCs.permute(2, 0, 1)\n",
    "        return MSF, self.classes.index(self.label[idx]),str(self.path_list[idx])+'-phrase.wav'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae6e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_filename=[]\n",
    "all_prediction=[]\n",
    "all_answers=[]\n",
    "\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "def valid_evaluate(model,data_ind):\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    predictions = []\n",
    "    answers = []\n",
    "    file_name = []\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    BATCH_SIZE=16\n",
    "\n",
    "    validation_loader = torch.utils.data.DataLoader(dataset = \n",
    "                                               svd_dataset_valid(\n",
    "                                                   X_valid_list,\n",
    "                                                   classes,\n",
    "                                                   transform = transforms.ToTensor(),\n",
    "                                                   data_num=data_ind,\n",
    "                                                   #normalize=transforms.Normalize((-11.4805,-54.7723,-54.7723),(16.87,19.0226,19.0226)),\n",
    "                                                   #mfcc_normalize=(53.5582, 217.43),\n",
    "                                                   mfcc_params=mfcc_run_config,\n",
    "                                                   mel_params=mel_run_config,\n",
    "                                                   spectro_params=spectro_run_config,\n",
    "                                                   training=False\n",
    "                                               ),\n",
    "                                                    batch_size = BATCH_SIZE,\n",
    "                                                    shuffle = True,\n",
    "                                                    worker_init_fn=seed_worker)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for image,label,path_list in validation_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1,keepdim=True)[1] # 가장 확률이 높은 class 1개를 가져온다.그리고 인덱스만\n",
    "            answers +=label\n",
    "            predictions +=prediction\n",
    "            file_name+=(path_list)\n",
    "        all_filename.append(file_name)\n",
    "        all_prediction.append(predictions)\n",
    "        all_answers.append(answers)\n",
    "    return predictions,answers,test_loss\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f542e566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번 모델\n",
      "Accuracy : 84.8624% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.8636\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.8407\n",
      "specificity : 0.8571%\n",
      "UAR : 0.8489%\n",
      "f score : 0.8485 \n",
      "[[90 15]\n",
      " [18 95]]\n",
      "-----\n",
      "2번 모델\n",
      "Accuracy : 87.8505% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.8707\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.9018\n",
      "specificity : 0.8529%\n",
      "UAR : 0.8774%\n",
      "f score : 0.8780 \n",
      "[[ 87  15]\n",
      " [ 11 101]]\n",
      "-----\n",
      "3번 모델\n",
      "Accuracy : 86.1702% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.8488\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.8488\n",
      "specificity : 0.8725%\n",
      "UAR : 0.8607%\n",
      "f score : 0.8607 \n",
      "[[89 13]\n",
      " [13 73]]\n",
      "-----\n",
      "4번 모델\n",
      "Accuracy : 88.8889% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.8642\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.8861\n",
      "specificity : 0.8911%\n",
      "UAR : 0.8886%\n",
      "f score : 0.8875 \n",
      "[[90 11]\n",
      " [ 9 70]]\n",
      "-----\n",
      "5번 모델\n",
      "Accuracy : 92.3858% \n",
      "Precision (pathology 예측한 것중 맞는 것) : 0.9263\n",
      "recall (실제 pathology 중  예측이 맞는 것) : 0.9167\n",
      "specificity : 0.9307%\n",
      "UAR : 0.9237%\n",
      "f score : 0.9238 \n",
      "[[94  7]\n",
      " [ 8 88]]\n",
      "-----\n",
      "평균 acc : 0.8803\n",
      "평균 UAR : 0.8798\n",
      "평균 f1score : 0.8797\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix (resnet18)\n",
    "# kfold의 confusion matrix는 계산 방법이 다르다.\n",
    "# 모델을 각각 불러와서 test set을 평가한다.\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "cf = np.zeros((2,2))\n",
    "cf_list = []\n",
    "average_accuracy = 0\n",
    "average_fscore = 0\n",
    "average_uar = 0\n",
    "\n",
    "all_filename=[]\n",
    "all_prediction=[]\n",
    "all_answers=[]\n",
    "\n",
    "args={  'model':'baseline',\n",
    "        'seed':1004\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for data_ind in range(1,6):\n",
    "    model=model_initialize()\n",
    "    check_path = './checkpoint/checkpoint_ros_fold_'+str(data_ind)+'_'+args['model']+'_seed_'+str(args['seed'])+'_organics_speaker.pt'\n",
    "    model.load_state_dict(torch.load(check_path))\n",
    "\n",
    "    predictions,answers,valid_loss = valid_evaluate(model, data_ind-1)\n",
    "    predictions=[ dat.cpu().numpy() for dat in predictions]\n",
    "    answers=[ dat.cpu().numpy() for dat in answers]\n",
    "\n",
    "    \n",
    "    cf = confusion_matrix(answers, predictions)\n",
    "    cf_list.append(cf)\n",
    "    \n",
    "    acc = (cf[0,0]+cf[1,1])/(cf[0,0]+cf[0,1]+cf[1,0]+cf[1,1])\n",
    "    average_accuracy+=acc\n",
    "    \n",
    "    precision=cf[1,1]/(cf[0,1]+cf[1,1])\n",
    "    \n",
    "    recall=cf[1,1]/(cf[1,1]+cf[1,0])\n",
    "    \n",
    "    specificity=cf[0,0]/(cf[0,0]+cf[0,1])\n",
    "    average_uar += (specificity+recall)/2\n",
    "    \n",
    "    #fscroe macro추가\n",
    "    fscore = f1_score(answers,predictions,average='macro')\n",
    "    average_fscore+=fscore\n",
    "    \n",
    "    print('{}번 모델'.format(data_ind))\n",
    "    print(\"Accuracy : {:.4f}% \".format(acc*100))\n",
    "    print(\"Precision (pathology 예측한 것중 맞는 것) : {:.4f}\".format(precision))\n",
    "    print(\"recall (실제 pathology 중  예측이 맞는 것) : {:.4f}\".format(recall))\n",
    "    print(\"specificity : {:.4f}%\".format(specificity))\n",
    "    print(\"UAR : {:.4f}%\".format( (specificity+recall)/2 ))\n",
    "    \n",
    "    \n",
    "    print(\"f score : {:.4f} \".format(fscore))\n",
    "    print(cf)\n",
    "    print(\"-----\")\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "print(\"평균 acc : {:.4f}\".format(average_accuracy/5))\n",
    "print(\"평균 UAR : {:.4f}\".format(average_uar/5))\n",
    "print(\"평균 f1score : {:.4f}\".format(average_fscore/5))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb7b2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd19358",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_excel = []\n",
    "for i in range(5):\n",
    "    fold_excel.append(pd.DataFrame({'filename':all_filename[i],\n",
    "                  'prediction':[data.cpu().numpy().item() for data in all_prediction[i]],\n",
    "                  'answer':[ data.cpu().numpy().item() for data in all_answers[i]],\n",
    "                  'fold':i+1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afc7e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_excel_all=pd.concat(fold_excel,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d553f2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECORDING</th>\n",
       "      <th>PATHOLOGY</th>\n",
       "      <th>DATE</th>\n",
       "      <th>SPEAKER</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DETAIL</th>\n",
       "      <th>DIAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>715</td>\n",
       "      <td>p</td>\n",
       "      <td>20.05.1998</td>\n",
       "      <td>1407</td>\n",
       "      <td>w</td>\n",
       "      <td>63</td>\n",
       "      <td>Laryngitis; Leukoplakie</td>\n",
       "      <td>structural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1303</td>\n",
       "      <td>p</td>\n",
       "      <td>21.04.1999</td>\n",
       "      <td>1407</td>\n",
       "      <td>w</td>\n",
       "      <td>64</td>\n",
       "      <td>Leukoplakie</td>\n",
       "      <td>structural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1557</td>\n",
       "      <td>p</td>\n",
       "      <td>08.12.1999</td>\n",
       "      <td>1407</td>\n",
       "      <td>w</td>\n",
       "      <td>65</td>\n",
       "      <td>Leukoplakie</td>\n",
       "      <td>structural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1559</td>\n",
       "      <td>p</td>\n",
       "      <td>15.12.1999</td>\n",
       "      <td>1407</td>\n",
       "      <td>w</td>\n",
       "      <td>65</td>\n",
       "      <td>Leukoplakie</td>\n",
       "      <td>structural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1864</td>\n",
       "      <td>p</td>\n",
       "      <td>29.11.2000</td>\n",
       "      <td>1407</td>\n",
       "      <td>w</td>\n",
       "      <td>66</td>\n",
       "      <td>Leukoplakie</td>\n",
       "      <td>structural</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RECORDING PATHOLOGY        DATE  SPEAKER GENDER  AGE  \\\n",
       "0        715         p  20.05.1998     1407      w   63   \n",
       "1       1303         p  21.04.1999     1407      w   64   \n",
       "2       1557         p  08.12.1999     1407      w   65   \n",
       "3       1559         p  15.12.1999     1407      w   65   \n",
       "4       1864         p  29.11.2000     1407      w   66   \n",
       "\n",
       "                    DETAIL        DIAG  \n",
       "0  Laryngitis; Leukoplakie  structural  \n",
       "1              Leukoplakie  structural  \n",
       "2              Leukoplakie  structural  \n",
       "3              Leukoplakie  structural  \n",
       "4              Leukoplakie  structural  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_paper=pd.read_excel('D:/project/voice_pathology_ai/voice_data/only_organics_healthy.xlsx')\n",
    "answer_paper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c041ccab",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_paper['RECORDING']=answer_paper['RECORDING'].values.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f744d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_paper['RECORDING']=answer_paper['RECORDING']+'-phrase.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6390fe95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RECORDING</th>\n",
       "      <th>DETAIL</th>\n",
       "      <th>AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>715-phrase.wav</td>\n",
       "      <td>Laryngitis; Leukoplakie</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1303-phrase.wav</td>\n",
       "      <td>Leukoplakie</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1557-phrase.wav</td>\n",
       "      <td>Leukoplakie</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1559-phrase.wav</td>\n",
       "      <td>Leukoplakie</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1864-phrase.wav</td>\n",
       "      <td>Leukoplakie</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>80-phrase.wav</td>\n",
       "      <td>control</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>81-phrase.wav</td>\n",
       "      <td>control</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>82-phrase.wav</td>\n",
       "      <td>control</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>83-phrase.wav</td>\n",
       "      <td>control</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>153-phrase.wav</td>\n",
       "      <td>control</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1466 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            RECORDING                   DETAIL  AGE\n",
       "0      715-phrase.wav  Laryngitis; Leukoplakie   63\n",
       "1     1303-phrase.wav              Leukoplakie   64\n",
       "2     1557-phrase.wav              Leukoplakie   65\n",
       "3     1559-phrase.wav              Leukoplakie   65\n",
       "4     1864-phrase.wav              Leukoplakie   66\n",
       "...               ...                      ...  ...\n",
       "1461    80-phrase.wav                  control   49\n",
       "1462    81-phrase.wav                  control   42\n",
       "1463    82-phrase.wav                  control   49\n",
       "1464    83-phrase.wav                  control   46\n",
       "1465   153-phrase.wav                  control   60\n",
       "\n",
       "[1466 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_paper[['RECORDING','DETAIL','AGE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623c791c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>prediction</th>\n",
       "      <th>answer</th>\n",
       "      <th>fold</th>\n",
       "      <th>RECORDING</th>\n",
       "      <th>DETAIL</th>\n",
       "      <th>AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>946-phrase.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>946-phrase.wav</td>\n",
       "      <td>control</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94-phrase.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>94-phrase.wav</td>\n",
       "      <td>control</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>876-phrase.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>876-phrase.wav</td>\n",
       "      <td>Diplophonie; Kontaktpachydermie</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1181-phrase.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1181-phrase.wav</td>\n",
       "      <td>control</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2028-phrase.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2028-phrase.wav</td>\n",
       "      <td>Dysphonie; Laryngitis</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>1967-phrase.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1967-phrase.wav</td>\n",
       "      <td>Kontaktpachydermie</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>21-phrase.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>21-phrase.wav</td>\n",
       "      <td>control</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>2498-phrase.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2498-phrase.wav</td>\n",
       "      <td>Kontaktpachydermie</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2375-phrase.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2375-phrase.wav</td>\n",
       "      <td>Reinke ?em</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>680-phrase.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>680-phrase.wav</td>\n",
       "      <td>control</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>997 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  prediction  answer  fold        RECORDING  \\\n",
       "0     946-phrase.wav           0       0     1   946-phrase.wav   \n",
       "1      94-phrase.wav           1       0     1    94-phrase.wav   \n",
       "2     876-phrase.wav           1       1     1   876-phrase.wav   \n",
       "3    1181-phrase.wav           0       0     1  1181-phrase.wav   \n",
       "4    2028-phrase.wav           1       1     1  2028-phrase.wav   \n",
       "..               ...         ...     ...   ...              ...   \n",
       "992  1967-phrase.wav           1       1     5  1967-phrase.wav   \n",
       "993    21-phrase.wav           0       0     5    21-phrase.wav   \n",
       "994  2498-phrase.wav           0       1     5  2498-phrase.wav   \n",
       "995  2375-phrase.wav           1       1     5  2375-phrase.wav   \n",
       "996   680-phrase.wav           0       0     5   680-phrase.wav   \n",
       "\n",
       "                              DETAIL  AGE  \n",
       "0                            control   37  \n",
       "1                            control   55  \n",
       "2    Diplophonie; Kontaktpachydermie   73  \n",
       "3                            control   32  \n",
       "4              Dysphonie; Laryngitis   36  \n",
       "..                               ...  ...  \n",
       "992               Kontaktpachydermie   60  \n",
       "993                          control   20  \n",
       "994               Kontaktpachydermie   29  \n",
       "995                       Reinke ?em   52  \n",
       "996                          control   20  \n",
       "\n",
       "[997 rows x 7 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_left = pd.merge(fold_excel_all,answer_paper[['RECORDING','DETAIL','AGE']], how='left', left_on='filename', right_on='RECORDING')\n",
    "merge_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7224bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_left.drop(['RECORDING'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95705a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_left['result']=merge_left['prediction']==merge_left['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71de1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>prediction</th>\n",
       "      <th>answer</th>\n",
       "      <th>fold</th>\n",
       "      <th>DETAIL</th>\n",
       "      <th>AGE</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>946-phrase.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>control</td>\n",
       "      <td>37</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94-phrase.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>control</td>\n",
       "      <td>55</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>876-phrase.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Diplophonie; Kontaktpachydermie</td>\n",
       "      <td>73</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1181-phrase.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>control</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2028-phrase.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dysphonie; Laryngitis</td>\n",
       "      <td>36</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>1967-phrase.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Kontaktpachydermie</td>\n",
       "      <td>60</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>21-phrase.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>control</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>2498-phrase.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Kontaktpachydermie</td>\n",
       "      <td>29</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2375-phrase.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Reinke ?em</td>\n",
       "      <td>52</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>680-phrase.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>control</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>997 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  prediction  answer  fold  \\\n",
       "0     946-phrase.wav           0       0     1   \n",
       "1      94-phrase.wav           1       0     1   \n",
       "2     876-phrase.wav           1       1     1   \n",
       "3    1181-phrase.wav           0       0     1   \n",
       "4    2028-phrase.wav           1       1     1   \n",
       "..               ...         ...     ...   ...   \n",
       "992  1967-phrase.wav           1       1     5   \n",
       "993    21-phrase.wav           0       0     5   \n",
       "994  2498-phrase.wav           0       1     5   \n",
       "995  2375-phrase.wav           1       1     5   \n",
       "996   680-phrase.wav           0       0     5   \n",
       "\n",
       "                              DETAIL  AGE  result  \n",
       "0                            control   37    True  \n",
       "1                            control   55   False  \n",
       "2    Diplophonie; Kontaktpachydermie   73    True  \n",
       "3                            control   32    True  \n",
       "4              Dysphonie; Laryngitis   36    True  \n",
       "..                               ...  ...     ...  \n",
       "992               Kontaktpachydermie   60    True  \n",
       "993                          control   20    True  \n",
       "994               Kontaktpachydermie   29   False  \n",
       "995                       Reinke ?em   52    True  \n",
       "996                          control   20    True  \n",
       "\n",
       "[997 rows x 7 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86057b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_name = 'D:/project/voice_pathology_ai/voice_data/'+args['model']+'_seed_'+str(args['seed'])+'_organics_speaker.xlsx'\n",
    "merge_left.to_excel(excel_name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a27fad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "561.143px",
    "left": "22px",
    "top": "111.143px",
    "width": "255.025px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "427fa2592f9d0b947426e18ee897f81f41d4196bbcbbd4ad171fc20ee58cf88d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
