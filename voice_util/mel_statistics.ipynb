{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e1add4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Pytorch version :  1.10.2  Device :  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn # 인공 신경망 모델들 모아놓은 모듈\n",
    "import torch.nn.functional as F #그중 자주 쓰이는것들을 F로\n",
    "from torchvision import transforms, datasets\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import torchvision.models as models\n",
    "import sys\n",
    "import librosa, librosa.display \n",
    "\n",
    "p = os.path.abspath('D:/project/voice_pathology_ai/model') # 상위 폴더를 사용하기 위해서.\n",
    "sys.path.insert(1, p)\n",
    "from pytorchtools.pytorchtools import EarlyStopping # 상위 폴더에 추가된 모듈.\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "#DEVICE = torch.device('cpu')\n",
    "print('Using Pytorch version : ',torch.__version__,' Device : ',DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a80788c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torchaudio.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7bf6c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pathology :  1354\n",
      "Healthy:  634\n",
      "총 데이터수 :  1988\n",
      "---\n",
      "훈련 셋 :  1590 Counter({'pathology': 1083, 'healthy': 507})\n",
      "테스트 셋 :  398 Counter({'pathology': 271, 'healthy': 127})\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "#1. train, test 나누기\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split # train , test 분리에 사용.\n",
    "\n",
    "\n",
    "pathology = glob('D:/project/voice_pathology_ai/voice_data/all_data/pathology/phrase/*.wav')\n",
    "healthy = glob('D:/project/voice_pathology_ai/voice_data/all_data/healthy/phrase/*.wav')\n",
    "print(\"Pathology : \",len(pathology))\n",
    "print(\"Healthy: \",len(healthy))\n",
    "\n",
    "pathology= [ path.split(\"\\\\\")[-1] for path in pathology] # path 데이터 변환.\n",
    "healthy= [ path.split(\"\\\\\")[-1] for path in healthy] # path 데이터 변환.\n",
    " # path 데이터 변환 #외부데이터로 가져오기위해서, 번호만 남긴다\n",
    "\n",
    "    \n",
    "X = pathology+healthy # path 데이터 합\n",
    "print(\"총 데이터수 : \",len(X))\n",
    "Y = [] # 라벨\n",
    "for idx,x in enumerate(X):\n",
    "    if idx<1354:\n",
    "        Y.append(\"pathology\")\n",
    "    else:\n",
    "        Y.append(\"healthy\")\n",
    "\n",
    "X, X_test, Y, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True, stratify=Y, random_state=456)\n",
    "#stratify를 넣어서, test에도 라벨별 잘 분류되게 한다.\n",
    "\n",
    "print(\"---\")\n",
    "print(\"훈련 셋 : \",len(Y),Counter(Y))\n",
    "print(\"테스트 셋 : \",len(Y_test),Counter(Y_test))\n",
    "print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cc205f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    " \n",
    "#load\n",
    "with open(\"D:/project/voice_pathology_ai/voice_data/all_data/phrase_sig_dict.pickle\",\"rb\") as fr:\n",
    "    phrase_dict = pickle.load(fr)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7306366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "\n",
    "classes = [\"pathology\",\"healthy\"]\n",
    "sr=16000\n",
    "win_length =  np.int64(sr/40) # \n",
    "n_fft= win_length # WINDOWS SIZE중 사용할 길이. WINDOW SIZE가 넘어가면 나머지 것들은 zero padding\n",
    "hop_length= np.int64( np.ceil(win_length/4) ) #  얼마만큼 시간 주기(sample)를 이동하면서 분석을 할 것인지. 일반적으로 window size의 1/4\n",
    "#또는 10ms만큼으로 한다고 한다.\n",
    "#hop_length가 mfcc의 frame수를 결정한다.\n",
    "\n",
    "\n",
    "\n",
    "class svd_dataset(Dataset):\n",
    "    def __init__(self,data_path_list,classes,data_num,training,transform=None,raw_augment=None,augment=None):\n",
    "        #클래스에서 사용할 인자를 받아 인스턴스 변수로 저장하는 일을 한다.\n",
    "        #예를들면, 이미지의 경로 리스트를 저장하는 일을 하게 된다.\n",
    "        \n",
    "        #data_num : k 개 데이터 셋 중 어떤것을 쓸지\n",
    "        #test인지 아닌지.\n",
    "        \n",
    "        self.path_list = data_path_list[data_num]\n",
    "        self.data_num = data_num\n",
    "        self.training = training\n",
    "        self.label = svd_dataset.get_label(self.path_list,training,data_num)\n",
    "        self.classes=classes\n",
    "        self.transform=transform\n",
    "        self.augment=augment\n",
    "        self.raw_augment = raw_augment\n",
    "        \n",
    "    \n",
    "    @classmethod\n",
    "    def get_label(cls,data_path_list,training,data_num):\n",
    "        label_list=[]\n",
    "        \n",
    "        if training:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_train_list[data_num][idx])\n",
    "        else:\n",
    "            for idx,x in enumerate(data_path_list):\n",
    "                label_list.append(Y_valid_list[data_num][idx])\n",
    "        #print(label_list)\n",
    "        return label_list\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path_list)\n",
    "        #데이터 셋의 길이를 정수로 반환한다.     \n",
    "    \n",
    "       \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        1. path를 받아서, 소리에서 mfcc, spectro, mel-spectro를 추출\n",
    "        2. mfcc를 224프레임으로 패딩. 또한 세로축은 224으로 interpolate\n",
    "        3. resnet에 사용되기 위해 3채널로 쌓기.\n",
    "        4. 미정. 0~1 정규화\n",
    "        \n",
    "        \"\"\"\n",
    "        sig =  phrase_dict[self.path_list[idx]] # 16000hz 실시\n",
    "        \n",
    "        if self.raw_augment and self.training:\n",
    "            sig =  self.raw_augment(sig)        \n",
    "        \n",
    "        MFCCs = librosa.feature.mfcc(y=sig, sr=sr,win_length=win_length ,n_fft=n_fft, hop_length=hop_length, n_mfcc=128)\n",
    "        #MFCCs = librosa.util.normalize(MFCCs) # l-infinity norm\n",
    "        #MFCCs=cv2.resize(MFCCs,(MFCCs.shape[1],128),interpolation=cv2.INTER_LINEAR)# interpolate 적용해서 128 사이즈로\n",
    "        \n",
    "        \n",
    "        \n",
    "        stft = librosa.stft(sig, win_length=win_length,n_fft=n_fft, hop_length=hop_length)\n",
    "        \n",
    "        \n",
    "        mel_feature = librosa.feature.melspectrogram(y=sig,sr=sr,hop_length=hop_length,n_fft=n_fft)\n",
    "        mel_feature = librosa.core.power_to_db(mel_feature,ref=np.max)\n",
    "        #mel_feature=librosa.util.normalize(mel_feature) # l-infinity norm\n",
    "        \n",
    "        #stft 300 FRAME이 되도록 패딩.\n",
    "        length = 300\n",
    "\n",
    "        magnitude = np.abs(stft)\n",
    "        log_spectrogram = librosa.amplitude_to_db(magnitude)\n",
    "        #log_spectrogram = librosa.util.normalize(log_spectrogram) # l-infinity norm\n",
    "        \n",
    "        \n",
    "        #padding\n",
    "        pad2d = lambda a, i: a[:, 0:i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0], i-a.shape[1]))))\n",
    "        log_spectrogram = pad2d(log_spectrogram, length)\n",
    "        mel_feature = pad2d(mel_feature, length)\n",
    "        MFCCs = pad2d(MFCCs, length) # mfcc 대신 encoder를 가져와서 해보자.\n",
    "        log_spectrogram=log_spectrogram[:128,:]# 224 x 300 으로 사이즈 조절\n",
    "        \n",
    "        \n",
    "        if self.transform:\n",
    "            #print('transform')\n",
    "            log_spectrogram=self.transform(log_spectrogram).type(torch.float32)# 타입 변화\n",
    "            mel_feature=self.transform(mel_feature).type(torch.float32)# 타입 변화\n",
    "            MFCCs=self.transform(MFCCs).type(torch.float32)# 타입 변화\n",
    "            \n",
    "            \n",
    "            MSF = torch.stack([log_spectrogram,mel_feature,MFCCs])# 3채널로 복사.\n",
    "            MSF = MSF.squeeze(dim=1)\n",
    "            #augmentation\n",
    "            if self.training and self.augment:\n",
    "                MSF=self.augment(MSF)\n",
    "                \n",
    "        else:\n",
    "            #print(\"else\")\n",
    "            ##################안쓰는 곳\n",
    "            log_spectrogram = torch.from_numpy(log_spectrogram).type(torch.float32)\n",
    "            log_spectrogram=log_spectrogram.unsqueeze(0)#cnn 사용위해서 추가\n",
    "            #MFCCs = MFCCs.permute(2, 0, 1)\n",
    "        return MSF, self.classes.index(self.label[idx])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bf6d09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
